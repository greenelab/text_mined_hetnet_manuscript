## Introduction

Knowledge bases are essential resources that hold complex structured and unstructured information. 
These resources have been used to construct networks for drug repurposing discovery [@doi:10.1371/journal.pone.0084912; @doi:10.1101/385617; @doi:10.7554/eLife.26726] or as a source of training labels for text mining systems [@doi:10.3115/1690219.1690287; @doi:10.1101/444398; @doi:10.1186/s12859-019-2873-7]. 
Populating knowledge bases often requires highly trained scientists to read biomedical literature and summarize the results through manual curation [@doi:10.1093/bib/bbn043].
In 2007, researchers estimated that filling a knowledge base via manual curation would require approximately 8.4 years to complete [@doi:10.1093/bioinformatics/btm229]. 
As the rate of publications increases exponentially [@doi:10.1002/asi.23329], using only manual curation to populate a knowledge base has become nearly impractical. 

Relationship extraction is one of several solutions to the challenge posed by an exponentially growing body of literature [@doi:10.1093/bib/bbn043].
This process creates an expert system to automatically scan, detect, and extract relationships from textual sources.
These expert systems fall into three types: unsupervised, rule-based, and supervised systems.

Unsupervised systems extract relationships without the need for annotated text.
These approaches utilize linguistic patterns such as the frequency of two entities appearing in a sentence together more often than chance, commonly referred to as co-occurrence [@doi:10.1016/j.ymeth.2014.11.020; @doi:10.1093/nar/gkv383; @doi:10.1186/s12859-018-2048-y; @doi:10.1371/journal.pcbi.1005962; @doi:10.1371/journal.pcbi.1000943;@doi:10.1186/s12859-019-2634-7; @doi:10.1093/database/bau012; @doi:10.1109/BIBM.2015.7359766; @doi:10.7717/peerj.1054].
For example, a possible system would say gene X is associated with disease Y because gene X and disease Y appear together more often than chance [@doi:10.1016/j.ymeth.2014.11.020].
Besides frequency, other systems can utilize grammatical structure to identify relationships [@doi:10.1093/bioinformatics/bty114].
This information is modeled in the form of a tree data structure, termed a dependency tree.
Dependency trees depict words as nodes, and edges represent a word's grammatical relationship with one another.
Through clustering on these generated trees, one can identify patterns that indicate a biomedical relationship [@doi:10.1093/bioinformatics/bty114].
Unsupervised systems are desirable since they do not require well-annotated training data; however,  precision may be limited compared to supervised machine learning systems.

Rule-based systems rely heavily on expert knowledge to perform relationship extraction.
These systems use linguistic rules and heuristics to identify critical sentences or phrases that suggest the presence of a biomedical relationship  [@doi:10.1109/TCBB.2014.2372765; @doi:10.1186/1471-2105-14-181; @doi:10.1186/1471-2105-10-S2-S6; @doi:10.1093/nar/gkx462; @doi:10.1093/database/bas052; @pmid:26277115].
For example, a hypothetical extractor focused on protein phosphorylation events would identify sentences containing the phrase "gene X phosphorylates gene Y" [@doi:10.1109/TCBB.2014.2372765].
These approaches provide exact results, but the quantity of positive results remains modest as sentences consistently change in form and structure.
For this project, we constructed our label functions without the aid of these works; however, the approaches mentioned in this section provide substantial inspiration for novel label functions in future endeavors.

Supervised systems depend on machine learning classifiers to predict the existence of a relationship using biomedical text as input.
These classifiers can range from linear methods such as support vector machines [@doi:10.1371/journal.pone.0200699; @doi:10.1093/bioinformatics/btw503] to deep learning [@doi:10.1093/database/bay102; @doi:10.1016/j.neunet.2014.09.003; @arxiv:1904.02181; @arxiv:1901.08746; @arxiv:1706.03762; @doi:10.1093/database/bay060], which all require access to well-annotated datasets.
Typically, these datasets are usually constructed via manual curation by individual scientists [@doi:10.1186/s12859-015-0472-9; @doi:10.1016/j.jbi.2012.04.004; @doi:10.1016/j.artmed.2004.07.016; @doi:10.1186/1471-2105-8-50; @doi:10.1093/bioinformatics/btl616]  or through community-based efforts [@doi:10.1093/database/baw068; @biocreative-chemprot; @doi:10.1186/1471-2105-9-S3-S6].
Often, these datasets are well annotated but are modest in size, making model training hard as these algorithms become increasingly complex.

Distant supervision is a paradigm that quickly sidesteps manual curation to generate large training datasets.
This technique assumes that positive examples have been previously established in selected databases, implying that the corresponding sentences or data points are also positive [@doi:10.3115/1690219.1690287].
The central problem with this technique is that generated labels are often of low quality, resulting in many false positives [@jiang2018revisiting].
Despite this caveat there have been notable effort using this technique [@doi:10.1093/bioinformatics/btv476; @doi:10.1007/978-981-13-2354-6_39; @doi:10.1093/bioinformatics/btz490].

Data programming is one proposed solution to amend the false positive problem in distant supervision.
This strategy combines labels obtained from distant supervision with simple rules and heuristics written as small programs called label functions  [@arxiv:1605.07723].
These outputs are consolidated via a noise-aware model to produce training labels for large datasets.
Using this paradigm can dramatically reduce the time required to obtain sufficient training data; however, writing a helpful label function requires substantial time and error analysis.
This dependency makes constructing a knowledge base with a myriad of heterogenous relationships nearly impossible as tens or hundreds of label functions are necessary per relationship type.  

This paper seeks to accelerate the label function creation process by measuring how label functions can be reused across different relationship types.
We hypothesized that sentences describing one relationship type might share linguistic features such as keywords or sentence structure with sentences describing other relationship types.
If this hypothesis were to, one could drastically reduce the time needed to build a relation extractor system and swiftly populate large databases like Hetionet v1.
We conducted a series of experiments to estimate how label function reuse enhances performance over distant supervision alone.
As biomedical data comes in various forms (e.g. publications, electronic health records, images, genomic sequences, etc.), we chose to subset this space to only include open-access biomedical publications available on pubmed.
We focused on relationships that indicated similar types of physical interactions (i.e., Gene-binds-Gene and Compound-binds-Gene) and two more distinct types (i.e., Disease-associates-Gene and Compound-treats-Disease).
