## Discussion and Conclusions

Filling out knowledge bases via manual curation can be an arduous and erroneous task [@doi:10.1093/bioinformatics/btm229].
Using manual curation alone becomes impractical as the rate of publications continuously increases.
Data programming is a paradigm that uses label functions to speed up the annotation process and can be used to solve this problem.
However, creating useful label functions is an obstacle to this paradigm, which takes considerable time.
We tested the feasibility of re-using label functions to reduce the number of label functions required for strong prediction performance.

Our sampling experiment revealed that adding edge-specific label functions increases performance for the generative model.
We found that label functions designed from conceptually related edge types can increase performance (Gene-interacts-Gene (GiG) label functions predicting the Compound-binds-Gene (CbG) edge and vice versa), while others did not.
Using all label functions at once generally reduced performance with the exception being the DaG edge type.
One possibility for this observation is that the "associates" relationship is a general concept.
For example, DaG may contain many concepts related to other edge types, such as a Disease (up/down) regulating a Gene, which makes it more agnostic to label function sources (examples highlighted in our [annotated sentences](https://github.com/greenelab/text_mined_hetnet_manuscript/tree/master/supplementary_materials/annotated_sentences)).  

Regarding the discriminative model, adding edge-specific label function improved performance for two out of the four edge types (Compound-treats-Disease (CtD) and  DaG) (Figure {@fig:auroc_discriminative_model_performance} and Supplemental Figure {@fig:aupr_discriminative_model_performance}). 
GiG discriminative model showed minor improvements compared to the generative model, but only when nearly all edge-specific label functions are included (Figure {@fig:auroc_discriminative_model_performance} and Supplemental Figure {@fig:aupr_discriminative_model_performance}).
In terms of CbG, the discriminator model failed to improve over the generative model (Figure {@fig:auroc_discriminative_model_performance} and Supplemental Figure {@fig:aupr_discriminative_model_performance}).
A possible explanation for hindered performance is that these edge types contain many sentences with spurious gene mentions, resulting in many false-positive examples.
Improving performance for all edge types would require more labeled examples for the tuning set, along with the construction of more label functions for the generative model.
Even with these limitations, we estimated the recall amount of edges within Hetionet v1.
We found that our approach could recall a modest amount of existing edges while proposing a significant amount of new edges to be included (Figure {@fig:hetionet_reconstruction}). 
These results suggest that text mining is a viable approach to expanding existing knowledge bases; however, more advanced techniques [@doi:10.1145/2623330.2623623] may be necessary to combat the problem of high false positives.

Overall, we conclude that the re-use of label functions may improve performance for closely related edge types but does not improve performance for most pairings.
The discriminative model's performance improves as more edge-specific label functions are incorporated into the generative model; however, performance greatly depends on the annotations provided by the generative model.
This pattern suggests that future endeavors should emphasize label function construction and generative model training over the discriminative model to achieve better downstream performance.
Furthermore, other strategies such as multitask learning [@doi:10.1145/3209889.3209898] or transfer learning [@doi:10.1186/s40537-016-0043-6] could make mining multiple edge types more practical.
