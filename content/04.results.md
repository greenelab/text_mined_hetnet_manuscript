## Results

### Generative Model Using Randomly Sampled Label Functions

Creating label functions is a labor-intensive process that can take days to accomplish.
We sought to accelerate this process by measuring how well label functions can be reused.
We evaluated this by performing an experiment where label functions are sampled on an individual (edge vs. edge) level and a global (collective pool of sources) level.
We observed that performance increased when edge-specific label functions were added to an edge-specific baseline model, while label function reuse usually provided less benefit (AUROC Figure {@fig:auroc_gen_model_test_set}, AUPR Supplemental Figure {@fig:aupr_gen_model_test_set}).
The quintessential example of this overarching trend is the Compound treats Disease (CtD) edge type, where edge-specific label functions consistently outperformed transferred label functions.
However, there is evidence that label function transferability may be feasible for selected edge types and label function sources. 
Performance increases as more GiG label functions are incorporated into the CbG baseline model and vice versa.
This trend suggests that sentences for GiG and CbG may share similar linguistic features or terminology that allows for label functions to be reused, which could relate to both describing physical interaction relationships.
Perplexingly, edge-specific Disease associates Gene (DaG) label functions did not improve performance over label functions drawn from other edge types.
Overall, only CbG and GiG showed significant signs of reusability.
This pattern suggests that label function transferability may be possible for these two edge types.

![
Edge-specific label functions perform better than edge-mismatch label functions, but certain mismatch situations show signs of successful transfer.
Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions.
For example, orange represents sampling label functions designed to predict the Compound treats Disease (CtD) edge type.
The x-axis shows the number of randomly sampled label functions incorporated as an addition to the database-only baseline model (the point at 0).
The y-axis shows the area under the receiver operating curve (AUROC).
Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.
](https://raw.githubusercontent.com/danich1/snorkeling-full-text/80c9c899e91418af6fba7c74c9bc28b04be78458/figure_generation/output/figure_two.png){#fig:auroc_gen_model_test_set}

We found that sampling from all label function sources at once usually underperformed relative to edge-specific label functions (Figure {@fig:auroc_grabbag_gen_model_test_set} and Supplemental Figure {@fig:aupr_grabbag_gen_model_test_set}).
The gap between edge-specific sources and all sources widened as we sampled more label functions.
CbG is a prime example of this trend (Figure {@fig:auroc_grabbag_gen_model_test_set} and Supplemental Figure {@fig:aupr_grabbag_gen_model_test_set}), while CtD and GiG show a similar but milder trend.
DaG was the exception to the general rule.
The pooled set of label functions improved performance over the edge-specific ones, which aligns with the previously observed results for individual edge types (Figure {@fig:auroc_gen_model_test_set}).
When pooling all label functions, the decreasing trend supports the notion that label functions cannot simply transfer between edge types (exception being CbG on GiG and vice versa).

![
Using all label functions generally hinders generative model performance.
Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions.
For example, orange represents sampling label functions designed to predict the Compound treats Disease (CtD) edge type.
The x-axis shows the number of randomly sampled label functions incorporated as an addition to the database-only baseline model (the point at 0).
The y-axis shows the area under the receiver operating curve (AUROC).
Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.
](https://raw.githubusercontent.com/danich1/snorkeling-full-text/80c9c899e91418af6fba7c74c9bc28b04be78458/figure_generation/output/figure_four.png){#fig:auroc_grabbag_gen_model_test_set}


### Discriminative Model Performance

The discriminative model augments performance over the generative model by incorporating textual features together with estimated training labels.
Our discriminative model is a transformer called BioBERT [@arxiv:1901.08746] (See Methods and Materials for more information on training this model).
We found that the discriminative model generally outperforms the generative model with respect to AUROC as more edge-specific label functions are incorporated (Figure {@fig:auroc_discriminative_model_performance}).
Regarding AUPR, the model outperforms the generative model for the DaG edge type while the rest of the edge types have close to par performance (Supplemental Figure {@fig:aupr_discriminative_model_performance}).
The discriminative model's performance is often poorest when very few edge-specific label functions are incorporated into the baseline model (seen in Disease associates Gene (DaG), Compound binds Gene (CbG), and Gene interacts Gene (GiG)). 
This example suggests that training generative models with more label functions produces better outputs for training for discriminative models. 
Compound treats Disease (CtD) is an exception to this trend, where the discriminative model outperforms the generative model at all sampling levels.
We observed the opposite trend with the Compound-binds-Gene (CbG) edges as the discriminative model was always worse or indistinguishable from the generative model.
Interestingly, the AUPR for CbG plateaus below the generative model and decreases when all edge-specific label functions are used (Supplemental Figure {@fig:aupr_discriminative_model_performance}).
This trend suggests that the discriminative model might be predicting more false positives in this setting.
Overall, incorporating more edge-specific label functions usually improves performance for the discriminative model over the generative model.

![
The discriminative model usually improves faster than the generative model as more edge-specific label functions are included.
The line plot headers represent the specific edge type the discriminative model is trying to predict.
The x-axis shows the number of randomly sampled label functions incorporated as an addition to the baseline model (the point at 0).
The y axis shows the area under the receiver operating curve (AUROC).
Each data point represents the average of 3 sample runs for the discriminator model and 50 sample runs for the generative model.
The error bars represent each run's 95% confidence interval.
The baseline and "All" data points consist of sampling from the entire fixed set of label functions.
](https://raw.githubusercontent.com/danich1/snorkeling-full-text/80c9c899e91418af6fba7c74c9bc28b04be78458/figure_generation/output/figure_six.png){#fig:auroc_discriminative_model_performance}

### Text Mined Edges Can Expand a Database-derived Knowledge Graph

![
Text-mined edges recreate a substantial fraction of an existing knowledge graph and include new predictions.
This bar chart shows the number of edges we can successfully recall in green and indicates the number of new edges in blue.  
The recall for the Hetionet v1 knowledge graph is shown as a percentage in parentheses.
For example, for the Compound treats Disease (CtD) edge, our method recalls 32% of existing edges and can add 11,146 new ones.
](https://raw.githubusercontent.com/danich1/snorkeling-full-text/80c9c899e91418af6fba7c74c9bc28b04be78458/figure_generation/output/figure_eight.png){#fig:hetionet_reconstruction}

One of the goals of our work is to measure the extent to which learning multiple edge types could construct a biomedical knowledge graph.
Using Hetionet v1 as an evaluation set, we measured this framework's recall and quantified the number of edges that may be incorporated with high confidence.
Overall, we were able to recall about thirty percent of the preexisting edges for all edge types (Figure {@fig:hetionet_reconstruction}) and report our top ten scoring sentences for each edge type in Supplemental Table {@tbl:edge_prediction_tbl}.
Our best recall is with the Disease associates Gene (DaG) and Compound binds Gene (CbG) edge types, where we retain 33% of preexisting edges.
Plus, we can add over 100,000 new edges into both categories.
In contrast, we could only recall close to 30% of existing edges for the other categories; however, we can add over 10,000 novel edges to each category.
This notion highlights that Hetionet v1 is missing a compelling amount of biomedical information, and relationship extraction is a viable way to close the information gap.
