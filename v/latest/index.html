<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="David N. Nicholson" />
  <meta name="author" content="Daniel S. Himmelstein" />
  <meta name="author" content="Casey S. Greene" />
  <meta name="dcterms.date" content="2022-04-25" />
  <meta name="keywords" content="machine learning, weak supervision, natural language processing, heterogenous netowrks, text mining" />
  <title>Expanding a Database-derived Biomedical Knowledge Graph via Multi-relation Extraction from Biomedical Abstracts</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <!--
  Manubot generated metadata rendered from header-includes-template.html.
  Suggest improvements at https://github.com/manubot/manubot/blob/main/manubot/process/header-includes-template.html
  -->
  <meta name="dc.format" content="text/html" />
  <meta name="dc.title" content="Expanding a Database-derived Biomedical Knowledge Graph via Multi-relation Extraction from Biomedical Abstracts" />
  <meta name="citation_title" content="Expanding a Database-derived Biomedical Knowledge Graph via Multi-relation Extraction from Biomedical Abstracts" />
  <meta property="og:title" content="Expanding a Database-derived Biomedical Knowledge Graph via Multi-relation Extraction from Biomedical Abstracts" />
  <meta property="twitter:title" content="Expanding a Database-derived Biomedical Knowledge Graph via Multi-relation Extraction from Biomedical Abstracts" />
  <meta name="dc.date" content="2022-04-25" />
  <meta name="citation_publication_date" content="2022-04-25" />
  <meta name="dc.language" content="en-US" />
  <meta name="citation_language" content="en-US" />
  <meta name="dc.relation.ispartof" content="Manubot" />
  <meta name="dc.publisher" content="Manubot" />
  <meta name="citation_journal_title" content="Manubot" />
  <meta name="citation_technical_report_institution" content="Manubot" />
  <meta name="citation_author" content="David N. Nicholson" />
  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania" />
  <meta name="citation_author_orcid" content="0000-0003-0002-5761" />
  <meta name="twitter:creator" content="@None" />
  <meta name="citation_author" content="Daniel S. Himmelstein" />
  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania" />
  <meta name="citation_author_orcid" content="0000-0002-3012-7446" />
  <meta name="twitter:creator" content="@dhimmel" />
  <meta name="citation_author" content="Casey S. Greene" />
  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania" />
  <meta name="citation_author_orcid" content="0000-0001-8713-9213" />
  <meta name="twitter:creator" content="@GreeneScientist" />
  <link rel="canonical" href="https://greenelab.github.io/text_mined_hetnet_manuscript/" />
  <meta property="og:url" content="https://greenelab.github.io/text_mined_hetnet_manuscript/" />
  <meta property="twitter:url" content="https://greenelab.github.io/text_mined_hetnet_manuscript/" />
  <meta name="citation_fulltext_html_url" content="https://greenelab.github.io/text_mined_hetnet_manuscript/" />
  <meta name="citation_pdf_url" content="https://greenelab.github.io/text_mined_hetnet_manuscript/manuscript.pdf" />
  <link rel="alternate" type="application/pdf" href="https://greenelab.github.io/text_mined_hetnet_manuscript/manuscript.pdf" />
  <link rel="alternate" type="text/html" href="https://greenelab.github.io/text_mined_hetnet_manuscript/v/1ccd3b603a45727d2219e1ebfe64394bb4b61e62/" />
  <meta name="manubot_html_url_versioned" content="https://greenelab.github.io/text_mined_hetnet_manuscript/v/1ccd3b603a45727d2219e1ebfe64394bb4b61e62/" />
  <meta name="manubot_pdf_url_versioned" content="https://greenelab.github.io/text_mined_hetnet_manuscript/v/1ccd3b603a45727d2219e1ebfe64394bb4b61e62/manuscript.pdf" />
  <meta property="og:type" content="article" />
  <meta property="twitter:card" content="summary_large_image" />
  <meta property="og:image" content="https://github.com/greenelab/text_mined_hetnet_manuscript/raw/1ccd3b603a45727d2219e1ebfe64394bb4b61e62/thumbnail.png" />
  <meta property="twitter:image" content="https://github.com/greenelab/text_mined_hetnet_manuscript/raw/1ccd3b603a45727d2219e1ebfe64394bb4b61e62/thumbnail.png" />
  <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />
  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" />
  <meta name="theme-color" content="#ad1457" />
  <!-- end Manubot generated metadata -->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Expanding a Database-derived Biomedical Knowledge Graph via Multi-relation Extraction from Biomedical Abstracts</h1>
</header>
<p><em>A DOI-citable version of this manuscript is available at <a href="https://doi.org/10.1101/730085" class="uri">https://doi.org/10.1101/730085</a></em>.</p>
<p><small><em>
This manuscript
(<a href="https://greenelab.github.io/text_mined_hetnet_manuscript/v/1ccd3b603a45727d2219e1ebfe64394bb4b61e62/">permalink</a>)
was automatically generated
from <a href="https://github.com/greenelab/text_mined_hetnet_manuscript/tree/1ccd3b603a45727d2219e1ebfe64394bb4b61e62">greenelab/text_mined_hetnet_manuscript@1ccd3b6</a>
on April 25, 2022.
</em></small></p>
<h2 id="authors">Authors</h2>
<ul>
<li><p><strong>David N. Nicholson</strong><br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-0002-5761">0000-0003-0002-5761</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/danich1">danich1</a><br>
<small>
Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania
· Funded by GBMF4552
</small></p></li>
<li><p><strong>Daniel S. Himmelstein</strong><br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-3012-7446">0000-0002-3012-7446</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/dhimmel">dhimmel</a>
· <img src="images/twitter.svg" class="inline_icon" width="16" height="16" alt="Twitter icon" />
<a href="https://twitter.com/dhimmel">dhimmel</a><br>
<small>
Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania
· Funded by GBMF4552
</small></p></li>
<li><p><strong>Casey S. Greene</strong><br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-8713-9213">0000-0001-8713-9213</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/cgreene">cgreene</a>
· <img src="images/twitter.svg" class="inline_icon" width="16" height="16" alt="Twitter icon" />
<a href="https://twitter.com/GreeneScientist">GreeneScientist</a><br>
<small>
Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania
· Funded by GBMF4552 and R01 HG010067
</small></p></li>
</ul>
<h2 class="page_break_before" id="abstract">Abstract</h2>
<p>Knowledge graphs support multiple research efforts by providing contextual information for biomedical entities, constructing networks, and supporting the interpretation of high-throughput analyses.
These databases are populated via some form of manual curation, which is difficult to scale in the context of an increasing publication rate.
Data programming is a paradigm that circumvents this arduous manual process by combining databases with simple rules and heuristics written as label functions, which are programs designed to automatically annotate textual data.
Unfortunately, writing a useful label function requires substantial error analysis and is a nontrivial task that takes multiple days per function.
This makes populating a knowledge graph with multiple nodes and edge types practically infeasible.
We sought to accelerate the label function creation process by evaluating the extent to which label functions could be re-used across multiple edge types.
We used a subset of an existing knowledge graph centered on disease, compound, and gene entities to evaluate label function re-use.
We determined the best label function combination by comparing a baseline database-only model with the same model but added edge-specific or edge-mismatch label functions.
We confirmed that adding additional edge-specific rather than edge-mismatch label functions often improves text annotation and shows that this approach can incorporate novel edges into our source knowledge graph. 
We expect that continued development of this strategy has the potential to swiftly populate knowledge graphs with new discoveries, ensuring that these resources include cutting-edge results.</p>
<h2 id="introduction">Introduction</h2>
<p>Knowledge bases are essential resources that hold complex structured and unstructured information.
These resources have been used to construct networks for drug repurposing discovery <span class="citation" data-cites="u8pIAt5j bPvC638e O21tn8vf">[<a href="#ref-u8pIAt5j" role="doc-biblioref">1</a>,<a href="#ref-bPvC638e" role="doc-biblioref">2</a>,<a href="#ref-O21tn8vf" role="doc-biblioref">3</a>]</span> or as a source of training labels for text mining systems <span class="citation" data-cites="EHeTvZht CVHSURuI HS4ARwmZ">[<a href="#ref-EHeTvZht" role="doc-biblioref">4</a>,<a href="#ref-CVHSURuI" role="doc-biblioref">5</a>,<a href="#ref-HS4ARwmZ" role="doc-biblioref">6</a>]</span>.
Populating knowledge bases often requires highly trained scientists to read biomedical literature and summarize the results through manual curation <span class="citation" data-cites="N1Ai0gaI">[<a href="#ref-N1Ai0gaI" role="doc-biblioref">7</a>]</span>.
In 2007, researchers estimated that filling a knowledge base via manual curation would require approximately 8.4 years to complete <span class="citation" data-cites="UdzvLgBM">[<a href="#ref-UdzvLgBM" role="doc-biblioref">8</a>]</span>.
As the rate of publications increases exponentially <span class="citation" data-cites="1DBISRlwN">[<a href="#ref-1DBISRlwN" role="doc-biblioref">9</a>]</span>, using only manual curation to populate a knowledge base has become nearly impractical.</p>
<p>Relationship extraction is one of several solutions to the challenge posed by an exponentially growing body of literature <span class="citation" data-cites="N1Ai0gaI">[<a href="#ref-N1Ai0gaI" role="doc-biblioref">7</a>]</span>.
This process creates an expert system to automatically scan, detect, and extract relationships from textual sources.
These expert systems fall into three types: unsupervised, rule-based, and supervised systems.</p>
<p>Unsupervised systems extract relationships without the need for annotated text.
These approaches utilize linguistic patterns such as the frequency of two entities appearing in a sentence together more often than chance, commonly referred to as co-occurrence <span class="citation" data-cites="5gG8hwv7 WDNuFZ4j CxErbNTp DGlWGDEt AdKPf5EO AlisOVuX B8EOgoNA ETC6lm7S 6QECA6Hm">[<a href="#ref-5gG8hwv7" role="doc-biblioref">10</a>,<a href="#ref-WDNuFZ4j" role="doc-biblioref">11</a>,<a href="#ref-CxErbNTp" role="doc-biblioref">12</a>,<a href="#ref-DGlWGDEt" role="doc-biblioref">13</a>,<a href="#ref-AdKPf5EO" role="doc-biblioref">14</a>,<a href="#ref-AlisOVuX" role="doc-biblioref">15</a>,<a href="#ref-B8EOgoNA" role="doc-biblioref">16</a>,<a href="#ref-ETC6lm7S" role="doc-biblioref">17</a>,<a href="#ref-6QECA6Hm" role="doc-biblioref">18</a>]</span>.
For example, a possible system would say gene X is associated with disease Y because gene X and disease Y appear together more often than chance <span class="citation" data-cites="5gG8hwv7">[<a href="#ref-5gG8hwv7" role="doc-biblioref">10</a>]</span>.
Besides frequency, other systems can utilize grammatical structure to identify relationships <span class="citation" data-cites="CSiMoOrI">[<a href="#ref-CSiMoOrI" role="doc-biblioref">19</a>]</span>.
This information is modeled in the form of a tree data structure, termed a dependency tree.
Dependency trees depict words as nodes, and edges represent a word’s grammatical relationship with one another.
Through clustering on these generated trees, one can identify patterns that indicate a biomedical relationship <span class="citation" data-cites="CSiMoOrI">[<a href="#ref-CSiMoOrI" role="doc-biblioref">19</a>]</span>.
Unsupervised systems are desirable since they do not require well-annotated training data; however, precision may be limited compared to supervised machine learning systems.</p>
<p>Rule-based systems rely heavily on expert knowledge to perform relationship extraction.
These systems use linguistic rules and heuristics to identify critical sentences or phrases that suggest the presence of a biomedical relationship <span class="citation" data-cites="KEkjqdB0 1avvFjJ9 107WYOcxW OnvaFHG9 yGMDz6lK VZAovzAo">[<a href="#ref-KEkjqdB0" role="doc-biblioref">20</a>,<a href="#ref-1avvFjJ9" role="doc-biblioref">21</a>,<a href="#ref-107WYOcxW" role="doc-biblioref">22</a>,<a href="#ref-OnvaFHG9" role="doc-biblioref">23</a>,<a href="#ref-yGMDz6lK" role="doc-biblioref">24</a>,<a href="#ref-VZAovzAo" role="doc-biblioref">25</a>]</span>.
For example, a hypothetical extractor focused on protein phosphorylation events would identify sentences containing the phrase “gene X phosphorylates gene Y” <span class="citation" data-cites="KEkjqdB0">[<a href="#ref-KEkjqdB0" role="doc-biblioref">20</a>]</span>.
These approaches provide exact results, but the quantity of positive results remains modest as sentences consistently change in form and structure.
For this project, we constructed our label functions without the aid of these works; however, the approaches mentioned in this section provide substantial inspiration for novel label functions in future endeavors.</p>
<p>Supervised systems depend on machine learning classifiers to predict the existence of a relationship using biomedical text as input.
These classifiers can range from linear methods such as support vector machines <span class="citation" data-cites="GeCe9qfW 3j1T67vB">[<a href="#ref-GeCe9qfW" role="doc-biblioref">26</a>,<a href="#ref-3j1T67vB" role="doc-biblioref">27</a>]</span> to deep learning <span class="citation" data-cites="17sq8vXhj BQS8ClV0 8MgLh2XL riimmjYr Exfv0f4l WP5p3RT3">[<a href="#ref-17sq8vXhj" role="doc-biblioref">28</a>,<a href="#ref-BQS8ClV0" role="doc-biblioref">29</a>,<a href="#ref-8MgLh2XL" role="doc-biblioref">30</a>,<a href="#ref-riimmjYr" role="doc-biblioref">31</a>,<a href="#ref-Exfv0f4l" role="doc-biblioref">32</a>,<a href="#ref-WP5p3RT3" role="doc-biblioref">33</a>]</span>, which all require access to well-annotated datasets.
Typically, these datasets are usually constructed via manual curation by individual scientists <span class="citation" data-cites="hbAqN08A Y2DcwTrA YWh6tPj DWpAeBxB L9IIm3Zd">[<a href="#ref-hbAqN08A" role="doc-biblioref">34</a>,<a href="#ref-Y2DcwTrA" role="doc-biblioref">35</a>,<a href="#ref-YWh6tPj" role="doc-biblioref">36</a>,<a href="#ref-DWpAeBxB" role="doc-biblioref">37</a>,<a href="#ref-L9IIm3Zd" role="doc-biblioref">38</a>]</span> or through community-based efforts <span class="citation" data-cites="6wNuLZWb laJumZeu DR8XM4Ff">[<a href="#ref-6wNuLZWb" role="doc-biblioref">39</a>,<a href="#ref-laJumZeu" role="doc-biblioref">40</a>,<a href="#ref-DR8XM4Ff" role="doc-biblioref">41</a>]</span>.
Often, these datasets are well annotated but are modest in size, making model training hard as these algorithms become increasingly complex.</p>
<p>Distant supervision is a paradigm that quickly sidesteps manual curation to generate large training datasets.
This technique assumes that positive examples have been previously established in selected databases, implying that the corresponding sentences or data points are also positive <span class="citation" data-cites="EHeTvZht">[<a href="#ref-EHeTvZht" role="doc-biblioref">4</a>]</span>.
The central problem with this technique is that generated labels are often of low quality, resulting in many false positives <span class="citation" data-cites="ab3MsthY">[<a href="#ref-ab3MsthY" role="doc-biblioref">42</a>]</span>.
Despite this caveat there have been notable effort using this technique <span class="citation" data-cites="WYud0jQT k7ZUI6FL IGXdryzB">[<a href="#ref-WYud0jQT" role="doc-biblioref">43</a>,<a href="#ref-k7ZUI6FL" role="doc-biblioref">44</a>,<a href="#ref-IGXdryzB" role="doc-biblioref">45</a>]</span>.</p>
<p>Data programming is one proposed solution to amend the false positive problem in distant supervision.
This strategy combines labels obtained from distant supervision with simple rules and heuristics written as small programs called label functions <span class="citation" data-cites="5Il3kN32">[<a href="#ref-5Il3kN32" role="doc-biblioref">46</a>]</span>.
These outputs are consolidated via a noise-aware model to produce training labels for large datasets.
Using this paradigm can dramatically reduce the time required to obtain sufficient training data; however, writing a helpful label function requires substantial time and error analysis.
This dependency makes constructing a knowledge base with a myriad of heterogenous relationships nearly impossible as tens or hundreds of label functions are necessary per relationship type.</p>
<p>This paper seeks to accelerate the label function creation process by measuring how label functions can be reused across different relationship types.
We hypothesized that sentences describing one relationship type might share linguistic features such as keywords or sentence structure with sentences describing other relationship types.
If this hypothesis were to, one could drastically reduce the time needed to build a relation extractor system and swiftly populate large databases like Hetionet v1.
We conducted a series of experiments to estimate how label function reuse enhances performance over distant supervision alone.
We focused on relationships that indicated similar types of physical interactions (i.e., gene-binds-gene and compound-binds-gene) and two more distinct types (i.e., disease-associates-gene and compound-treats-disease).</p>
<style> 
span.gene_color { color:#02b3e4 } 
span.disease_color { color:#875442 } 
span.compound_color { color:#e91e63 }
 </style>
<h2 id="methods-and-materials">Methods and Materials</h2>
<h3 id="hetionet">Hetionet</h3>
<p>Hetionet v1 <span class="citation" data-cites="O21tn8vf">[<a href="#ref-O21tn8vf" role="doc-biblioref">3</a>]</span> is a heterogeneous network that contains pharmacological and biological information.
This network depicts information in the form of nodes and edges of different types.
Nodes in this network represent biological and pharmacological entities, while edges represent relationships between entities.
Hetionet v1 contains 47,031 nodes with 11 different data types and 2,250,197 edges that represent 24 different relationship types (Figure <a href="#fig:hetionet">1</a>).
Edges in Hetionet v1 were obtained from open databases, such as the GWAS Catalog <span class="citation" data-cites="16cIDAXhG">[<a href="#ref-16cIDAXhG" role="doc-biblioref">47</a>]</span>, Human Interaction database <span class="citation" data-cites="LCyCrr7W">[<a href="#ref-LCyCrr7W" role="doc-biblioref">48</a>]</span> and DrugBank <span class="citation" data-cites="1FI8iuYiQ">[<a href="#ref-1FI8iuYiQ" role="doc-biblioref">49</a>]</span>.
For this project, we analyzed performance over a subset of the Hetionet v1 edge types: disease associates with a gene (DaG), compound binds to a gene (CbG), compound treating a disease (CtD), and gene interacts with gene (GiG) (bolded in Figure <a href="#fig:hetionet">1</a>).</p>
<div id="fig:hetionet" class="fignos">
<figure>
<img src="images/figures/hetionet/metagraph_highlighted_edges.png" alt="Figure 1: A metagraph (schema) of Hetionet v1 where biomedical entities are represented as nodes and the relationships between them are represented as edges. We examined performance on the highlighted subgraph; however, the long-term vision is to capture edges for the entire graph." /><figcaption aria-hidden="true"><span>Figure 1:</span> A metagraph (schema) of Hetionet v1 where biomedical entities are represented as nodes and the relationships between them are represented as edges.
We examined performance on the highlighted subgraph; however, the long-term vision is to capture edges for the entire graph.</figcaption>
</figure>
</div>
<h3 id="dataset">Dataset</h3>
<p>We used PubTator Central <span class="citation" data-cites="18ZyyTcTe">[<a href="#ref-18ZyyTcTe" role="doc-biblioref">50</a>]</span> as input to our analysis.
PubTator Central provides MEDLINE abstracts that have been annotated with well-established entity recognition tools including Tagger One <span class="citation" data-cites="11YUuHulp">[<a href="#ref-11YUuHulp" role="doc-biblioref">51</a>]</span> for disease, chemical and cell line entities, tmVar <span class="citation" data-cites="17LQKv7vO">[<a href="#ref-17LQKv7vO" role="doc-biblioref">52</a>]</span> for genetic variation tagging, GNormPlus <span class="citation" data-cites="aOPX10e0">[<a href="#ref-aOPX10e0" role="doc-biblioref">53</a>]</span> for gene entities and SR4GN <span class="citation" data-cites="NXIFrudx">[<a href="#ref-NXIFrudx" role="doc-biblioref">54</a>]</span> for species entities.
We downloaded PubTator Central on March 1, 2020, at which point it contained approximately 30,000,000 documents.
After downloading, we filtered out annotated entities that were not contained in Hetionet v1.
We extracted sentences with two or more annotations and termed these sentences as candidate sentences.
We used the Spacy’s English natural language processing (NLP) pipeline (en_core_web_sm) <span class="citation" data-cites="q2fFAZTG">[<a href="#ref-q2fFAZTG" role="doc-biblioref">55</a>]</span> to generate dependency trees and parts of speech tags for every extracted candidate sentence.
Each candidate sentence was stratified by their corresponding abstract ID to produce a training set, tuning set, and a testing set.
We used random assortment to assign dataset labels to each abstract.
Every abstract had a 70% chance of being labeled training, 20% chance of being labeled tuning, and 10% chance of being labeled testing.
Despite the power of data programming, all text mining systems need to have ground truth labels to be well-calibrated.
We hand-labeled five hundred to a thousand candidate sentences of each edge type to obtain a ground truth set (Table <a href="#tbl:candidate-sentences">1</a>).</p>
<div id="tbl:candidate-sentences" class="tablenos">
<table id="tbl:candidate-sentences">
<caption><span>Table 1:</span> Statistics of Candidate Sentences.
We sorted each abstract into a training, tuning and testing set.
Numbers in parentheses show the number of positives and negatives that resulted from the hand-labeling process.
</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Relationship</th>
<th style="text-align: center;">Train</th>
<th style="text-align: center;">Tune</th>
<th style="text-align: center;">Test</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Disease Associates Gene</td>
<td style="text-align: center;">2.49 M</td>
<td style="text-align: center;">696K (397+, 603-)</td>
<td style="text-align: center;">348K (351+, 649-)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Compound Binds Gene</td>
<td style="text-align: center;">2.4M</td>
<td style="text-align: center;">684K (37+, 463-)</td>
<td style="text-align: center;">341k (31+, 469-)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Compound Treats Disease</td>
<td style="text-align: center;">1.5M</td>
<td style="text-align: center;">441K (96+, 404-)</td>
<td style="text-align: center;">223K (112+, 388-)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Gene Interacts Gene</td>
<td style="text-align: center;">11.2M</td>
<td style="text-align: center;">2.19M (60+, 440-)</td>
<td style="text-align: center;">1.62M (76+, 424-)</td>
</tr>
</tbody>
</table>
</div>
<h3 id="label-functions-for-annotating-sentences">Label Functions for Annotating Sentences</h3>
<p>The challenge of having too few ground truth annotations is familiar to many natural language processing applications, even when unannotated text is abundant.
Data programming circumvents this issue by quickly annotating large datasets using multiple noisy signals emitted by label functions <span class="citation" data-cites="5Il3kN32">[<a href="#ref-5Il3kN32" role="doc-biblioref">46</a>]</span>.
Label functions are simple pythonic functions that emit: a positive label (1), a negative label (0), or abstain from emitting a label (-1).
These functions can use different approaches or techniques to emit a label; however, these functions can be grouped into simple categories discussed below.
Once constructed, these functions are combined using a generative model to output a single annotation.
This single annotation is a consensus probability score bounded between 0 (low chance of mentioning a relationship) and 1 (high chance of mentioning a relationship).
We used these annotations to train a discriminative model for the final classification step.</p>
<h4 id="label-function-categories">Label Function Categories</h4>
<p>Label functions can be constructed in various ways; however, they also share similar characteristics.
We grouped functions into databases and text patterns.
The majority of our label functions fall into the text pattern category (Supplemental Table <a href="#tbl:label-functions">2</a>).
Further, we described each label function category and provided an example that refers to the following candidate sentence: “<span class="gene_color">PTK6</span> may be a novel therapeutic target for <span class="disease_color">pancreatic cancer</span>”.</p>
<p><strong>Databases</strong>: These label functions incorporate existing databases to generate a signal, as seen in distant supervision <span class="citation" data-cites="EHeTvZht">[<a href="#ref-EHeTvZht" role="doc-biblioref">4</a>]</span>.
These functions detect if a candidate sentence’s co-mention pair is present in a given database.
Our label function emits a positive label if the pair is present and abstains otherwise.
If the pair is not present in any existing database, a separate label function emits a negative label.
We used a separate label function to prevent a label imbalance problem, which can occur when a single function labels every possible sentence despite being correct or not.
If this problem isn’t handled correctly, the generative model could become biased and only emit one prediction (solely positive or solely negative) for every sentence.</p>
<p><span class="math display">\[ \Lambda_{DB}(\color{#875442}{D}, \color{#02b3e4}{G}) = 
\begin{cases}
 1 &amp; (\color{#875442}{D}, \color{#02b3e4}{G}) \in DB \\
0 &amp; otherwise \\
\end{cases} \]</span></p>
<p><span class="math display">\[ \Lambda_{\neg DB}(\color{#875442}{D}, \color{#02b3e4}{G}) = 
\begin{cases}
 -1 &amp; (\color{#875442}{D}, \color{#02b3e4}{G}) \notin DB \\
0 &amp; otherwise \\
\end{cases} \]</span></p>
<p><strong>Text Patterns</strong>: These label functions are designed to use keywords or sentence context to generate a signal.
For example, a label function could focus on the number of words between two mentions and emit a label if two mentions are too close.
Alternatively, a label function could focus on the parts of speech contained within a sentence and ensures a verb is present.
Besides parts of speech, a label function could exploit dependency parse trees to emit a label.
These trees are akin to the tree data structure where words are nodes and edges are how each word modifies each other.
Label functions that use these parse trees will test if the generated tree matches a pattern and emits a positive label if true.
For our analysis, we used previously identified patterns designed for biomedical text to generate our label functions <span class="citation" data-cites="tag:global_network">[<a href="#ref-tag:global_network" role="doc-biblioref"><strong>tag:global_network?</strong></a>]</span>.</p>
<p><span class="math display">\[ \Lambda_{TP}(\color{#875442}{D}, \color{#02b3e4}{G}) = 
\begin{cases}
 1 &amp; &quot;target&quot; \&gt; \in Candidate \&gt; Sentence \\
 -1 &amp; otherwise \\
\end{cases} \]</span></p>
<p><span class="math display">\[ \Lambda_{TP}(\color{#875442}{D}, \color{#02b3e4}{G}) = 
\begin{cases}
 0 &amp;    &quot;VB&quot; \&gt; \notin pos\_tags(Candidate \&gt; Sentence) \\
 -1 &amp; otherwise \\
\end{cases} \]</span></p>
<p><span class="math display">\[
\Lambda_{TP}(\color{#875442}{D}, \color{#02b3e4}{G}) = \begin{cases}
    1 &amp; dep(Candidate \&gt; Sentence) \in Cluster \&gt; Theme\\
    -1 &amp; otherwise \\
    \end{cases}
\]</span></p>
<p>Each text pattern label function was constructed via manual examination of sentences within the training set.
For example, using the candidate sentence above, one would identify the phrase “novel therapeutic target” and incorporate this phrase into a global list that a label function would use to check if present in a sentence.
After initial construction, we tested and augmented the label function using sentences in the tune set.
We repeated this process for every label function in our repertoire.</p>
<div id="tbl:label-functions" class="tablenos">
<table id="tbl:label-functions">
<caption><span>Table 2:</span> The distribution of each label function per relationship. </caption>
<thead>
<tr class="header">
<th>Relationship</th>
<th style="text-align: center;">Databases (DB)</th>
<th style="text-align: center;">Text Patterns (TP)</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>DaG</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>CtD</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td>CbG</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>GiG</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">28</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
</div>
<h3 id="training-models">Training Models</h3>
<h4 id="generative-model">Generative Model</h4>
<p>The generative model is a core part of this automatic annotation framework.
It integrates multiple signals emitted by label functions to assign each candidate sentence the most appropriate training class.
This model takes as input a label function output in the form of a matrix where rows represent candidate sentences, and columns represent each label function (<span class="math inline">\(\Lambda^{nxm}\)</span>).
Once constructed, this model treats the true training class (<span class="math inline">\(Y\)</span>) as a latent variable and assumes that each label function is independent of one another.
Under these two assumptions, the model finds the optimal parameters by minimizing a loglikelihood function marginalized over the latent training class.</p>
<p><span class="math display">\[
\hat{\theta} = argmin_{\theta}\sum_{Y}-log(P_{\theta}(\Lambda, Y)) 
\]</span></p>
<p>Following optimization, the model emits a probability estimate that each sentence belongs to the positive training class.
At this step, each probability estimate can be discretized via a chosen threshold into a positive or negative class.
We used a threshold of 0.5 for discretizing our training classes within our analysis.
For more information on how the likelihood function is constructed and minimized, refer to <span class="citation" data-cites="M3TiGlfS">[<a href="#ref-M3TiGlfS" role="doc-biblioref">56</a>]</span>.</p>
<h4 id="discriminative-model">Discriminative Model</h4>
<p>The discriminative model is the final step in this framework.
This model uses training labels generated from the generative model combined with sentence features to classify the presence of a biomedical relationship.
Typically, the discriminative model is a neural network.
We used BioBERT <span class="citation" data-cites="riimmjYr">[<a href="#ref-riimmjYr" role="doc-biblioref">31</a>]</span>, a BERT <span class="citation" data-cites="POJM5tCR">[<a href="#ref-POJM5tCR" role="doc-biblioref">57</a>]</span> model trained on all papers and abstracts within Pubmed Central <span class="citation" data-cites="u294RvPz">[<a href="#ref-u294RvPz" role="doc-biblioref">58</a>]</span>, as our discriminative model.
BioBERT provides its own set of word embeddings, dense vectors representing words that models such as neural networks can use to construct sentence features.
We downloaded a pre-trained version of this model using huggingface’s transformer python package <span class="citation" data-cites="187nWRTVH">[<a href="#ref-187nWRTVH" role="doc-biblioref">59</a>]</span> and fine-tuned it using our generated training labels.
Our fine-tuning approach involved freezing all downstream layers except for the classification head of this model.
Next, we trained this model for 10 epochs using the Adam optimizer <span class="citation" data-cites="c6d3lKFX">[<a href="#ref-c6d3lKFX" role="doc-biblioref">60</a>]</span> with huggingface’s default parameter settings and a learning rate of 0.001.</p>
<h3 id="experimental-design">Experimental Design</h3>
<p>Reusing label functions across edge types would substantially reduce the number of label functions required to extract multiple relationships from biomedical literature.
We first established a baseline by training a generative model using only distant supervision label functions designed for the target edge type (see Supplemental Methods).
Then we compared the baseline model with models that incorporated a set number of text pattern label functions.
Using a sampling with replacement approach, we sampled these text pattern label functions from three different groups: within edge types, across edge types, and from a pool of all label functions.
We compared within-edge-type performance to across-edge-type and all-edge-type performance.
We sampled a fixed number of label functions for each edge type consisting of five evenly spaced numbers between one and the total number of possible label functions.
We repeated this sampling process 50 times for each point.
Furthermore, we also trained the discriminative model using annotations from the generative model trained on edge-specific label functions at each point.
We report the performance of both models in terms of the area under the receiver operating characteristic curve (AUROC) and the area under the precision-recall curve (AUPR).
Ensuing model evaluations, we quantified the number of edges we could incorporate into Hetionet v1.
We used our best performing discriminative model to score every candidate sentence within our dataset and grouped candidates based on their mention pair.
We took the max score within each candidate group, and this score represents the probability of the existence of an edge.
We established edges using a cutoff score that produced an equal error rate between the false positives and false negatives.
Lastly, we report the number of preexisting edges we could recall and the number of novel edges we can incorporate.</p>
<h2 id="results">Results</h2>
<h3 id="generative-model-using-randomly-sampled-label-functions">Generative Model Using Randomly Sampled Label Functions</h3>
<p>Creating label functions is a labor-intensive process that can take days to accomplish.
We sought to accelerate this process by measuring how well label functions can be reused.
We evaluated this by performing an experiment where label functions are sampled on an individual (edge vs. edge) level and a global (collective pool of sources) level.
We observed that performance increased when edge-specific label functions were added to an edge-specific baseline model, while label function reuse usually provided less benefit (AUROC Figure <a href="#fig:auroc_gen_model_test_set">2</a>, AUPR Supplemental Figure <a href="#fig:aupr_gen_model_test_set">6</a>).
The quintessential example of this overarching trend is the Compound-treats-Disease (CtD) edge type, where edge-specific label functions consistently outperformed transferred label functions.
However, there is evidence that label function transferability may be feasible for selected edge types and label function sources.
Performance increases as more Gene-interacts-Gene (GiG) label functions are incorporated into the Compound-binds-Gene (CbG) baseline model and vice versa.
This trend suggests that sentences for GiG and CbG may share similar linguistic features or terminology that allows for label functions to be reused, which could relate to both describing physical interaction relationships.
Perplexingly, edge-specific Disease-associates-Gene (DaG) label functions did not improve performance over label functions drawn from other edge types.
Overall, only CbG and GiG showed significant signs of reusability.
This pattern suggests that label function transferability may be possible for these two edge types.</p>
<div id="fig:auroc_gen_model_test_set" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling-full-text/cd38c26db62f7eb7bc83fd9c424d0c8912512d06/figure_generation/output/figure_two.png" alt="Figure 2: Edge-specific label functions perform better than edge-mismatch label functions, but certain mismatch situations show signs of successful transfer. Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions. For example, orange represents sampling label functions designed to predict the Compound-treats-Disease (CtD) edge type. The x-axis shows the number of randomly sampled label functions incorporated as an addition to the database-only baseline model (the point at 0). The y-axis shows the area under the receiver operating curve (AUROC). Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs. The baseline and “All” data points consist of sampling from the entire fixed set of label functions." /><figcaption aria-hidden="true"><span>Figure 2:</span> Edge-specific label functions perform better than edge-mismatch label functions, but certain mismatch situations show signs of successful transfer.
Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions.
For example, orange represents sampling label functions designed to predict the Compound-treats-Disease (CtD) edge type.
The x-axis shows the number of randomly sampled label functions incorporated as an addition to the database-only baseline model (the point at 0).
The y-axis shows the area under the receiver operating curve (AUROC).
Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.</figcaption>
</figure>
</div>
<p>We found that sampling from all label function sources at once usually underperformed relative to edge-specific label functions (Figure <a href="#fig:auroc_grabbag_gen_model_test_set">3</a> and Supplemental Figure <a href="#fig:aupr_grabbag_gen_model_test_set">7</a>).
The gap between edge-specific sources and all sources widened as we sampled more label functions.
CbG is a prime example of this trend (Figure <a href="#fig:auroc_grabbag_gen_model_test_set">3</a> and Supplemental Figure <a href="#fig:aupr_grabbag_gen_model_test_set">7</a>), while CtD and GiG show a similar but milder trend.
DaG was the exception to the general rule.
The pooled set of label functions improved performance over the edge-specific ones, which aligns with the previously observed results for individual edge types (Figure <a href="#fig:auroc_gen_model_test_set">2</a>).
When pooling all label functions, the decreasing trend supports the notion that label functions cannot simply transfer between edge types (exception being CbG on GiG and vice versa).</p>
<div id="fig:auroc_grabbag_gen_model_test_set" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling-full-text/cd38c26db62f7eb7bc83fd9c424d0c8912512d06/figure_generation/output/figure_four.png" alt="Figure 3: Using all label functions generally hinders generative model performance. Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions. For example, orange represents sampling label functions designed to predict the Compound-treats-Disease (CtD) edge type. The x-axis shows the number of randomly sampled label functions incorporated as an addition to the database-only baseline model (the point at 0). The y-axis shows the area under the receiver operating curve (AUROC). Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs. The baseline and “All” data points consist of sampling from the entire fixed set of label functions." /><figcaption aria-hidden="true"><span>Figure 3:</span> Using all label functions generally hinders generative model performance.
Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions.
For example, orange represents sampling label functions designed to predict the Compound-treats-Disease (CtD) edge type.
The x-axis shows the number of randomly sampled label functions incorporated as an addition to the database-only baseline model (the point at 0).
The y-axis shows the area under the receiver operating curve (AUROC).
Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.</figcaption>
</figure>
</div>
<h3 id="discriminative-model-performance">Discriminative Model Performance</h3>
<p>The discriminative model is intended to augment performance over the generative model by incorporating textual features together with estimated training labels.
We found that the discriminative model generally outperformed the generative model with respect to AUROC as more edge-specific label functions were incorporated (Figure <a href="#fig:auroc_discriminative_model_performance">4</a>).
Regarding AUPR, this model outperformed the generative model for the Disease-associates-Gene (DaG) edge type.
At the same time, it had close to par performance for the rest of the edge types (Supplemental Figure <a href="#fig:aupr_discriminative_model_performance">8</a>).
The discriminative model’s performance was often poorest when very few edge-specific label functions were incorporated into the baseline model (seen in DaG, CbG, and Gene-interacts-Gene (GiG)).
This example suggests that training generative models with more label functions produces better outputs for training for discriminative models.
Compound-treats-Disease (CtD) was an exception to this trend, where the discriminative model outperformed the generative model at all sampling levels in regards to AUROC.
We observed the opposite trend with the Compound-binds-Gene (CbG) edges as the discriminative model was always worse or indistinguishable from the generative model.
Interestingly, the AUPR for CbG plateaus below the generative model and decreases when all edge-specific label functions are used (Supplemental Figure <a href="#fig:aupr_discriminative_model_performance">8</a>).
This trend suggests that the discriminative model might have predicted more false positives in this setting.
Overall, incorporating more edge-specific label functions usually improved performance for the discriminative model over the generative model.</p>
<div id="fig:auroc_discriminative_model_performance" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling-full-text/cd38c26db62f7eb7bc83fd9c424d0c8912512d06/figure_generation/output/figure_six.png" alt="Figure 4: The discriminative model usually improves faster than the generative model as more edge-specific label functions are included. The line plot headers represent the specific edge type the discriminative model is trying to predict. The x-axis shows the number of randomly sampled label functions incorporated as an addition to the baseline model (the point at 0). The y axis shows the area under the receiver operating curve (AUROC). Each data point represents the average of 3 sample runs for the discriminator model and 50 sample runs for the generative model. The error bars represent each run’s 95% confidence interval. The baseline and “All” data points consist of sampling from the entire fixed set of label functions." /><figcaption aria-hidden="true"><span>Figure 4:</span> The discriminative model usually improves faster than the generative model as more edge-specific label functions are included.
The line plot headers represent the specific edge type the discriminative model is trying to predict.
The x-axis shows the number of randomly sampled label functions incorporated as an addition to the baseline model (the point at 0).
The y axis shows the area under the receiver operating curve (AUROC).
Each data point represents the average of 3 sample runs for the discriminator model and 50 sample runs for the generative model.
The error bars represent each run’s 95% confidence interval.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.</figcaption>
</figure>
</div>
<h3 id="text-mined-edges-can-expand-a-database-derived-knowledge-graph">Text Mined Edges Can Expand a Database-derived Knowledge Graph</h3>
<div id="fig:hetionet_reconstruction" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling-full-text/8735cdde7e1db8592899dda8cbb44eda4479b1fa/figure_generation/output/figure_eight.png" alt="Figure 5: Text-mined edges recreate a substantial fraction of an existing knowledge graph and include new predictions. This bar chart shows the number of edges we can successfully recall in green and indicates the number of new edges in blue. The recall for the Hetionet v1 knowledge graph is shown as a percentage in parentheses. For example, for the Compound-treats-Disease (CtD) edge, our method recalls 30% of existing edges and can add 6,282 new ones." /><figcaption aria-hidden="true"><span>Figure 5:</span> Text-mined edges recreate a substantial fraction of an existing knowledge graph and include new predictions.
This bar chart shows the number of edges we can successfully recall in green and indicates the number of new edges in blue.<br />
The recall for the Hetionet v1 knowledge graph is shown as a percentage in parentheses.
For example, for the Compound-treats-Disease (CtD) edge, our method recalls 30% of existing edges and can add 6,282 new ones.</figcaption>
</figure>
</div>
<p>One of the goals of our work is to measure the extent to which learning multiple edge types could construct a biomedical knowledge graph.
Using Hetionet v1 as an evaluation set, we measured this framework’s recall and quantified the number of edges that may be incorporated with high confidence.
Overall, we were able to recall about thirty percent of the preexisting edges for all edge types (Figure <a href="#fig:hetionet_reconstruction">5</a>) and report our top ten scoring sentences for each edge type in Supplemental Table <a href="#tbl:edge_prediction_tbl">3</a>.
Our best recall was with the Compound-binds-Gene (CbG) edge type, where we retained 33% of preexisting edges.
In contrast, we only recalled close to 30% for Compound-treats-Disease (CtD), while the other two categories achieved a recall score close to 22%.
Despite the modest recall level, the amount of novel edge types remains elevated.
This notion highlights that Hetionet v1 is missing a compelling amount of biomedical information, and relationship extraction is a viable way to close the information gap.</p>
<h2 id="discussion-and-conclusions">Discussion and Conclusions</h2>
<p>Filling out knowledge bases via manual curation can be an arduous and erroneous task <span class="citation" data-cites="UdzvLgBM">[<a href="#ref-UdzvLgBM" role="doc-biblioref">8</a>]</span>.
Using manual curation alone becomes impractical as the rate of publications continuously increases.
Data programming is a paradigm that uses label functions to speed up the annotation process and can be used to solve this problem.
However, creating useful label functions is an obstacle to this paradigm, which takes considerable time.
We tested the feasibility of re-using label functions to reduce the number of label functions required for strong prediction performance.</p>
<p>Our sampling experiment revealed that adding edge-specific label functions is better than adding off-edge label functions.
An exception to this trend is using label functions designed from conceptually related edge types (using Gene-interacts-Gene (GiG) label functions to predict Compound-binds-Gene (CbG) sentences and vice versa).
Furthermore, broad edge types such as Disease-associates-Gene (DaG) did not follow this trend as we found this edge to be agnostic to any tested label function source.
One possibility for this observation is that the “associates” relationship is a general concept that may include other concepts such as Disease (up/down) regulating a Gene (examples highlighted in our <a href="https://github.com/greenelab/text_mined_hetnet_manuscript/tree/master/supplementary_materials/annotated_sentences">annotated sentences</a>).
The discriminator model did not have an apparent positive or negative effect on performance; however, we noticed that performance heavily depended on the annotations provided by the generative model.
This pattern suggests a focus on label function construction and generative model training may be key steps to focus on in future work.
Although we found that label functions cannot be re-used across all edge types with the standard task framing, strategies like multitask <span class="citation" data-cites="9Jo1af7Z">[<a href="#ref-9Jo1af7Z" role="doc-biblioref">61</a>]</span> or transfer learning <span class="citation" data-cites="YRDXK4f4">[<a href="#ref-YRDXK4f4" role="doc-biblioref">62</a>]</span> may make multi-label-function efforts more successful.</p>
<h2 id="supplemental-information">Supplemental Information</h2>
<p>An online version of this manuscript is available at <a href="https://greenelab.github.io/text_mined_hetnet_manuscript/" class="uri">https://greenelab.github.io/text_mined_hetnet_manuscript/</a>.
Labeled sentences are available at <a href="https://github.com/greenelab/text_mined_hetnet_manuscript/tree/master/supplementary_materials/annotated_sentences">https://github.com/greenelab/text_mined_hetnet_manuscript/tree/master/supplementary_materials/annotated_sentences</a>.
Source code for this work is available under open licenses at: <a href="https://github.com/greenelab/snorkeling/" class="uri">https://github.com/greenelab/snorkeling/</a>.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>The authors would like to thank Christopher Ré’s group at Stanford University, especially Alex Ratner and Steven Bach, for their assistance with this project.
We also want to thank Graciela Gonzalez-Hernandez for her advice and input with this project.
This work was support by <a href="https://www.moore.org/grant-detail?grantId=GBMF4552">Grant GBMF4552</a> from the Gordon Betty Moore Foundation.</p>
<h2 class="page_break_before" id="references">References</h2>
<!-- Explicitly insert bibliography here -->
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-u8pIAt5j" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline"><strong>Graph Theory Enables Drug Repurposing – How a Mathematical Model Can Drive the Discovery of Hidden Mechanisms of Action</strong> <div class="csl-block">Ruggero Gramatica, T Di Matteo, Stefano Giorgetti, Massimo Barbiani, Dorian Bevec, Tomaso Aste</div> <em>PLoS ONE</em> (2014-01-09) <a href="https://doi.org/gf45zp">https://doi.org/gf45zp</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pone.0084912">10.1371/journal.pone.0084912</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24416311">24416311</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3886994">PMC3886994</a></div></div>
</div>
<div id="ref-bPvC638e" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline"><strong>Drug repurposing through joint learning on knowledge graphs and literature</strong> <div class="csl-block">Mona Alshahrani, Robert Hoehndorf</div> <em>Bioinformatics</em> (2018-08-06) <a href="https://doi.org/gf45zk">https://doi.org/gf45zk</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1101/385617">10.1101/385617</a></div></div>
</div>
<div id="ref-O21tn8vf" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline"><strong>Systematic integration of biomedical knowledge prioritizes drugs for repurposing</strong> <div class="csl-block">Daniel Scott Himmelstein, Antoine Lizee, Christine Hessler, Leo Brueggeman, Sabrina L Chen, Dexter Hadley, Ari Green, Pouya Khankhanian, Sergio E Baranzini</div> <em>eLife</em> (2017-09-22) <a href="https://doi.org/cdfk">https://doi.org/cdfk</a> <div class="csl-block">DOI: <a href="https://doi.org/10.7554/elife.26726">10.7554/elife.26726</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28936969">28936969</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5640425">PMC5640425</a></div></div>
</div>
<div id="ref-EHeTvZht" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline"><strong>Distant supervision for relation extraction without labeled data</strong> <div class="csl-block">Mike Mintz, Steven Bills, Rion Snow, Dan Jurafsky</div> <em>Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2 - ACL-IJCNLP '09</em> (2009) <a href="https://doi.org/fg9q43">https://doi.org/fg9q43</a> <div class="csl-block">DOI: <a href="https://doi.org/10.3115/1690219.1690287">10.3115/1690219.1690287</a> · ISBN: 9781932432466</div></div>
</div>
<div id="ref-CVHSURuI" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline"><strong>CoCoScore: Context-aware co-occurrence scoring for text mining applications using distant supervision</strong> <div class="csl-block">Alexander Junge, Lars Juhl Jensen</div> <em>Bioinformatics</em> (2018-10-16) <a href="https://doi.org/gf45zm">https://doi.org/gf45zm</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1101/444398">10.1101/444398</a></div></div>
</div>
<div id="ref-HS4ARwmZ" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">6. </div><div class="csl-right-inline"><strong>Knowledge-guided convolutional networks for chemical-disease relation extraction</strong> <div class="csl-block">Huiwei Zhou, Chengkun Lang, Zhuang Liu, Shixian Ning, Yingyu Lin, Lei Du</div> <em>BMC Bioinformatics</em> (2019-12) <a href="https://doi.org/gf45zn">https://doi.org/gf45zn</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/s12859-019-2873-7">10.1186/s12859-019-2873-7</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31113357">31113357</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6528333">PMC6528333</a></div></div>
</div>
<div id="ref-N1Ai0gaI" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">7. </div><div class="csl-right-inline"><strong>Facts from text: can text mining help to scale-up high-quality manual curation of gene products with ontologies?</strong> <div class="csl-block">R Winnenburg, T Wachter, C Plake, A Doms, M Schroeder</div> <em>Briefings in Bioinformatics</em> (2008-07-11) <a href="https://doi.org/bfsnwg">https://doi.org/bfsnwg</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bib/bbn043">10.1093/bib/bbn043</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19060303">19060303</a></div></div>
</div>
<div id="ref-UdzvLgBM" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">8. </div><div class="csl-right-inline"><strong>Manual curation is not sufficient for annotation of genomic databases</strong> <div class="csl-block">William A Baumgartner, KBretonnel Cohen, Lynne M Fox, George Acquaah-Mensah, Lawrence Hunter</div> <em>Bioinformatics</em> (2007-07-01) <a href="https://doi.org/dtck86">https://doi.org/dtck86</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btm229">10.1093/bioinformatics/btm229</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/17646325">17646325</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2516305">PMC2516305</a></div></div>
</div>
<div id="ref-1DBISRlwN" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">9. </div><div class="csl-right-inline"><strong>Growth rates of modern science: A bibliometric analysis based on the number of publications and cited references: Growth Rates of Modern Science: A Bibliometric Analysis Based on the Number of Publications and Cited References</strong> <div class="csl-block">Lutz Bornmann, Rüdiger Mutz</div> <em>Journal of the Association for Information Science and Technology</em> (2015-11) <a href="https://doi.org/gfj5zc">https://doi.org/gfj5zc</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1002/asi.23329">10.1002/asi.23329</a></div></div>
</div>
<div id="ref-5gG8hwv7" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">10. </div><div class="csl-right-inline"><strong>DISEASES: Text mining and data integration of disease–gene associations</strong> <div class="csl-block">Sune Pletscher-Frankild, Albert Pallejà, Kalliopi Tsafou, Janos X Binder, Lars Juhl Jensen</div> <em>Methods</em> (2015-03) <a href="https://doi.org/f3mn6s">https://doi.org/f3mn6s</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.ymeth.2014.11.020">10.1016/j.ymeth.2014.11.020</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25484339">25484339</a></div></div>
</div>
<div id="ref-WDNuFZ4j" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">11. </div><div class="csl-right-inline"><strong>PolySearch2: a significantly improved text-mining system for discovering associations between human diseases, genes, drugs, metabolites, toxins and more</strong> <div class="csl-block">Yifeng Liu, Yongjie Liang, David Wishart</div> <em>Nucleic Acids Research</em> (2015-07-01) <a href="https://doi.org/f7nzn5">https://doi.org/f7nzn5</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/gkv383">10.1093/nar/gkv383</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25925572">25925572</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4489268">PMC4489268</a></div></div>
</div>
<div id="ref-CxErbNTp" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">12. </div><div class="csl-right-inline"><strong>The research on gene-disease association based on text-mining of PubMed</strong> <div class="csl-block">Jie Zhou, Bo-quan Fu</div> <em>BMC Bioinformatics</em> (2018-12) <a href="https://doi.org/gf479k">https://doi.org/gf479k</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/s12859-018-2048-y">10.1186/s12859-018-2048-y</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29415654">29415654</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5804013">PMC5804013</a></div></div>
</div>
<div id="ref-DGlWGDEt" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">13. </div><div class="csl-right-inline"><strong>A comprehensive and quantitative comparison of text-mining in 15 million full-text articles versus their corresponding abstracts</strong> <div class="csl-block">David Westergaard, Hans-Henrik Stærfeldt, Christian Tønsberg, Lars Juhl Jensen, Søren Brunak</div> <em>PLOS Computational Biology</em> (2018-02-15) <a href="https://doi.org/gcx747">https://doi.org/gcx747</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pcbi.1005962">10.1371/journal.pcbi.1005962</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29447159">29447159</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5831415">PMC5831415</a></div></div>
</div>
<div id="ref-AdKPf5EO" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">14. </div><div class="csl-right-inline"><strong>Literature Mining for the Discovery of Hidden Connections between Drugs, Genes and Diseases</strong> <div class="csl-block">Raoul Frijters, Marianne van Vugt, Ruben Smeets, René van Schaik, Jacob de Vlieg, Wynand Alkema</div> <em>PLoS Computational Biology</em> (2010-09-23) <a href="https://doi.org/bhrw7x">https://doi.org/bhrw7x</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pcbi.1000943">10.1371/journal.pcbi.1000943</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20885778">20885778</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2944780">PMC2944780</a></div></div>
</div>
<div id="ref-AlisOVuX" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">15. </div><div class="csl-right-inline"><strong>Analyzing a co-occurrence gene-interaction network to identify disease-gene association</strong> <div class="csl-block">Amira Al-Aamri, Kamal Taha, Yousof Al-Hammadi, Maher Maalouf, Dirar Homouz</div> <em>BMC Bioinformatics</em> (2019-12) <a href="https://doi.org/gf49nm">https://doi.org/gf49nm</a> <div class="csl-block">DOI: <a href="https://doi.org/doi:10.1186/s12859-019-2634-7">doi:10.1186/s12859-019-2634-7</a></div></div>
</div>
<div id="ref-B8EOgoNA" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">16. </div><div class="csl-right-inline"><strong>COMPARTMENTS: unification and visualization of protein subcellular localization evidence</strong> <div class="csl-block">JX Binder, S Pletscher-Frankild, K Tsafou, C Stolte, SI O'Donoghue, R Schneider, LJ Jensen</div> <em>Database</em> (2014-02-25) <a href="https://doi.org/btbm">https://doi.org/btbm</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/database/bau012">10.1093/database/bau012</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24573882">24573882</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3935310">PMC3935310</a></div></div>
</div>
<div id="ref-ETC6lm7S" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">17. </div><div class="csl-right-inline"><strong>A new method for prioritizing drug repositioning candidates extracted by literature-based discovery</strong> <div class="csl-block">Majid Rastegar-Mojarad, Ravikumar Komandur Elayavilli, Dingcheng Li, Rashmi Prasad, Hongfang Liu</div> <em>2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</em> (2015-11) <a href="https://doi.org/gf479j">https://doi.org/gf479j</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1109/bibm.2015.7359766">10.1109/bibm.2015.7359766</a> · ISBN: 9781467367998</div></div>
</div>
<div id="ref-6QECA6Hm" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">18. </div><div class="csl-right-inline"><strong>Comprehensive comparison of large-scale tissue expression datasets</strong> <div class="csl-block">Alberto Santos, Kalliopi Tsafou, Christian Stolte, Sune Pletscher-Frankild, Seán I O’Donoghue, Lars Juhl Jensen</div> <em>PeerJ</em> (2015-06-30) <a href="https://doi.org/f3mn6p">https://doi.org/f3mn6p</a> <div class="csl-block">DOI: <a href="https://doi.org/10.7717/peerj.1054">10.7717/peerj.1054</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26157623">26157623</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4493645">PMC4493645</a></div></div>
</div>
<div id="ref-CSiMoOrI" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">19. </div><div class="csl-right-inline"><strong>A global network of biomedical relationships derived from text</strong> <div class="csl-block">Bethany Percha, Russ B Altman</div> <em>Bioinformatics</em> (2018-08-01) <a href="https://doi.org/gc3ndk">https://doi.org/gc3ndk</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/bty114">10.1093/bioinformatics/bty114</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29490008">29490008</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6061699">PMC6061699</a></div></div>
</div>
<div id="ref-KEkjqdB0" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">20. </div><div class="csl-right-inline"><strong>RLIMS-P 2.0: A Generalizable Rule-Based Information Extraction System for Literature Mining of Protein Phosphorylation Information</strong> <div class="csl-block">Manabu Torii, Cecilia N Arighi, Gang Li, Qinghua Wang, Cathy H Wu, K Vijay-Shanker</div> <em>IEEE/ACM Transactions on Computational Biology and Bioinformatics</em> (2015-01-01) <a href="https://doi.org/gf8fpv">https://doi.org/gf8fpv</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1109/tcbb.2014.2372765">10.1109/tcbb.2014.2372765</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26357075">26357075</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4568560">PMC4568560</a></div></div>
</div>
<div id="ref-1avvFjJ9" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">21. </div><div class="csl-right-inline"><strong>Large-scale extraction of accurate drug-disease treatment pairs from biomedical literature for drug repurposing</strong> <div class="csl-block">Rong Xu, QuanQiu Wang</div> <em>BMC Bioinformatics</em> (2013-12) <a href="https://doi.org/gb8v3k">https://doi.org/gb8v3k</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/1471-2105-14-181">10.1186/1471-2105-14-181</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/23742147">23742147</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3702428">PMC3702428</a></div></div>
</div>
<div id="ref-107WYOcxW" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">22. </div><div class="csl-right-inline"><strong>Pharmspresso: a text mining tool for extraction of pharmacogenomic concepts and relationships from full text</strong> <div class="csl-block">Yael Garten, Russ B Altman</div> <em>BMC Bioinformatics</em> (2009-02) <a href="https://doi.org/df75hq">https://doi.org/df75hq</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/1471-2105-10-s2-s6">10.1186/1471-2105-10-s2-s6</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19208194">19208194</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2646239">PMC2646239</a></div></div>
</div>
<div id="ref-OnvaFHG9" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">23. </div><div class="csl-right-inline"><strong>LimTox: a web tool for applied text mining of adverse event and toxicity associations of compounds, drugs and genes</strong> <div class="csl-block">Andres Cañada, Salvador Capella-Gutierrez, Obdulia Rabal, Julen Oyarzabal, Alfonso Valencia, Martin Krallinger</div> <em>Nucleic Acids Research</em> (2017-07-03) <a href="https://doi.org/gf479h">https://doi.org/gf479h</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/gkx462">10.1093/nar/gkx462</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28531339">28531339</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5570141">PMC5570141</a></div></div>
</div>
<div id="ref-yGMDz6lK" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">24. </div><div class="csl-right-inline"><strong>PPInterFinder—a mining tool for extracting causal relations on human proteins from literature</strong> <div class="csl-block">Kalpana Raja, Suresh Subramani, Jeyakumar Natarajan</div> <em>Database</em> (2013-01-01) <a href="https://doi.org/gf479b">https://doi.org/gf479b</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/database/bas052">10.1093/database/bas052</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/23325628">23325628</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3548331">PMC3548331</a></div></div>
</div>
<div id="ref-VZAovzAo" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">25. </div><div class="csl-right-inline"><strong>PKDE4J: Entity and relation extraction for public knowledge discovery.</strong> <div class="csl-block">Min Song, Won Chul Kim, Dahee Lee, Go Eun Heo, Keun Young Kang</div> <em>Journal of biomedical informatics</em> (2015-08-12) <a href="https://www.ncbi.nlm.nih.gov/pubmed/26277115">https://www.ncbi.nlm.nih.gov/pubmed/26277115</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.jbi.2015.08.008">10.1016/j.jbi.2015.08.008</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26277115">26277115</a></div></div>
</div>
<div id="ref-GeCe9qfW" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">26. </div><div class="csl-right-inline"><strong>Automatic extraction of gene-disease associations from literature using joint ensemble learning</strong> <div class="csl-block">Balu Bhasuran, Jeyakumar Natarajan</div> <em>PLOS ONE</em> (2018-07-26) <a href="https://doi.org/gdx63f">https://doi.org/gdx63f</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pone.0200699">10.1371/journal.pone.0200699</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30048465">30048465</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6061985">PMC6061985</a></div></div>
</div>
<div id="ref-3j1T67vB" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">27. </div><div class="csl-right-inline"><strong>DTMiner: identification of potential disease targets through biomedical literature mining</strong> <div class="csl-block">Dong Xu, Meizhuo Zhang, Yanping Xie, Fan Wang, Ming Chen, Kenny Q Zhu, Jia Wei</div> <em>Bioinformatics</em> (2016-08-09) <a href="https://doi.org/f9nw36">https://doi.org/f9nw36</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btw503">10.1093/bioinformatics/btw503</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27506226">27506226</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5181534">PMC5181534</a></div></div>
</div>
<div id="ref-17sq8vXhj" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">28. </div><div class="csl-right-inline"><strong>Extracting chemical–protein relations using attention-based neural networks</strong> <div class="csl-block">Sijia Liu, Feichen Shen, Ravikumar Komandur Elayavilli, Yanshan Wang, Majid Rastegar-Mojarad, Vipin Chaudhary, Hongfang Liu</div> <em>Database</em> (2018-01-01) <a href="https://doi.org/gfdz8d">https://doi.org/gfdz8d</a> <div class="csl-block">DOI: <a href="https://doi.org/doi:10.1093/database/bay102">doi:10.1093/database/bay102</a></div></div>
</div>
<div id="ref-BQS8ClV0" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">29. </div><div class="csl-right-inline"><strong>Deep learning in neural networks: An overview</strong> <div class="csl-block">Jürgen Schmidhuber</div> <em>Neural Networks</em> (2015-01) <a href="https://doi.org/f6v78n">https://doi.org/f6v78n</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.neunet.2014.09.003">10.1016/j.neunet.2014.09.003</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25462637">25462637</a></div></div>
</div>
<div id="ref-8MgLh2XL" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">30. </div><div class="csl-right-inline"><strong>Probing Biomedical Embeddings from Language Models</strong> <div class="csl-block">Qiao Jin, Bhuwan Dhingra, William W Cohen, Xinghua Lu</div> <em>arXiv</em> (2019-04-05) <a href="https://arxiv.org/abs/1904.02181">https://arxiv.org/abs/1904.02181</a></div>
</div>
<div id="ref-riimmjYr" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">31. </div><div class="csl-right-inline"><strong>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</strong> <div class="csl-block">Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, Jaewoo Kang</div> <em>arXiv</em> (2019-10-21) <a href="https://arxiv.org/abs/1901.08746">https://arxiv.org/abs/1901.08746</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btz682">10.1093/bioinformatics/btz682</a></div></div>
</div>
<div id="ref-Exfv0f4l" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">32. </div><div class="csl-right-inline"><strong>Attention Is All You Need</strong> <div class="csl-block">Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, Illia Polosukhin</div> <em>arXiv</em> (2017-12-07) <a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a></div>
</div>
<div id="ref-WP5p3RT3" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">33. </div><div class="csl-right-inline"><strong>Chemical–gene relation extraction using recursive neural network</strong> <div class="csl-block">Sangrak Lim, Jaewoo Kang</div> <em>Database</em> (2018-01-01) <a href="https://doi.org/gdss6f">https://doi.org/gdss6f</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/database/bay060">10.1093/database/bay060</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29961818">29961818</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6014134">PMC6014134</a></div></div>
</div>
<div id="ref-hbAqN08A" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">34. </div><div class="csl-right-inline"><strong>Extraction of relations between genes and diseases from text and large-scale data analysis: implications for translational research</strong> <div class="csl-block">Àlex Bravo, Janet Piñero, Núria Queralt-Rosinach, Michael Rautschka, Laura I Furlong</div> <em>BMC Bioinformatics</em> (2015-12) <a href="https://doi.org/f7kn8s">https://doi.org/f7kn8s</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/s12859-015-0472-9">10.1186/s12859-015-0472-9</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25886734">25886734</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4466840">PMC4466840</a></div></div>
</div>
<div id="ref-Y2DcwTrA" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">35. </div><div class="csl-right-inline"><strong>The EU-ADR corpus: Annotated drugs, diseases, targets, and their relationships</strong> <div class="csl-block">Erik M van Mulligen, Annie Fourrier-Reglat, David Gurwitz, Mariam Molokhia, Ainhoa Nieto, Gianluca Trifiro, Jan A Kors, Laura I Furlong</div> <em>Journal of Biomedical Informatics</em> (2012-10) <a href="https://doi.org/f36vn6">https://doi.org/f36vn6</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.jbi.2012.04.004">10.1016/j.jbi.2012.04.004</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22554700">22554700</a></div></div>
</div>
<div id="ref-YWh6tPj" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">36. </div><div class="csl-right-inline"><strong>Comparative experiments on learning information extractors for proteins and their interactions</strong> <div class="csl-block">Razvan Bunescu, Ruifang Ge, Rohit J Kate, Edward M Marcotte, Raymond J Mooney, Arun K Ramani, Yuk Wah Wong</div> <em>Artificial Intelligence in Medicine</em> (2005-02) <a href="https://doi.org/dhztpn">https://doi.org/dhztpn</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.artmed.2004.07.016">10.1016/j.artmed.2004.07.016</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/15811782">15811782</a></div></div>
</div>
<div id="ref-DWpAeBxB" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">37. </div><div class="csl-right-inline"><strong>BioInfer: a corpus for information extraction in the biomedical domain</strong> <div class="csl-block">Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari Björne, Jorma Boberg, Jouni Järvinen, Tapio Salakoski</div> <em>BMC Bioinformatics</em> (2007-12) <a href="https://doi.org/b7bhhc">https://doi.org/b7bhhc</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/1471-2105-8-50">10.1186/1471-2105-8-50</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/17291334">17291334</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1808065">PMC1808065</a></div></div>
</div>
<div id="ref-L9IIm3Zd" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">38. </div><div class="csl-right-inline"><strong>RelEx--Relation extraction using dependency parse trees</strong> <div class="csl-block">K Fundel, R Kuffner, R Zimmer</div> <em>Bioinformatics</em> (2007-02-01) <a href="https://doi.org/cz7q4d">https://doi.org/cz7q4d</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btl616">10.1093/bioinformatics/btl616</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/17142812">17142812</a></div></div>
</div>
<div id="ref-6wNuLZWb" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">39. </div><div class="csl-right-inline"><strong>BioCreative V CDR task corpus: a resource for chemical disease relation extraction</strong> <div class="csl-block">Jiao Li, Yueping Sun, Robin J Johnson, Daniela Sciaky, Chih-Hsuan Wei, Robert Leaman, Allan Peter Davis, Carolyn J Mattingly, Thomas C Wiegers, Zhiyong Lu</div> <em>Database</em> (2016) <a href="https://doi.org/gf5hfw">https://doi.org/gf5hfw</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/database/baw068">10.1093/database/baw068</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27161011">27161011</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4860626">PMC4860626</a></div></div>
</div>
<div id="ref-laJumZeu" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">40. </div><div class="csl-right-inline"><strong>Overview of the biocreative vi chemical-protein interaction track</strong> <div class="csl-block">Martin Krallinger, Obdulia Rabal, Saber A Akhondiothers</div> <em>Proceedings of the sixth biocreative challenge evaluation workshop</em> (2017) <a href="https://www.semanticscholar.org/paper/Overview-of-the-BioCreative-VI-chemical-protein-Krallinger-Rabal/eed781f498b563df5a9e8a241c67d63dd1d92ad5">https://www.semanticscholar.org/paper/Overview-of-the-BioCreative-VI-chemical-protein-Krallinger-Rabal/eed781f498b563df5a9e8a241c67d63dd1d92ad5</a></div>
</div>
<div id="ref-DR8XM4Ff" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">41. </div><div class="csl-right-inline"><strong>Comparative analysis of five protein-protein interaction corpora</strong> <div class="csl-block">Sampo Pyysalo, Antti Airola, Juho Heimonen, Jari Björne, Filip Ginter, Tapio Salakoski</div> <em>BMC Bioinformatics</em> (2008-04) <a href="https://doi.org/fh3df7">https://doi.org/fh3df7</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/1471-2105-9-s3-s6">10.1186/1471-2105-9-s3-s6</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/18426551">18426551</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2349296">PMC2349296</a></div></div>
</div>
<div id="ref-ab3MsthY" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">42. </div><div class="csl-right-inline"><strong>Revisiting distant supervision for relation extraction</strong> <div class="csl-block">Tingsong Jiang, Jing Liu, Chin-Yew Lin, Zhifang Sui</div> <em>Proceedings of the eleventh international conference on language resources and evaluation (LREC 2018)</em> (2018-05) <a href="https://aclanthology.org/L18-1566">https://aclanthology.org/L18-1566</a></div>
</div>
<div id="ref-WYud0jQT" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">43. </div><div class="csl-right-inline"><strong>Large-scale extraction of gene interactions from full-text literature using DeepDive</strong> <div class="csl-block">Emily K Mallory, Ce Zhang, Christopher Ré, Russ B Altman</div> <em>Bioinformatics</em> (2015-09-03) <a href="https://doi.org/gb5g7b">https://doi.org/gb5g7b</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btv476">10.1093/bioinformatics/btv476</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26338771">26338771</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4681986">PMC4681986</a></div></div>
</div>
<div id="ref-k7ZUI6FL" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">44. </div><div class="csl-right-inline"><strong>Distant Supervision for Large-Scale Extraction of Gene–Disease Associations from Literature Using DeepDive</strong> <div class="csl-block">Balu Bhasuran, Jeyakumar Natarajan</div> <em>International Conference on Innovative Computing and Communications</em> (2019) <a href="https://doi.org/gf5hfv">https://doi.org/gf5hfv</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/978-981-13-2354-6_39">10.1007/978-981-13-2354-6_39</a> · ISBN: 9789811323539</div></div>
</div>
<div id="ref-IGXdryzB" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">45. </div><div class="csl-right-inline"><strong>CoCoScore: context-aware co-occurrence scoring for text mining applications using distant supervision</strong> <div class="csl-block">Alexander Junge, Lars Juhl Jensen</div> <em>Bioinformatics</em> (2020-01-01) <a href="https://doi.org/gf4789">https://doi.org/gf4789</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btz490">10.1093/bioinformatics/btz490</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31199464">31199464</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6956794">PMC6956794</a></div></div>
</div>
<div id="ref-5Il3kN32" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">46. </div><div class="csl-right-inline"><strong>Data Programming: Creating Large Training Sets, Quickly</strong> <div class="csl-block">Alexander Ratner, Christopher De Sa, Sen Wu, Daniel Selsam, Christopher Ré</div> <em>arXiv</em> (2018-12-10) <a href="https://arxiv.org/abs/1605.07723">https://arxiv.org/abs/1605.07723</a></div>
</div>
<div id="ref-16cIDAXhG" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">47. </div><div class="csl-right-inline"><strong>The new NHGRI-EBI Catalog of published genome-wide association studies (GWAS Catalog)</strong> <div class="csl-block">Jacqueline MacArthur, Emily Bowler, Maria Cerezo, Laurent Gil, Peggy Hall, Emma Hastings, Heather Junkins, Aoife McMahon, Annalisa Milano, Joannella Morales, … Helen Parkinson</div> <em>Nucleic Acids Research</em> (2017-01-04) <a href="https://doi.org/f9v7cp">https://doi.org/f9v7cp</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/gkw1133">10.1093/nar/gkw1133</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27899670">27899670</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5210590">PMC5210590</a></div></div>
</div>
<div id="ref-LCyCrr7W" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">48. </div><div class="csl-right-inline"><strong>A Proteome-Scale Map of the Human Interactome Network</strong> <div class="csl-block">Thomas Rolland, Murat Taşan, Benoit Charloteaux, Samuel J Pevzner, Quan Zhong, Nidhi Sahni, Song Yi, Irma Lemmens, Celia Fontanillo, Roberto Mosca, … Marc Vidal</div> <em>Cell</em> (2014-11) <a href="https://doi.org/f3mn6x">https://doi.org/f3mn6x</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.cell.2014.10.050">10.1016/j.cell.2014.10.050</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25416956">25416956</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4266588">PMC4266588</a></div></div>
</div>
<div id="ref-1FI8iuYiQ" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">49. </div><div class="csl-right-inline"><strong>DrugBank 5.0: a major update to the DrugBank database for 2018</strong> <div class="csl-block">David S Wishart, Yannick D Feunang, An C Guo, Elvis J Lo, Ana Marcu, Jason R Grant, Tanvir Sajed, Daniel Johnson, Carin Li, Zinat Sayeeda, … Michael Wilson</div> <em>Nucleic Acids Research</em> (2018-01-04) <a href="https://doi.org/gcwtzk">https://doi.org/gcwtzk</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/gkx1037">10.1093/nar/gkx1037</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29126136">29126136</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5753335">PMC5753335</a></div></div>
</div>
<div id="ref-18ZyyTcTe" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">50. </div><div class="csl-right-inline"><strong>PubTator central: automated concept annotation for biomedical full text articles</strong> <div class="csl-block">Chih-Hsuan Wei, Alexis Allot, Robert Leaman, Zhiyong Lu</div> <em>Nucleic Acids Research</em> (2019-07-02) <a href="https://doi.org/ggzfsc">https://doi.org/ggzfsc</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/gkz389">10.1093/nar/gkz389</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31114887">31114887</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6602571">PMC6602571</a></div></div>
</div>
<div id="ref-11YUuHulp" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">51. </div><div class="csl-right-inline"><strong>TaggerOne: joint named entity recognition and normalization with semi-Markov Models</strong> <div class="csl-block">Robert Leaman, Zhiyong Lu</div> <em>Bioinformatics</em> (2016-09-15) <a href="https://doi.org/f855dg">https://doi.org/f855dg</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btw343">10.1093/bioinformatics/btw343</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27283952">27283952</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5018376">PMC5018376</a></div></div>
</div>
<div id="ref-17LQKv7vO" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">52. </div><div class="csl-right-inline"><strong>tmVar 2.0: integrating genomic variant information from literature with dbSNP and ClinVar for precision medicine</strong> <div class="csl-block">Chih-Hsuan Wei, Lon Phan, Juliana Feltz, Rama Maiti, Tim Hefferon, Zhiyong Lu</div> <em>Bioinformatics</em> (2018-01-01) <a href="https://doi.org/gbzsmc">https://doi.org/gbzsmc</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btx541">10.1093/bioinformatics/btx541</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28968638">28968638</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5860583">PMC5860583</a></div></div>
</div>
<div id="ref-aOPX10e0" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">53. </div><div class="csl-right-inline"><strong>GNormPlus: An Integrative Approach for Tagging Genes, Gene Families, and Protein Domains</strong> <div class="csl-block">Chih-Hsuan Wei, Hung-Yu Kao, Zhiyong Lu</div> <em>BioMed Research International</em> (2015) <a href="https://doi.org/gb85jb">https://doi.org/gb85jb</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1155/2015/918710">10.1155/2015/918710</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26380306">26380306</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4561873">PMC4561873</a></div></div>
</div>
<div id="ref-NXIFrudx" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">54. </div><div class="csl-right-inline"><strong>SR4GN: A Species Recognition Software Tool for Gene Normalization</strong> <div class="csl-block">Chih-Hsuan Wei, Hung-Yu Kao, Zhiyong Lu</div> <em>PLoS ONE</em> (2012-06-05) <a href="https://doi.org/gpq498">https://doi.org/gpq498</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pone.0038460">10.1371/journal.pone.0038460</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22679507">22679507</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3367953">PMC3367953</a></div></div>
</div>
<div id="ref-q2fFAZTG" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">55. </div><div class="csl-right-inline"><strong>spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing</strong> <div class="csl-block">Matthew Honnibal, Ines Montani</div> (2017)</div>
</div>
<div id="ref-M3TiGlfS" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">56. </div><div class="csl-right-inline"><strong>Snorkel: rapid training data creation with weak supervision</strong> <div class="csl-block">Alexander Ratner, Stephen H Bach, Henry Ehrenberg, Jason Fries, Sen Wu, Christopher Ré</div> <em>The VLDB Journal</em> (2020-05) <a href="https://doi.org/ghbw5f">https://doi.org/ghbw5f</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/s00778-019-00552-1">10.1007/s00778-019-00552-1</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32214778">32214778</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7075849">PMC7075849</a></div></div>
</div>
<div id="ref-POJM5tCR" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">57. </div><div class="csl-right-inline"><strong>[No title found]</strong> <div class="csl-block">Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova</div> <em>Proceedings of the 2019 Conference of the North</em> (2019) <a href="https://doi.org/ggbwf6">https://doi.org/ggbwf6</a> <div class="csl-block">DOI: <a href="https://doi.org/10.18653/v1/n19-1423">10.18653/v1/n19-1423</a></div></div>
</div>
<div id="ref-u294RvPz" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">58. </div><div class="csl-right-inline"><strong>PubMed Central: The GenBank of the published literature</strong> <div class="csl-block">Richard J Roberts</div> <em>Proceedings of the National Academy of Sciences</em> (2001-01-16) <a href="https://doi.org/bbn9k8">https://doi.org/bbn9k8</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1073/pnas.98.2.381">10.1073/pnas.98.2.381</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/11209037">11209037</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC33354">PMC33354</a></div></div>
</div>
<div id="ref-187nWRTVH" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">59. </div><div class="csl-right-inline"><strong>&lt;span class="nocase"&gt;Transformers: State-of-the-Art Natural Language Processing&lt;/span&gt;</strong> <div class="csl-block">Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Perric Cistac, Clara Ma, Yacine Jernite, Julien Plu, … Alexander M Rush</div> <em>Association for Computational Linguistics</em> (2020-10) <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.6">https://www.aclweb.org/anthology/2020.emnlp-demos.6</a></div>
</div>
<div id="ref-c6d3lKFX" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">60. </div><div class="csl-right-inline"><strong>Adam: A Method for Stochastic Optimization</strong> <div class="csl-block">Diederik P Kingma, Jimmy Ba</div> <em>arXiv</em> (2017-01-31) <a href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a></div>
</div>
<div id="ref-9Jo1af7Z" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">61. </div><div class="csl-right-inline"><strong>Snorkel MeTaL: Weak Supervision for Multi-Task Learning</strong> <div class="csl-block">Alex Ratner, Braden Hancock, Jared Dunnmon, Roger Goldman, Christopher Ré</div> <em>Proceedings of the Second Workshop on Data Management for End-To-End Machine Learning</em> (2018-06-15) <a href="https://doi.org/gf3xk7">https://doi.org/gf3xk7</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1145/3209889.3209898">10.1145/3209889.3209898</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30931438">30931438</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6436830">PMC6436830</a> · ISBN: 9781450358286</div></div>
</div>
<div id="ref-YRDXK4f4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">62. </div><div class="csl-right-inline"><strong>A survey of transfer learning</strong> <div class="csl-block">Karl Weiss, Taghi M Khoshgoftaar, DingDing Wang</div> <em>Journal of Big Data</em> (2016-12) <a href="https://doi.org/gfkr2w">https://doi.org/gfkr2w</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/s40537-016-0043-6">10.1186/s40537-016-0043-6</a></div></div>
</div>
</div>
<h2 id="supplemental-figures">Supplemental Figures</h2>
<h3 id="generative-model-using-randomly-sampled-label-functions-1">Generative Model Using Randomly Sampled Label Functions</h3>
<h4 id="individual-sources">Individual Sources</h4>
<div id="fig:aupr_gen_model_test_set" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling-full-text/cd38c26db62f7eb7bc83fd9c424d0c8912512d06/figure_generation/output/figure_three.png" alt="Figure 6: Edge-specific label functions improve performance over edge-mismatch label functions. Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions. For example, orange represents sampling label functions designed to predict the Compound treats Disease (CtD) edge type. The x-axis shows the number of randomly sampled label functions incorporated as an addition to the database-only baseline model (the point at 0). The y-axis shows the area under the precision-recall curve (AUPR). Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs. The baseline and “All” data points consist of sampling from the entire fixed set of label functions." /><figcaption aria-hidden="true"><span>Figure 6:</span> Edge-specific label functions improve performance over edge-mismatch label functions.
Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions.
For example, orange represents sampling label functions designed to predict the Compound treats Disease (CtD) edge type.
The x-axis shows the number of randomly sampled label functions incorporated as an addition to the database-only baseline model (the point at 0).
The y-axis shows the area under the precision-recall curve (AUPR).
Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.</figcaption>
</figure>
</div>
<h4 id="collective-pool-of-sources">Collective Pool of Sources</h4>
<div id="fig:aupr_grabbag_gen_model_test_set" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling-full-text/cd38c26db62f7eb7bc83fd9c424d0c8912512d06/figure_generation/output/figure_five.png" alt="Figure 7: Using all label functions generally hinders generative model performance. Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions. For example, orange represents sampling label functions designed to predict the Compound treats Disease (CtD) edge type. The x-axis shows the number of randomly sampled label functions incorporated as an addition to the database-only baseline model (the point at 0). The y-axis shows the area under the precision-recall curve (AUPR). Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs. The baseline and “All” data points consist of sampling from the entire fixed set of label functions." /><figcaption aria-hidden="true"><span>Figure 7:</span> Using all label functions generally hinders generative model performance.
Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions.
For example, orange represents sampling label functions designed to predict the Compound treats Disease (CtD) edge type.
The x-axis shows the number of randomly sampled label functions incorporated as an addition to the database-only baseline model (the point at 0).
The y-axis shows the area under the precision-recall curve (AUPR).
Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.</figcaption>
</figure>
</div>
<h3 id="discriminative-model-performance-1">Discriminative Model Performance</h3>
<div id="fig:aupr_discriminative_model_performance" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling-full-text/cd38c26db62f7eb7bc83fd9c424d0c8912512d06/figure_generation/output/figure_seven.png" alt="Figure 8: The discriminator model improves performance as the number of edge-specific label functions is added to the baseline model. The line plot headers represent the specific edge type the discriminator model is trying to predict. The x-axis shows the number of randomly sampled label functions incorporated as an addition to the baseline model (the point at 0). The y axis shows the area under the precision-recall curve (AUPR). Each data point represents the average of 3 sample runs for the discriminator model and 50 sample runs for the generative model. The error bars represent each run’s 95% confidence interval. The baseline and “All” data points consist of sampling from the entire fixed set of label functions." /><figcaption aria-hidden="true"><span>Figure 8:</span> The discriminator model improves performance as the number of edge-specific label functions is added to the baseline model.
The line plot headers represent the specific edge type the discriminator model is trying to predict.
The x-axis shows the number of randomly sampled label functions incorporated as an addition to the baseline model (the point at 0).
The y axis shows the area under the precision-recall curve (AUPR).
Each data point represents the average of 3 sample runs for the discriminator model and 50 sample runs for the generative model.
The error bars represent each run’s 95% confidence interval.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.</figcaption>
</figure>
</div>
<h2 id="supplemental-tables">Supplemental Tables</h2>
<h3 id="top-ten-sentences-for-each-edge-type">Top Ten Sentences for Each Edge Type</h3>
<div id="tbl:edge_prediction_tbl" class="tablenos">
<table id="tbl:edge_prediction_tbl">
<caption><span>Table 3:</span> Contains the top ten predictions for each edge type. Highlighted words represent entities mentioned within the given sentence. </caption>
<colgroup>
<col style="width: 7%" />
<col style="width: 3%" />
<col style="width: 3%" />
<col style="width: 5%" />
<col style="width: 6%" />
<col style="width: 3%" />
<col style="width: 2%" />
<col style="width: 68%" />
</colgroup>
<thead>
<tr class="header">
<th>Edge Type</th>
<th>Source Node</th>
<th>Target Node</th>
<th>Generative Model Prediction</th>
<th>Discriminative Model Prediction</th>
<th>Number of Sentences</th>
<th>In Hetionet</th>
<th>Text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>hematologic cancer</td>
<td>STMN1</td>
<td>1.000</td>
<td>0.979</td>
<td>83</td>
<td>Novel</td>
<td>the stathmin1 mrna expression level in de novo al patient be high than that in healthy person ( p &lt; 0.05 ) , the [stathmin1].{gene_color} mrna expression level in relapse patient with al be high than that in de novo patient ( p &lt; 0.05 ) , and there be no significant difference of stathmin1 mrna expression between patient with [aml].{disease_color} and patient with all .</td>
</tr>
<tr class="even">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>breast cancer</td>
<td>INSIG2</td>
<td>1.000</td>
<td>0.979</td>
<td>4</td>
<td>Novel</td>
<td>in analysis of [idc ].{disease_color} cell , the level of [insig2].{gene_color} mrna expression be significantly high in late - stage patient than in early - stage patient .</td>
</tr>
<tr class="odd">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>lung cancer</td>
<td>GNAO1</td>
<td>1.000</td>
<td>0.979</td>
<td>104</td>
<td>Novel</td>
<td>high [numb].{disease_color} expression be associate with favorable prognosis in patient with [lung adenocarcinoma].{gene_color} , but not in those with squamous cell carcinoma .</td>
</tr>
<tr class="even">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>breast cancer</td>
<td>TTF1</td>
<td>1.000</td>
<td>0.977</td>
<td>88</td>
<td>Novel</td>
<td>significant [ttf-1].{gene_color} overexpression be observe in adenocarcinomas harbor egfr mutation ( p = 0.008 ) , and no or significantly low level expression of ttf-1 be observe in [adenocarcinomas].{disease_color} harbor kras mutation ( p = 0.000 ) .</td>
</tr>
<tr class="odd">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>breast cancer</td>
<td>BUB1B</td>
<td>1.000</td>
<td>0.977</td>
<td>13</td>
<td>Novel</td>
<td>elevated [bubr1].{gene_color} expression be associate with poor survival in early stage [breast cancer].{disease_color} patient .</td>
</tr>
<tr class="even">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>Alzheimer’s disease</td>
<td>SERPINA3</td>
<td>1.000</td>
<td>0.977</td>
<td>182</td>
<td>Existing</td>
<td>a common polymorphism within act and il-1beta gene affect plasma level of [act].{gene_color} or il-1beta , and [ad].{disease_color} patient with the act t , t or il-1beta t , t genotype show the high level of plasma act or il-1beta , respectively .</td>
</tr>
<tr class="odd">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>esophageal cancer</td>
<td>TRAF6</td>
<td>1.000</td>
<td>0.976</td>
<td>15</td>
<td>Novel</td>
<td>expression of traf6 be highly elevated in [esophageal cancer].{disease_color} tissue , and patient with high [traf6].{gene_color} expression have a significantly short survival time than those with low traf6 expression .</td>
</tr>
<tr class="even">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>hypertension</td>
<td>TBX4</td>
<td>1.000</td>
<td>0.975</td>
<td>146</td>
<td>Novel</td>
<td>the proportion of circulate [th1].{gene_color} cell and the level of t - bet , ifng mrna be increase in [ht].{disease_color} patient , the expression of ifng - as1 be upregulated and positively correlate with the proportion of circulate th1 cell or t - bet , and ifng expression , or serum level of anti - thyroglobulin antibody / thyroperoxidase antibody in ht patient .</td>
</tr>
<tr class="odd">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>breast cancer</td>
<td>TP53</td>
<td>1.000</td>
<td>0.975</td>
<td>3481</td>
<td>Existing</td>
<td>hormone receptor status rather than her2 status be significantly associate with increase ki-67 and [p53].{gene_color} expression in triple [- negative ].{disease_color} breast carcinoma , and high expression of ki-67 but not p53 be significantly associate with axillary nodal metastasis in triple - negative and high - grade non - triple - negative breast carcinoma .</td>
</tr>
<tr class="even">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>esophageal cancer</td>
<td>COL17A1</td>
<td>1.000</td>
<td>0.975</td>
<td>32</td>
<td>Novel</td>
<td>high [cd147].{gene_color} expression in patient with [esophageal cancer].{disease_color} be associate with bad survival outcome and common clinicopathological indicator of poor prognosis .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Docetaxel</td>
<td>prostate cancer</td>
<td>0.996</td>
<td>0.964</td>
<td>5614</td>
<td>Existing</td>
<td>docetaxel and atrasentan versus [docetaxel ].{compound_color} and placebo for man with advanced castration - resistant [prostate cancer].{disease_color} ( swog s0421 ) : a randomised phase 3 trial</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>E7389</td>
<td>breast cancer</td>
<td>0.999</td>
<td>0.957</td>
<td>862</td>
<td>Novel</td>
<td>clinical effect of prior trastuzumab on combination [eribulin mesylate].{compound_color} plus trastuzumab as first - line treatment for human epidermal growth factor receptor 2 positive locally recurrent or metastatic [breast cancer].{disease_color} : result from a phase ii , single - arm , multicenter study</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Zoledronate</td>
<td>bone cancer</td>
<td>0.996</td>
<td>0.955</td>
<td>226</td>
<td>Novel</td>
<td>[zoledronate].{compound_color} in combination with chemotherapy and surgery to treat [osteosarcoma].{disease_color} ( os2006 ) : a randomised , multicentre , open - label , phase 3 trial .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td></td>
<td></td>
<td>0.878</td>
<td>0.954</td>
<td>484</td>
<td>Existing</td>
<td>the role of [ixazomib].{compound_color} as an augment conditioning therapy in salvage autologous stem cell transplant ( asct ) and as a post - asct consolidation and maintenance strategy in patient with relapse multiple myeloma ( accord [ uk - mra [myeloma].{disease_color} xii ] trial ) : study protocol for a phase iii randomise controlled trial</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Topotecan</td>
<td>lung cancer</td>
<td>1.000</td>
<td>0.954</td>
<td>315</td>
<td>Existing</td>
<td>combine chemotherapy with cisplatin , etoposide , and irinotecan versus [topotecan].{compound_color} alone as second - line treatment for patient with [sensitive relapse small].{disease_color} - cell lung cancer ( jcog0605 ) : a multicentre , open - label , randomised phase 3 trial .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Epirubicin</td>
<td>breast cancer</td>
<td>0.999</td>
<td>0.953</td>
<td>2147</td>
<td>Existing</td>
<td>accelerate versus standard [epirubicin].{compound_color} follow by cyclophosphamide , methotrexate , and fluorouracil or capecitabine as adjuvant therapy for [breast cancer].{disease_color} in the randomised uk tact2 trial ( cruk/05/19 ) : a multicentre , phase 3 , open - label , randomise , control trial</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Paclitaxel</td>
<td>breast cancer</td>
<td>1.000</td>
<td>0.952</td>
<td>10255</td>
<td>Existing</td>
<td>sunitinib plus [paclitaxel].{compound_color} versus bevacizumab plus paclitaxel for first - line treatment of patients with [advanced breast cancer].{disease_color} : a phase iii , randomized , open - label trial</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Anastrozole</td>
<td>breast cancer</td>
<td>0.996</td>
<td>0.952</td>
<td>2364</td>
<td>Existing</td>
<td>a european organisation for research and treatment of cancer randomize , double - blind , placebo - control , multicentre [phase].{disease_color} ii trial of anastrozole in combination with [gefitinib or placebo in hormone].{compound_color} receptor - positive advanced breast cancer ( nct00066378 ) .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Gefitinib</td>
<td>lung cancer</td>
<td>1.000</td>
<td>0.950</td>
<td>11860</td>
<td>Existing</td>
<td>[gefitinib].{compound_color} versus placebo as maintenance therapy in patient with locally advanced or metastatic [non - small].{disease_color} - cell lung cancer ( inform ; c - tong 0804 ) : a multicentre , double - blind randomise phase 3 trial .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Docetaxel</td>
<td>prostate cancer</td>
<td>1.000</td>
<td>0.949</td>
<td>5614</td>
<td>Existing</td>
<td>ipilimumab versus placebo after radiotherapy in patient with metastatic castration - resistant [prostate cancer].{disease_color} that have progress after [docetaxel].{compound_color} chemotherapy ( ca184 - 043 ) : a multicentre , randomised , double - blind , phase 3 trial</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Sulfamethazine</td>
<td>lung cancer</td>
<td>0.611</td>
<td>0.949</td>
<td>4</td>
<td>Novel</td>
<td>[tmp].{compound_color} / smz ( 320/1600 mg / day ) treatment be compare to placebo in a double - blind , randomized trial in [patient with newly diagnose].{disease_color} small cell carcinoma of the lung during the initial course of chemotherapy with cyclophosphamide , doxorubicin , and etoposide .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>D-Tyrosine</td>
<td>EGFR</td>
<td>0.601</td>
<td>0.876</td>
<td>3423</td>
<td>Novel</td>
<td>amphiregulin ( ar ) and heparin - binding egf - like growth factor ( hb - [egf].{gene_color} ) bind and activate the egfr while heregulin ( hrg [) act ].{compound_color} through the p185erbb-2 and p180erbb-4 tyrosine kinase .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>Phosphonotyrosine</td>
<td>ANK3</td>
<td>0.004</td>
<td>0.865</td>
<td>1</td>
<td>Novel</td>
<td>at least two domain of p85 can bind to [ank3 ].{gene_color} , and the interaction involve the p85 c - sh2 domain be find to be [phosphotyrosine].{compound_color} - independent .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>Adenosine</td>
<td>ABCC8</td>
<td>0.891</td>
<td>0.860</td>
<td>353</td>
<td>Novel</td>
<td>sulfonylurea act by inhibition of [beta - cell ].{compound_color} adenosine triphosphate - dependent potassium ( k(atp ) ) channel after bind to the sulfonylurea subunit 1 [receptor ( ].{gene_color} sur1 ) .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>D-Tyrosine</td>
<td>AREG</td>
<td>0.891</td>
<td>0.857</td>
<td>22</td>
<td>Novel</td>
<td>amphiregulin ( [ar ) ].{gene_color} and heparin - binding egf - like growth factor ( hb - egf ) bind and activate the egfr while heregulin ( hrg [) act ].{compound_color} through the p185erbb-2 and p180erbb-4 tyrosine kinase .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>D-Tyrosine</td>
<td>EGF</td>
<td>0.602</td>
<td>0.856</td>
<td>389</td>
<td>Novel</td>
<td>upon activation of the receptor for the epidermal growth factor ( [egfr ) ].{gene_color} , sprouty2 undergoe phosphorylation at a conserve [tyrosine ].{compound_color} that recruit the src homology 2 domain of c - cbl .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>D-Tyrosine</td>
<td>CSF1</td>
<td>0.101</td>
<td>0.854</td>
<td>106</td>
<td>Novel</td>
<td>as a member of the subclass iii family of receptor [tyrosine].{compound_color} kinase , kit be closely relate to the receptor for platelet derive growth factor alpha and beta ( pdgf - a and b [) , macrophage colony ].{gene_color} stimulate factor ( m - csf ) , and flt3 ligand .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>D-Tyrosine</td>
<td>ERBB4</td>
<td>0.101</td>
<td>0.848</td>
<td>115</td>
<td>Novel</td>
<td>the efgr family be a group of four structurally similar [tyrosine ].{compound_color} kinase ( egfr , her2 / neu , erbb-3 [, and erbb-4].{gene_color} ) that dimerize on bind with a number of ligand , include egf and transform growth factor alpha .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>D-Tyrosine</td>
<td>EGFR</td>
<td>0.969</td>
<td>0.848</td>
<td>3423</td>
<td>Novel</td>
<td>the [epidermal growth factor receptor ].{gene_color} be a member of type - -pron- growth factor receptor [family ].{compound_color} with tyrosine kinase activity that be activate follow the binding of multiple cognate ligand .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>D-Tyrosine</td>
<td>VAV1</td>
<td>0.601</td>
<td>0.842</td>
<td>187</td>
<td>Novel</td>
<td>stimulation of quiescent rodent fibroblast with either epidermal or platelet - derive growth factor induce an increase affinity of vav for cbl - b and result in the [subsequent ].{gene_color} formation of a vav - [dependent ].{compound_color} trimeric complex with the ligand - stimulate tyrosine kinase receptor .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>Tretinoin</td>
<td>RORB</td>
<td>0.601</td>
<td>0.840</td>
<td>7</td>
<td>Novel</td>
<td>the retinoid z receptor beta ( [rzr beta ) ].{gene_color} , an orphan receptor , be a member of the [retinoic acid].{compound_color} receptor ( rar)/thyroid hormone receptor ( tr ) subfamily of nuclear receptor .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>L-Tryptophan</td>
<td>TACR1</td>
<td>0.891</td>
<td>0.839</td>
<td>4</td>
<td>Novel</td>
<td>these result suggest that the [tryptophan ].{compound_color} and quinuclidine series of nk-1 antagonist bind to similar bind site on the human [nk-1 receptor ].{gene_color} .</td>
</tr>
<tr class="odd">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>CYSLTR2</td>
<td>CYSLTR2</td>
<td>0.967</td>
<td>0.564</td>
<td>37</td>
<td>Novel</td>
<td>the bind pocket of [cyslt2 ].{gene2_color} receptor and the proposition of the interaction mode between [cyslt2 ].{gene1_color} and hami3379 be identify .</td>
</tr>
<tr class="even">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>RXRA</td>
<td>PPARA</td>
<td>1.000</td>
<td>0.563</td>
<td>143</td>
<td>Novel</td>
<td>after bind ligand , the [ppar ].{gene2_color} - y receptor heterodimerize [with ].{gene1_color} the rxr receptor .</td>
</tr>
<tr class="odd">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>RXRA</td>
<td>RXRA</td>
<td>0.824</td>
<td>0.551</td>
<td>1101</td>
<td>Existing</td>
<td>nuclear hormone receptor , for example , bind either as homodimer or as heterodimer with [retinoid x receptor ].{gene1_color} ( [rxr ) ].{gene2_color} to half - site repeat that be stabilize by protein - protein interaction mediate by residue within both the dna- and ligand - bind domain .</td>
</tr>
<tr class="even">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>ADRBK1</td>
<td>ADRA2A</td>
<td>0.822</td>
<td>0.543</td>
<td>3</td>
<td>Novel</td>
<td>mutation of these residue within the [holo - alpha(2a)ar diminish grk2-promoted].{gene2_color} phosphorylation [of ].{gene1_color} the receptor as well as the ability of the kinase to be activate by receptor binding .</td>
</tr>
<tr class="odd">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>ESRRA</td>
<td>ESRRA</td>
<td>0.001</td>
<td>0.531</td>
<td>308</td>
<td>Existing</td>
<td>the crystal structure of the ligand bind domain ( lbd ) of the estrogen - relate receptor [alpha ].{gene2_color} ( [erralpha , ].{gene1_color} nr3b1 ) complexe with a coactivator peptide from peroxisome proliferator - activate receptor coactivator-1alpha ( pgc-1alpha ) reveal a transcriptionally active conformation in the absence of a ligand .</td>
</tr>
<tr class="even">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>GP1BA</td>
<td>VWF</td>
<td>0.518</td>
<td>0.527</td>
<td>144</td>
<td>Existing</td>
<td>these finding indicate the novel bind site require for [vwf ].{gene2_color} binding of human [gpibalpha ].{gene1_color} .</td>
</tr>
<tr class="odd">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>NR2C1</td>
<td>NR2C1</td>
<td>0.027</td>
<td>0.522</td>
<td>26</td>
<td>Novel</td>
<td>the human [testicular receptor 2].{gene1_color} ( [tr2 )].{gene2_color} , a member of the nuclear hormone receptor superfamily , have no identify ligand yet .</td>
</tr>
<tr class="even">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>NCOA1</td>
<td>ESRRG</td>
<td>0.992</td>
<td>0.518</td>
<td>1</td>
<td>Novel</td>
<td>the crystal structure of the ligand bind domain ( lbd ) of the estrogen - relate receptor [3 (].{gene2_color} err3 ) complexe with a steroid receptor [coactivator-1 (].{gene1_color} src-1 ) peptide reveal a transcriptionally active conformation in absence of any ligand .</td>
</tr>
<tr class="odd">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>PPARG</td>
<td>PPARG</td>
<td>0.824</td>
<td>0.504</td>
<td>2497</td>
<td>Existing</td>
<td>although these agent can bind and activate an orphan nuclear receptor , [peroxisome proliferator - activate].{gene2_color} receptor [gamma ( ].{gene1_color} ppargamma ) , there be no direct evidence to conclusively implicate this receptor in the regulation of mammalian glucose homeostasis .</td>
</tr>
<tr class="even">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>ESR2</td>
<td>ESR1</td>
<td>0.995</td>
<td>0.503</td>
<td>1715</td>
<td>Novel</td>
<td>ligand bind experiment with purify [er alpha].{gene2_color} and [er beta].{gene1_color} confirm that the two phytoestrogen be er ligand .</td>
</tr>
<tr class="odd">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>FGFR2</td>
<td>FGFR2</td>
<td>1.000</td>
<td>0.501</td>
<td>584</td>
<td>Existing</td>
<td>receptor modeling of [kgfr].{gene1_color} be use to identify selective kgfr tyrosine kinase ( tk ) inhibitor molecule that have the potential to bind selectively to the [kgfr].{gene2_color} .</td>
</tr>
</tbody>
</table>
</div>
<!-- default theme -->

<style>
  /* import google fonts */
  @import url("https://fonts.googleapis.com/css?family=Open+Sans:400,600,700");
  @import url("https://fonts.googleapis.com/css?family=Source+Code+Pro");

  /* -------------------------------------------------- */
  /* global */
  /* -------------------------------------------------- */

  /* all elements */
  * {
    /* force sans-serif font unless specified otherwise */
    font-family: "Open Sans", "Helvetica", sans-serif;

    /* prevent text inflation on some mobile browsers */
    -webkit-text-size-adjust: none !important;
    -moz-text-size-adjust: none !important;
    -o-text-size-adjust: none !important;
    text-size-adjust: none !important;
  }

  @media only screen {
    /* "page" element */
    body {
      position: relative;
      box-sizing: border-box;
      font-size: 12pt;
      line-height: 1.5;
      max-width: 8.5in;
      margin: 20px auto;
      padding: 40px;
      border-radius: 5px;
      border: solid 1px #bdbdbd;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      background: #ffffff;
    }
  }

  /* when on screen < 8.5in wide */
  @media only screen and (max-width: 8.5in) {
    /* "page" element */
    body {
      padding: 20px;
      margin: 0;
      border-radius: 0;
      border: none;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05) inset;
      background: none;
    }
  }

  /* -------------------------------------------------- */
  /* headings */
  /* -------------------------------------------------- */

  /* all headings */
  h1,
  h2,
  h3,
  h4,
  h5,
  h6 {
    margin: 20px 0;
    padding: 0;
    font-weight: bold;
  }

  /* biggest heading */
  h1 {
    margin: 40px 0;
    text-align: center;
  }

  /* second biggest heading */
  h2 {
    margin-top: 30px;
    padding-bottom: 5px;
    border-bottom: solid 1px #bdbdbd;
  }

  /* heading font sizes */
  h1 {
    font-size: 2em;
  }
  h2 {
    font-size: 1.5em;
  }
  h3 {
    font-size: 1.35em;
  }
  h4 {
    font-size: 1.25em;
  }
  h5 {
    font-size: 1.15em;
  }
  h6 {
    font-size: 1em;
  }

  /* -------------------------------------------------- */
  /* manuscript header */
  /* -------------------------------------------------- */

  /* manuscript title */
  header > h1 {
    margin: 0;
  }

  /* manuscript title caption text (ie "automatically generated on") */
  header + p {
    text-align: center;
    margin-top: 10px;
  }

  /* -------------------------------------------------- */
  /* text elements */
  /* -------------------------------------------------- */

  /* links */
  a {
    color: #2196f3;
    overflow-wrap: break-word;
  }

  /* superscripts and subscripts */
  sub,
  sup {
    /* prevent from affecting line height */
    line-height: 0;
  }

  /* unordered and ordered lists*/
  ul,
  ol {
    padding-left: 20px;
  }

  /* class for styling text semibold */
  .semibold {
    font-weight: 600;
  }

  /* class for styling elements horizontally left aligned */
  .left {
    display: block;
    text-align: left;
    margin-left: auto;
    margin-right: 0;
    justify-content: left;
  }

  /* class for styling elements horizontally centered */
  .center {
    display: block;
    text-align: center;
    margin-left: auto;
    margin-right: auto;
    justify-content: center;
  }

  /* class for styling elements horizontally right aligned */
  .right {
    display: block;
    text-align: right;
    margin-left: 0;
    margin-right: auto;
    justify-content: right;
  }

  /* -------------------------------------------------- */
  /* section elements */
  /* -------------------------------------------------- */

  /* horizontal divider line */
  hr {
    border: none;
    height: 1px;
    background: #bdbdbd;
  }

  /* paragraphs, horizontal dividers, figures, tables, code */
  p,
  hr,
  figure,
  table,
  pre {
    /* treat all as "paragraphs", with consistent vertical margins */
    margin-top: 20px;
    margin-bottom: 20px;
  }

  /* -------------------------------------------------- */
  /* figures */
  /* -------------------------------------------------- */

  /* figure */
  figure {
    max-width: 100%;
    margin-left: auto;
    margin-right: auto;
  }

  /* figure caption */
  figcaption {
    padding: 0;
    padding-top: 10px;
  }

  /* figure image element */
  figure > img,
  figure > svg {
    max-width: 100%;
    display: block;
    margin-left: auto;
    margin-right: auto;
  }

  /* figure auto-number */
  img + figcaption > span:first-of-type,
  svg + figcaption > span:first-of-type {
    font-weight: bold;
    margin-right: 5px;
  }

  /* -------------------------------------------------- */
  /* tables */
  /* -------------------------------------------------- */

  /* table */
  table {
    border-collapse: collapse;
    border-spacing: 0;
    width: 100%;
    margin-left: auto;
    margin-right: auto;
  }

  /* table cells */
  th,
  td {
    border: solid 1px #bdbdbd;
    padding: 10px;
    /* squash table if too wide for page by forcing line breaks */
    overflow-wrap: break-word;
    word-break: break-word;
  }

  /* header row and even rows */
  th,
  tr:nth-child(2n) {
    background-color: #fafafa;
  }

  /* odd rows */
  tr:nth-child(2n + 1) {
    background-color: #ffffff;
  }

  /* table caption */
  caption {
    text-align: left;
    padding: 0;
    padding-bottom: 10px;
  }

  /* table auto-number */
  table > caption > span:first-of-type {
    font-weight: bold;
    margin-right: 5px;
  }

  /* -------------------------------------------------- */
  /* code */
  /* -------------------------------------------------- */

  /* multi-line code block */
  pre {
    padding: 10px;
    background-color: #eeeeee;
    color: #000000;
    border-radius: 5px;
    break-inside: avoid;
    text-align: left;
  }

  /* inline code, ie code within normal text */
  :not(pre) > code {
    padding: 0 4px;
    background-color: #eeeeee;
    color: #000000;
    border-radius: 5px;
  }

  /* code text */
  /* apply all children, to reach syntax highlighting sub-elements */
  code,
  code * {
    /* force monospace font */
    font-family: "Source Code Pro", "Courier New", monospace;
  }

  /* -------------------------------------------------- */
  /* quotes */
  /* -------------------------------------------------- */

  /* quoted text */
  blockquote {
    margin: 0;
    padding: 0;
    border-left: 4px solid #bdbdbd;
    padding-left: 16px;
    break-inside: avoid;
  }

  /* -------------------------------------------------- */
  /* banners */
  /* -------------------------------------------------- */

  /* info banners */
  .banner {
    box-sizing: border-box;
    display: block;
    position: relative;
    width: 100%;
    margin-top: 20px;
    margin-bottom: 20px;
    padding: 20px;
    text-align: center;
  }

  /* paragraph in banner */
  .banner > p {
    margin: 0;
  }

  /* -------------------------------------------------- */
  /* highlight colors */
  /* -------------------------------------------------- */

  .white {
    background: #ffffff;
  }
  .lightgrey {
    background: #eeeeee;
  }
  .grey {
    background: #757575;
  }
  .darkgrey {
    background: #424242;
  }
  .black {
    background: #000000;
  }
  .lightred {
    background: #ffcdd2;
  }
  .lightyellow {
    background: #ffecb3;
  }
  .lightgreen {
    background: #dcedc8;
  }
  .lightblue {
    background: #e3f2fd;
  }
  .lightpurple {
    background: #f3e5f5;
  }
  .red {
    background: #f44336;
  }
  .orange {
    background: #ff9800;
  }
  .yellow {
    background: #ffeb3b;
  }
  .green {
    background: #4caf50;
  }
  .blue {
    background: #2196f3;
  }
  .purple {
    background: #9c27b0;
  }
  .white,
  .lightgrey,
  .lightred,
  .lightyellow,
  .lightgreen,
  .lightblue,
  .lightpurple,
  .orange,
  .yellow,
  .white a,
  .lightgrey a,
  .lightred a,
  .lightyellow a,
  .lightgreen a,
  .lightblue a,
  .lightpurple a,
  .orange a,
  .yellow a {
    color: #000000;
  }
  .grey,
  .darkgrey,
  .black,
  .red,
  .green,
  .blue,
  .purple,
  .grey a,
  .darkgrey a,
  .black a,
  .red a,
  .green a,
  .blue a,
  .purple a {
    color: #ffffff;
  }

  /* -------------------------------------------------- */
  /* buttons */
  /* -------------------------------------------------- */

  /* class for styling links like buttons */
  .button {
    display: inline-flex;
    justify-content: center;
    align-items: center;
    margin: 5px;
    padding: 10px 20px;
    font-size: 0.75em;
    font-weight: 600;
    text-transform: uppercase;
    text-decoration: none;
    letter-spacing: 1px;
    background: none;
    color: #2196f3;
    border: solid 1px #bdbdbd;
    border-radius: 5px;
  }

  /* buttons when hovered */
  .button:hover:not([disabled]),
  .icon_button:hover:not([disabled]) {
    cursor: pointer;
    background: #f5f5f5;
  }

  /* buttons when disabled */
  .button[disabled],
  .icon_button[disabled] {
    opacity: 0.35;
    pointer-events: none;
  }

  /* class for styling buttons containg only single icon */
  .icon_button {
    display: inline-flex;
    justify-content: center;
    align-items: center;
    text-decoration: none;
    margin: 0;
    padding: 0;
    background: none;
    border-radius: 5px;
    border: none;
    width: 20px;
    height: 20px;
    min-width: 20px;
    min-height: 20px;
  }

  /* icon button inner svg image */
  .icon_button > svg {
    height: 16px;
  }

  /* -------------------------------------------------- */
  /* icons */
  /* -------------------------------------------------- */

  /* class for styling icons inline with text */
  .inline_icon {
    height: 1em;
    position: relative;
    top: 0.125em;
  }

  /* -------------------------------------------------- */
  /* references */
  /* -------------------------------------------------- */

  .csl-entry {
    margin-top: 15px;
    margin-bottom: 15px;
  }

  /* -------------------------------------------------- */
  /* print control */
  /* -------------------------------------------------- */

  @media print {
    @page {
      /* suggested printing margin */
      margin: 0.5in;
    }

    /* document and "page" elements */
    html,
    body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
    }

    /* "page" element */
    body {
      font-size: 11pt !important;
      line-height: 1.35;
    }

    /* all headings */
    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      margin: 15px 0;
    }

    /* figures and tables */
    figure,
    table {
      font-size: 0.85em;
    }

    /* table cells */
    th,
    td {
      padding: 5px;
    }

    /* shrink font awesome icons */
    i.fas,
    i.fab,
    i.far,
    i.fal {
      transform: scale(0.85);
    }

    /* decrease banner margins */
    .banner {
      margin-top: 15px;
      margin-bottom: 15px;
      padding: 15px;
    }

    /* class for centering an element vertically on its own page */
    .page_center {
      margin: auto;
      width: 100%;
      height: 100%;
      display: flex;
      align-items: center;
      vertical-align: middle;
      break-before: page;
      break-after: page;
    }

    /* always insert a page break before the element */
    .page_break_before {
      break-before: page;
    }

    /* always insert a page break after the element */
    .page_break_after {
      break-after: page;
    }

    /* avoid page break before the element */
    .page_break_before_avoid {
      break-before: avoid;
    }

    /* avoid page break after the element */
    .page_break_after_avoid {
      break-after: avoid;
    }

    /* avoid page break inside the element */
    .page_break_inside_avoid {
      break-inside: avoid;
    }
  }

  /* -------------------------------------------------- */
  /* override pandoc css quirks */
  /* -------------------------------------------------- */

  .sourceCode {
    /* prevent unsightly overflow in wide code blocks */
    overflow: auto !important;
  }

  div.sourceCode {
    /* prevent background fill on top-most code block  container */
    background: none !important;
  }

  .sourceCode * {
    /* force consistent line spacing */
    line-height: 1.5 !important;
  }

  div.sourceCode {
    /* style code block margins same as <pre> element */
    margin-top: 20px;
    margin-bottom: 20px;
  }

  /* -------------------------------------------------- */
  /* tablenos */
  /* -------------------------------------------------- */

  /* tablenos wrapper */
  .tablenos {
    width: 100%;
    margin: 20px 0;
  }

  .tablenos > table {
    /* move margins from table to table_wrapper to allow margin collapsing */
    margin: 0;
  }

  @media only screen {
    /* tablenos wrapper */
    .tablenos {
      /* show scrollbar on tables if necessary to prevent overflow */
      overflow-x: auto !important;
    }

    .tablenos th,
    .tablenos td {
      overflow-wrap: unset !important;
      word-break: unset !important;
    }

    /* table in wrapper */
    .tablenos table,
    .tablenos table * {
      /* don't break table words */
      overflow-wrap: normal !important;
    }
  }
</style>
<!-- 
    Plugin Core

    Functions needed for and shared across all first-party plugins.
-->

<script>
  // get element that is target of hash (from link element or url)
  function getHashTarget(link) {
    const hash = link ? link.hash : window.location.hash;
    const id = hash.slice(1);
    let target = document.querySelector(`[id="${id}"]`);
    if (!target) return;

    // if figure or table, modify target to get expected element
    if (id.indexOf("fig:") === 0) target = target.querySelector("figure");
    if (id.indexOf("tbl:") === 0) target = target.querySelector("table");

    return target;
  }

  // get position/dimensions of element or viewport
  function getRectInView(element) {
    let rect = {};
    rect.left = 0;
    rect.top = 0;
    rect.right = document.documentElement.clientWidth;
    rect.bottom = document.documentElement.clientHeight;
    let style = {};

    if (element instanceof HTMLElement) {
      rect = element.getBoundingClientRect();
      style = window.getComputedStyle(element);
    }

    const margin = {};
    margin.left = parseFloat(style.marginLeftWidth) || 0;
    margin.top = parseFloat(style.marginTopWidth) || 0;
    margin.right = parseFloat(style.marginRightWidth) || 0;
    margin.bottom = parseFloat(style.marginBottomWidth) || 0;

    const border = {};
    border.left = parseFloat(style.borderLeftWidth) || 0;
    border.top = parseFloat(style.borderTopWidth) || 0;
    border.right = parseFloat(style.borderRightWidth) || 0;
    border.bottom = parseFloat(style.borderBottomWidth) || 0;

    const newRect = {};
    newRect.left = rect.left + margin.left + border.left;
    newRect.top = rect.top + margin.top + border.top;
    newRect.right = rect.right + margin.right + border.right;
    newRect.bottom = rect.bottom + margin.bottom + border.bottom;
    newRect.width = newRect.right - newRect.left;
    newRect.height = newRect.bottom - newRect.top;

    return newRect;
  }

  // get position of element relative to page
  function getRectInPage(element) {
    const rect = getRectInView(element);
    const body = getRectInView(document.body);

    const newRect = {};
    newRect.left = rect.left - body.left;
    newRect.top = rect.top - body.top;
    newRect.right = rect.right - body.left;
    newRect.bottom = rect.bottom - body.top;
    newRect.width = rect.width;
    newRect.height = rect.height;

    return newRect;
  }

  // get closest element before specified element that matches query
  function firstBefore(element, query) {
    while (element && element !== document.body && !element.matches(query))
      element = element.previousElementSibling || element.parentNode;

    return element;
  }

  // check if element is part of collapsed heading
  function isCollapsed(element) {
    while (element && element !== document.body) {
      if (element.dataset.collapsed === "true") return true;
      element = element.parentNode;
    }
    return false;
  }

  // expand any collapsed parent containers of element if necessary
  function expandElement(element) {
    if (isCollapsed(element)) {
      // accordion plugin
      const heading = firstBefore(element, "h2");
      if (heading) heading.click();
      // details/summary HTML element
      const summary = firstBefore(element, "summary");
      if (summary) summary.click();
    }
  }

  // scroll to and focus element
  function goToElement(element, offset) {
    // expand accordion section if collapsed
    expandElement(element);
    const y =
      getRectInView(element).top -
      getRectInView(document.documentElement).top -
      (offset || 0);

    // trigger any function listening for "onscroll" event
    window.dispatchEvent(new Event("scroll"));
    window.scrollTo(0, y);
    document.activeElement.blur();
    element.focus();
  }

  // get list of elements after a start element up to element matching query
  function nextUntil(element, query, exclude) {
    const elements = [];
    while (((element = element.nextElementSibling), element)) {
      if (element.matches(query)) break;
      if (!element.matches(exclude)) elements.push(element);
    }
    return elements;
  }
</script>
<!--
  Accordion Plugin

  Allows sections of content under h2 headings to be collapsible.
-->

<script type="module">
  // whether to always start expanded ('false'), always start collapsed
  // ('true'), or start collapsed when screen small ('auto')
  const startCollapsed = "auto";

  // start script
  function start() {
    // run through each <h2> heading
    const headings = document.querySelectorAll("h2");
    for (const heading of headings) {
      addArrow(heading);

      // start expanded/collapsed based on option
      if (
        startCollapsed === "true" ||
        (startCollapsed === "auto" && isSmallScreen()) ||
        heading.dataset.collapsed === "true"
      )
        collapseHeading(heading);
      else expandElement(heading);
    }

    // attach hash change listener to window
    window.addEventListener("hashchange", onHashChange);
  }

  // when hash (eg manuscript.html#introduction) changes
  function onHashChange() {
    const target = getHashTarget();
    if (target) goToElement(target);
  }

  // add arrow to heading
  function addArrow(heading) {
    // add arrow button
    const arrow = document.createElement("button");
    arrow.innerHTML = document.querySelector(".icon_angle_down").innerHTML;
    arrow.classList.add("icon_button", "accordion_arrow");
    heading.insertBefore(arrow, heading.firstChild);

    // attach click listener to heading and button
    heading.addEventListener("click", onHeadingClick);
    arrow.addEventListener("click", onArrowClick);
  }

  // determine if on mobile-like device with small screen
  function isSmallScreen() {
    return Math.min(window.innerWidth, window.innerHeight) < 480;
  }

  // when <h2> heading is clicked
  function onHeadingClick(event) {
    // only collapse if <h2> itself is target of click (eg, user did
    // not click on anchor within <h2>)
    if (event.target === this) toggleCollapse(this);
  }

  // when arrow button is clicked
  function onArrowClick() {
    toggleCollapse(this.parentNode);
  }

  // collapse section if expanded, expand if collapsed
  function toggleCollapse(heading) {
    if (heading.dataset.collapsed === "false") collapseHeading(heading);
    else expandElement(heading);
  }

  // elements to exclude from collapse, such as table of contents panel,
  // hypothesis panel, etc
  const exclude = "#toc_panel, div.annotator-frame, #lightbox_overlay";

  // collapse section
  function collapseHeading(heading) {
    heading.setAttribute("data-collapsed", "true");
    const children = getChildren(heading);
    for (const child of children) child.setAttribute("data-collapsed", "true");
  }

  // expand section
  function expandElement(heading) {
    heading.setAttribute("data-collapsed", "false");
    const children = getChildren(heading);
    for (const child of children) child.setAttribute("data-collapsed", "false");
  }

  // get list of elements between this <h2> and next <h2> or <h1>
  // ("children" of the <h2> section)
  function getChildren(heading) {
    return nextUntil(heading, "h2, h1", exclude);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- angle down icon -->

<template class="icon_angle_down">
  <!-- modified from: https://fontawesome.com/icons/angle-down -->
  <svg width="16" height="16" viewBox="0 0 448 512">
    <path
      fill="currentColor"
      d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* accordion arrow button */
    .accordion_arrow {
      margin-right: 10px;
    }

    /* arrow icon when <h2> data-collapsed attribute true */
    h2[data-collapsed="true"] > .accordion_arrow > svg {
      transform: rotate(-90deg);
    }

    /* all elements (except <h2>'s) when data-collapsed attribute true */
    *:not(h2)[data-collapsed="true"] {
      display: none;
    }

    /* accordion arrow button when hovered and <h2>'s when hovered */
    .accordion_arrow:hover,
    h2[data-collapsed="true"]:hover,
    h2[data-collapsed="false"]:hover {
      cursor: pointer;
    }
  }

  /* always hide accordion arrow button on print */
  @media only print {
    .accordion_arrow {
      display: none;
    }
  }
</style>
<!--
  Anchors Plugin

  Adds an anchor next to each of a certain type of element that provides a
  human-readable url to that specific item/position in the document (e.g.
  "manuscript.html#abstract"). It also makes it such that scrolling out of view
  of a target removes its identifier from the url.
-->

<script type="module">
  // which types of elements to add anchors next to, in "document.querySelector"
  // format
  const typesQuery =
    'h1, h2, h3, div[id^="fig:"], div[id^="tbl:"], span[id^="eq:"]';

  // start script
  function start() {
    // add anchor to each element of specified types
    const elements = document.querySelectorAll(typesQuery);
    for (const element of elements) addAnchor(element);

    // attach scroll listener to window
    window.addEventListener("scroll", onScroll);
  }

  // when window is scrolled
  function onScroll() {
    // if url has hash and user has scrolled out of view of hash
    // target, remove hash from url
    const tolerance = 100;
    const target = getHashTarget();
    if (target) {
      if (
        target.getBoundingClientRect().top > window.innerHeight + tolerance ||
        target.getBoundingClientRect().bottom < 0 - tolerance
      )
        history.pushState(null, null, " ");
    }
  }

  // add anchor to element
  function addAnchor(element) {
    let addTo; // element to add anchor button to

    // if figure or table, modify withId and addTo to get expected
    // elements
    if (element.id.indexOf("fig:") === 0) {
      addTo = element.querySelector("figcaption");
    } else if (element.id.indexOf("tbl:") === 0) {
      addTo = element.querySelector("caption");
    } else if (element.id.indexOf("eq:") === 0) {
      addTo = element.querySelector(".eqnos-number");
    }

    addTo = addTo || element;
    const id = element.id || null;

    // do not add anchor if element doesn't have assigned id.
    // id is generated by pandoc and is assumed to be unique and
    // human-readable
    if (!id) return;

    // create anchor button
    const anchor = document.createElement("a");
    anchor.innerHTML = document.querySelector(".icon_link").innerHTML;
    anchor.title = "Link to this part of the document";
    anchor.classList.add("icon_button", "anchor");
    anchor.dataset.ignore = "true";
    anchor.href = "#" + id;
    addTo.appendChild(anchor);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- link icon -->

<template class="icon_link">
  <!-- modified from: https://fontawesome.com/icons/link -->
  <svg width="16" height="16" viewBox="0 0 512 512">
    <path
      fill="currentColor"
      d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* anchor button */
    .anchor {
      opacity: 0;
      margin-left: 5px;
    }

    /* anchor buttons within <h2>'s */
    h2 .anchor {
      margin-left: 10px;
    }

    /* anchor buttons when hovered/focused and anything containing an anchor button when hovered */
    *:hover > .anchor,
    .anchor:hover,
    .anchor:focus {
      opacity: 1;
    }

    /* anchor button when hovered */
    .anchor:hover {
      cursor: pointer;
    }
  }

  /* always show anchor button on devices with no mouse/hover ability */
  @media (hover: none) {
    .anchor {
      opacity: 1;
    }
  }

  /* always hide anchor button on print */
  @media only print {
    .anchor {
      display: none;
    }
  }
</style>
<!-- 
    Attributes Plugin

    Allows arbitrary HTML attributes to be attached to (almost) any element.
    Place an HTML comment inside or next to the desired element with the content:
    $attribute="value"
-->

<script type="module">
  // start script
  function start() {
    // get list of comments in document
    const comments = findComments();

    for (const comment of comments)
      if (comment.parentElement)
        addAttributes(comment.parentElement, comment.nodeValue.trim());
  }

  // add html attributes to specified element based on string of
  // html attributes and values
  function addAttributes(element, text) {
    // regex's for finding attribute/value pairs in the format of
    // attribute="value" or attribute='value
    const regex2 = /\$([a-zA-Z\-]+)?=\"(.+?)\"/;
    const regex1 = /\$([a-zA-Z\-]+)?=\'(.+?)\'/;

    // loop through attribute/value pairs
    let match;
    while ((match = text.match(regex2) || text.match(regex1))) {
      // get attribute and value from regex capture groups
      let attribute = match[1];
      let value = match[2];

      // remove from string
      text = text.substring(match.index + match[0].length);

      if (!attribute || !value) break;

      // set attribute of parent element
      try {
        element.setAttribute(attribute, value);
      } catch (error) {
        console.log(error);
      }

      // special case for colspan
      if (attribute === "colspan") removeTableCells(element, value);
    }
  }

  // get list of comment elements in document
  function findComments() {
    const comments = [];

    // iterate over comment nodes in document
    function acceptNode(node) {
      return NodeFilter.FILTER_ACCEPT;
    }
    const iterator = document.createNodeIterator(
      document.body,
      NodeFilter.SHOW_COMMENT,
      acceptNode
    );
    let node;
    while ((node = iterator.nextNode())) comments.push(node);

    return comments;
  }

  // remove certain number of cells after specified cell
  function removeTableCells(cell, number) {
    number = parseInt(number);
    if (!number) return;

    // remove elements
    for (; number > 1; number--) {
      if (cell.nextElementSibling) cell.nextElementSibling.remove();
    }
  }

  // start script on DOMContentLoaded instead of load to ensure this plugins
  // runs before other plugins
  window.addEventListener("DOMContentLoaded", start);
</script>
<!--
  Jump to First Plugin

  Adds a button next to each reference entry, figure, and table that jumps the
  page to the first occurrence of a link to that item in the manuscript.
-->

<script type="module">
  // whether to add buttons next to reference entries
  const references = "true";
  // whether to add buttons next to figures
  const figures = "true";
  // whether to add buttons next to tables
  const tables = "true";

  // start script
  function start() {
    if (references !== "false")
      makeButtons(`div[id^="ref-"]`, ".csl-left-margin", "reference");
    if (figures !== "false")
      makeButtons(`div[id^="fig:"]`, "figcaption", "figure");
    if (tables !== "false") makeButtons(`div[id^="tbl:"]`, "caption", "table");
  }

  // when jump button clicked
  function onButtonClick() {
    const first = getFirstOccurrence(this.dataset.id);
    if (!first) return;

    // update url hash so navigating "back" in history will return user to button
    window.location.hash = this.dataset.id;
    // scroll to link
    const timeout = function () {
      goToElement(first, window.innerHeight * 0.5);
    };
    window.setTimeout(timeout, 0);
  }

  // get first occurrence of link to item in document
  function getFirstOccurrence(id) {
    let query = "a";
    query += '[href="#' + id + '"]';
    // exclude buttons, anchor links, toc links, etc
    query += ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    return document.querySelector(query);
  }

  // add button next to each reference entry, figure, or table
  function makeButtons(query, containerQuery, subject) {
    const elements = document.querySelectorAll(query);
    for (const element of elements) {
      const id = element.id;
      const buttonContainer = element.querySelector(containerQuery);
      const first = getFirstOccurrence(id);

      // if can't find link to reference or place to put button, ignore
      if (!first || !buttonContainer) continue;

      // make jump button
      let button = document.createElement("button");
      button.classList.add("icon_button", "jump_arrow");
      button.title = `Jump to the first occurrence of this ${subject} in the document`;
      const icon = document.querySelector(".icon_angle_double_up");
      button.innerHTML = icon.innerHTML;
      button.dataset.id = id;
      button.dataset.ignore = "true";
      button.addEventListener("click", onButtonClick);
      buttonContainer.prepend(button);
    }
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- angle double up icon -->

<template class="icon_angle_double_up">
  <!-- modified from: https://fontawesome.com/icons/angle-double-up -->
  <svg width="16" height="16" viewBox="0 0 320 512">
    <path
      fill="currentColor"
      d="M177 255.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 351.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 425.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1zm-34-192L7 199.7c-9.4 9.4-9.4 24.6 0 33.9l22.6 22.6c9.4 9.4 24.6 9.4 33.9 0l96.4-96.4 96.4 96.4c9.4 9.4 24.6 9.4 33.9 0l22.6-22.6c9.4-9.4 9.4-24.6 0-33.9l-136-136c-9.2-9.4-24.4-9.4-33.8 0z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* jump button */
    .jump_arrow {
      position: relative;
      top: 0.125em;
      margin-right: 5px;
    }
  }

  /* always hide jump button on print */
  @media only print {
    .jump_arrow {
      display: none;
    }
  }
</style>
<!-- 
    Lightbox Plugin

    Makes it such that when a user clicks on an image, the image fills the
    screen and the user can pan/drag/zoom the image and navigate between other
    images in the document.
-->

<script type="module">
  // list of possible zoom/scale factors
  const zooms =
    "0.1, 0.25, 0.333333, 0.5, 0.666666, 0.75, 1, 1.25, 1.5, 1.75, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8";
  // whether to fit image to view ('fit'), display at 100% and shrink if
  // necessary ('shrink'), or always display at 100% ('100')
  const defaultZoom = "fit";
  // whether to zoom in/out toward center of view ('true') or mouse ('false')
  const centerZoom = "false";

  // start script
  function start() {
    // run through each <img> element
    const imgs = document.querySelectorAll("figure > img");
    let count = 1;
    for (const img of imgs) {
      img.classList.add("lightbox_document_img");
      img.dataset.number = count;
      img.dataset.total = imgs.length;
      img.addEventListener("click", openLightbox);
      count++;
    }

    // attach mouse and key listeners to window
    window.addEventListener("mousemove", onWindowMouseMove);
    window.addEventListener("keyup", onKeyUp);
  }

  // when mouse is moved anywhere in window
  function onWindowMouseMove(event) {
    window.mouseX = event.clientX;
    window.mouseY = event.clientY;
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    switch (event.key) {
      // trigger click of prev button
      case "ArrowLeft":
        const prevButton = document.getElementById("lightbox_prev_button");
        if (prevButton) prevButton.click();
        break;
      // trigger click of next button
      case "ArrowRight":
        const nextButton = document.getElementById("lightbox_next_button");
        if (nextButton) nextButton.click();
        break;
      // close on esc
      case "Escape":
        closeLightbox();
        break;
    }
  }

  // open lightbox
  function openLightbox() {
    const lightbox = makeLightbox(this);
    if (!lightbox) return;

    blurBody(lightbox);
    document.body.appendChild(lightbox);
  }

  // make lightbox
  function makeLightbox(img) {
    // delete lightbox if it exists, start fresh
    closeLightbox();

    // create screen overlay containing lightbox
    const overlay = document.createElement("div");
    overlay.id = "lightbox_overlay";

    // create image info boxes
    const numberInfo = document.createElement("div");
    const zoomInfo = document.createElement("div");
    numberInfo.id = "lightbox_number_info";
    zoomInfo.id = "lightbox_zoom_info";

    // create container for image
    const imageContainer = document.createElement("div");
    imageContainer.id = "lightbox_image_container";
    const lightboxImg = makeLightboxImg(
      img,
      imageContainer,
      numberInfo,
      zoomInfo
    );
    imageContainer.appendChild(lightboxImg);

    // create bottom container for caption and navigation buttons
    const bottomContainer = document.createElement("div");
    bottomContainer.id = "lightbox_bottom_container";
    const caption = makeCaption(img);
    const prevButton = makePrevButton(img);
    const nextButton = makeNextButton(img);
    bottomContainer.appendChild(prevButton);
    bottomContainer.appendChild(caption);
    bottomContainer.appendChild(nextButton);

    // attach top middle and bottom to overlay
    overlay.appendChild(numberInfo);
    overlay.appendChild(zoomInfo);
    overlay.appendChild(imageContainer);
    overlay.appendChild(bottomContainer);

    return overlay;
  }

  // make <img> object that is intuitively draggable and zoomable
  function makeLightboxImg(sourceImg, container, numberInfoBox, zoomInfoBox) {
    // create copy of source <img>
    const img = sourceImg.cloneNode(true);
    img.classList.remove("lightbox_document_img");
    img.removeAttribute("id");
    img.removeAttribute("width");
    img.removeAttribute("height");
    img.style.position = "unset";
    img.style.margin = "0";
    img.style.padding = "0";
    img.style.width = "";
    img.style.height = "";
    img.style.minWidth = "";
    img.style.minHeight = "";
    img.style.maxWidth = "";
    img.style.maxHeight = "";
    img.id = "lightbox_img";

    // build sorted list of zoomSteps
    const zoomSteps = zooms.split(/[^0-9.]/).map((step) => parseFloat(step));
    zoomSteps.sort((a, b) => a - b);

    // <img> object property variables
    let zoom = 1;
    let translateX = 0;
    let translateY = 0;
    let clickMouseX = undefined;
    let clickMouseY = undefined;
    let clickTranslateX = undefined;
    let clickTranslateY = undefined;

    updateNumberInfo();

    // update image numbers displayed in info box
    function updateNumberInfo() {
      numberInfoBox.innerHTML =
        sourceImg.dataset.number + " of " + sourceImg.dataset.total;
    }

    // update zoom displayed in info box
    function updateZoomInfo() {
      let zoomInfo = zoom * 100;
      if (!Number.isInteger(zoomInfo)) zoomInfo = zoomInfo.toFixed(2);
      zoomInfoBox.innerHTML = zoomInfo + "%";
    }

    // move to closest zoom step above current zoom
    const zoomIn = function () {
      for (const zoomStep of zoomSteps) {
        if (zoomStep > zoom) {
          zoom = zoomStep;
          break;
        }
      }
      updateTransform();
    };

    // move to closest zoom step above current zoom
    const zoomOut = function () {
      zoomSteps.reverse();
      for (const zoomStep of zoomSteps) {
        if (zoomStep < zoom) {
          zoom = zoomStep;
          break;
        }
      }
      zoomSteps.reverse();

      updateTransform();
    };

    // update display of <img> based on scale/translate properties
    const updateTransform = function () {
      // set transform
      img.style.transform =
        "translate(" +
        (translateX || 0) +
        "px," +
        (translateY || 0) +
        "px) scale(" +
        (zoom || 1) +
        ")";

      // get new width/height after scale
      const rect = img.getBoundingClientRect();
      // limit translate
      translateX = Math.max(translateX, -rect.width / 2);
      translateX = Math.min(translateX, rect.width / 2);
      translateY = Math.max(translateY, -rect.height / 2);
      translateY = Math.min(translateY, rect.height / 2);

      // set transform
      img.style.transform =
        "translate(" +
        (translateX || 0) +
        "px," +
        (translateY || 0) +
        "px) scale(" +
        (zoom || 1) +
        ")";

      updateZoomInfo();
    };

    // fit <img> to container
    const fit = function () {
      // no x/y offset, 100% zoom by default
      translateX = 0;
      translateY = 0;
      zoom = 1;

      // widths of <img> and container
      const imgWidth = img.naturalWidth;
      const imgHeight = img.naturalHeight;
      const containerWidth = parseFloat(
        window.getComputedStyle(container).width
      );
      const containerHeight = parseFloat(
        window.getComputedStyle(container).height
      );

      // how much zooming is needed to fit <img> to container
      const xRatio = imgWidth / containerWidth;
      const yRatio = imgHeight / containerHeight;
      const maxRatio = Math.max(xRatio, yRatio);
      const newZoom = 1 / maxRatio;

      // fit <img> to container according to option
      if (defaultZoom === "shrink") {
        if (maxRatio > 1) zoom = newZoom;
      } else if (defaultZoom === "fit") zoom = newZoom;

      updateTransform();
    };

    // when mouse wheel is rolled anywhere in container
    const onContainerWheel = function (event) {
      if (!event) return;

      // let ctrl + mouse wheel to zoom behave as normal
      if (event.ctrlKey) return;

      // prevent normal scroll behavior
      event.preventDefault();
      event.stopPropagation();

      // point around which to scale img
      const viewRect = container.getBoundingClientRect();
      const viewX = (viewRect.left + viewRect.right) / 2;
      const viewY = (viewRect.top + viewRect.bottom) / 2;
      const originX = centerZoom === "true" ? viewX : mouseX;
      const originY = centerZoom === "true" ? viewY : mouseY;

      // get point on image under origin
      const oldRect = img.getBoundingClientRect();
      const oldPercentX = (originX - oldRect.left) / oldRect.width;
      const oldPercentY = (originY - oldRect.top) / oldRect.height;

      // increment/decrement zoom
      if (event.deltaY < 0) zoomIn();
      if (event.deltaY > 0) zoomOut();

      // get offset between previous image point and origin
      const newRect = img.getBoundingClientRect();
      const offsetX = originX - (newRect.left + newRect.width * oldPercentX);
      const offsetY = originY - (newRect.top + newRect.height * oldPercentY);

      // translate image to keep image point under origin
      translateX += offsetX;
      translateY += offsetY;

      // perform translate
      updateTransform();
    };

    // when container is clicked
    function onContainerClick(event) {
      // if container itself is target of click, and not other
      // element above it
      if (event.target === this) closeLightbox();
    }

    // when mouse button is pressed on image
    const onImageMouseDown = function (event) {
      // store original mouse position relative to image
      clickMouseX = window.mouseX;
      clickMouseY = window.mouseY;
      clickTranslateX = translateX;
      clickTranslateY = translateY;
      event.stopPropagation();
      event.preventDefault();
    };

    // when mouse button is released anywhere in window
    const onWindowMouseUp = function (event) {
      // reset original mouse position
      clickMouseX = undefined;
      clickMouseY = undefined;
      clickTranslateX = undefined;
      clickTranslateY = undefined;

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("mouseup", onWindowMouseUp);
    };

    // when mouse is moved anywhere in window
    const onWindowMouseMove = function (event) {
      if (
        clickMouseX === undefined ||
        clickMouseY === undefined ||
        clickTranslateX === undefined ||
        clickTranslateY === undefined
      )
        return;

      // offset image based on original and current mouse position
      translateX = clickTranslateX + window.mouseX - clickMouseX;
      translateY = clickTranslateY + window.mouseY - clickMouseY;
      updateTransform();
      event.preventDefault();

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("mousemove", onWindowMouseMove);
    };

    // when window is resized
    const onWindowResize = function (event) {
      fit();

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("resize", onWindowResize);
    };

    // attach the necessary event listeners
    img.addEventListener("dblclick", fit);
    img.addEventListener("mousedown", onImageMouseDown);
    container.addEventListener("wheel", onContainerWheel);
    container.addEventListener("mousedown", onContainerClick);
    container.addEventListener("touchstart", onContainerClick);
    window.addEventListener("mouseup", onWindowMouseUp);
    window.addEventListener("mousemove", onWindowMouseMove);
    window.addEventListener("resize", onWindowResize);

    // run fit() after lightbox atttached to document and <img> Loaded
    // so needed container and img dimensions available
    img.addEventListener("load", fit);

    return img;
  }

  // make caption
  function makeCaption(img) {
    const caption = document.createElement("div");
    caption.id = "lightbox_caption";
    const captionSource = img.nextElementSibling;
    if (captionSource.tagName.toLowerCase() === "figcaption") {
      const captionCopy = makeCopy(captionSource);
      caption.innerHTML = captionCopy.innerHTML;
    }

    caption.addEventListener("touchstart", function (event) {
      event.stopPropagation();
    });

    return caption;
  }

  // make carbon copy of html dom element
  function makeCopy(source) {
    const sourceCopy = source.cloneNode(true);

    // delete elements marked with ignore (eg anchor and jump buttons)
    const deleteFromCopy = sourceCopy.querySelectorAll('[data-ignore="true"]');
    for (const element of deleteFromCopy) element.remove();

    // delete certain element attributes
    const attributes = [
      "id",
      "data-collapsed",
      "data-selected",
      "data-highlighted",
      "data-glow",
    ];
    for (const attribute of attributes) {
      sourceCopy.removeAttribute(attribute);
      const elements = sourceCopy.querySelectorAll("[" + attribute + "]");
      for (const element of elements) element.removeAttribute(attribute);
    }

    return sourceCopy;
  }

  // make button to jump to previous image in document
  function makePrevButton(img) {
    const prevButton = document.createElement("button");
    prevButton.id = "lightbox_prev_button";
    prevButton.title = "Jump to the previous image in the document [←]";
    prevButton.classList.add("icon_button", "lightbox_button");
    prevButton.innerHTML = document.querySelector(".icon_caret_left").innerHTML;

    // attach click listeners to button
    prevButton.addEventListener("click", function () {
      getPrevImg(img).click();
    });

    return prevButton;
  }

  // make button to jump to next image in document
  function makeNextButton(img) {
    const nextButton = document.createElement("button");
    nextButton.id = "lightbox_next_button";
    nextButton.title = "Jump to the next image in the document [→]";
    nextButton.classList.add("icon_button", "lightbox_button");
    nextButton.innerHTML = document.querySelector(
      ".icon_caret_right"
    ).innerHTML;

    // attach click listeners to button
    nextButton.addEventListener("click", function () {
      getNextImg(img).click();
    });

    return nextButton;
  }

  // get previous image in document
  function getPrevImg(img) {
    const imgs = document.querySelectorAll(".lightbox_document_img");

    // find index of provided img
    let index;
    for (index = 0; index < imgs.length; index++) {
      if (imgs[index] === img) break;
    }

    // wrap index to other side if < 1
    if (index - 1 >= 0) index--;
    else index = imgs.length - 1;
    return imgs[index];
  }

  // get next image in document
  function getNextImg(img) {
    const imgs = document.querySelectorAll(".lightbox_document_img");

    // find index of provided img
    let index;
    for (index = 0; index < imgs.length; index++) {
      if (imgs[index] === img) break;
    }

    // wrap index to other side if > total
    if (index + 1 <= imgs.length - 1) index++;
    else index = 0;
    return imgs[index];
  }

  // close lightbox
  function closeLightbox() {
    focusBody();

    const lightbox = document.getElementById("lightbox_overlay");
    if (lightbox) lightbox.remove();
  }

  // make all elements behind lightbox non-focusable
  function blurBody(overlay) {
    const all = document.querySelectorAll("*");
    for (const element of all) element.tabIndex = -1;
    document.body.classList.add("body_no_scroll");
  }

  // make all elements focusable again
  function focusBody() {
    const all = document.querySelectorAll("*");
    for (const element of all) element.removeAttribute("tabIndex");
    document.body.classList.remove("body_no_scroll");
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
  <!-- modified from: https://fontawesome.com/icons/caret-left -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
    ></path>
  </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
  <!-- modified from: https://fontawesome.com/icons/caret-right -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* regular <img> in document when hovered */
    img.lightbox_document_img:hover {
      cursor: pointer;
    }

    .body_no_scroll {
      overflow: hidden !important;
    }

    /* screen overlay */
    #lightbox_overlay {
      display: flex;
      flex-direction: column;
      position: fixed;
      left: 0;
      top: 0;
      right: 0;
      bottom: 0;
      background: rgba(0, 0, 0, 0.75);
      z-index: 3;
    }

    /* middle area containing lightbox image */
    #lightbox_image_container {
      flex-grow: 1;
      display: flex;
      justify-content: center;
      align-items: center;
      overflow: hidden;
      position: relative;
      padding: 20px;
    }

    /* bottom area containing caption */
    #lightbox_bottom_container {
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100px;
      min-height: 100px;
      max-height: 100px;
      background: rgba(0, 0, 0, 0.5);
    }

    /* image number info text box */
    #lightbox_number_info {
      position: absolute;
      color: #ffffff;
      font-weight: 600;
      left: 2px;
      top: 0;
      z-index: 4;
    }

    /* zoom info text box */
    #lightbox_zoom_info {
      position: absolute;
      color: #ffffff;
      font-weight: 600;
      right: 2px;
      top: 0;
      z-index: 4;
    }

    /* copy of image caption */
    #lightbox_caption {
      box-sizing: border-box;
      display: inline-block;
      width: 100%;
      max-height: 100%;
      padding: 10px 0;
      text-align: center;
      overflow-y: auto;
      color: #ffffff;
    }

    /* navigation previous/next button */
    .lightbox_button {
      width: 100px;
      height: 100%;
      min-width: 100px;
      min-height: 100%;
      color: #ffffff;
    }

    /* navigation previous/next button when hovered */
    .lightbox_button:hover {
      background: none !important;
    }

    /* navigation button icon */
    .lightbox_button > svg {
      height: 25px;
    }

    /* figure auto-number */
    #lightbox_caption > span:first-of-type {
      font-weight: bold;
      margin-right: 5px;
    }

    /* lightbox image when hovered */
    #lightbox_img:hover {
      cursor: grab;
    }

    /* lightbox image when grabbed */
    #lightbox_img:active {
      cursor: grabbing;
    }
  }

  /* when on screen < 480px wide */
  @media only screen and (max-width: 480px) {
    /* make navigation buttons skinnier on small screens to make more room for caption text */
    .lightbox_button {
      width: 50px;
      min-width: 50px;
    }
  }

  /* always hide lightbox on print */
  @media only print {
    #lightbox_overlay {
      display: none;
    }
  }
</style>
<!-- 
  Link Highlight Plugin

  Makes it such that when a user hovers or focuses a link, other links that have
  the same target will be highlighted. It also makes it such that when clicking
  a link, the target of the link (eg reference, figure, table) is briefly
  highlighted.
-->

<script type="module">
  // whether to also highlight links that go to external urls
  const externalLinks = "false";
  // whether user must click off to unhighlight instead of just
  // un-hovering
  const clickUnhighlight = "false";
  // whether to also highlight links that are unique
  const highlightUnique = "true";

  // start script
  function start() {
    const links = getLinks();
    for (const link of links) {
      // attach mouse and focus listeners to link
      link.addEventListener("mouseenter", onLinkFocus);
      link.addEventListener("focus", onLinkFocus);
      link.addEventListener("mouseleave", onLinkUnhover);
    }

    // attach click and hash change listeners to window
    window.addEventListener("click", onClick);
    window.addEventListener("touchstart", onClick);
    window.addEventListener("hashchange", onHashChange);

    // run hash change on window load in case user has navigated
    // directly to hash
    onHashChange();
  }

  // when link is focused (tabbed to) or hovered
  function onLinkFocus() {
    highlight(this);
  }

  // when link is unhovered
  function onLinkUnhover() {
    if (clickUnhighlight !== "true") unhighlightAll();
  }

  // when the mouse is clicked anywhere in window
  function onClick(event) {
    unhighlightAll();
  }

  // when hash (eg manuscript.html#introduction) changes
  function onHashChange() {
    const target = getHashTarget();
    if (target) glowElement(target);
  }

  // start glow sequence on an element
  function glowElement(element) {
    const startGlow = function () {
      onGlowEnd();
      element.dataset.glow = "true";
      element.addEventListener("animationend", onGlowEnd);
    };
    const onGlowEnd = function () {
      element.removeAttribute("data-glow");
      element.removeEventListener("animationend", onGlowEnd);
    };
    startGlow();
  }

  // highlight link and all others with same target
  function highlight(link) {
    // force unhighlight all to start fresh
    unhighlightAll();

    // get links with same target
    if (!link) return;
    const sameLinks = getSameLinks(link);

    // if link unique and option is off, exit and don't highlight
    if (sameLinks.length <= 1 && highlightUnique !== "true") return;

    // highlight all same links, and "select" (special highlight) this
    // one
    for (const sameLink of sameLinks) {
      if (sameLink === link) sameLink.setAttribute("data-selected", "true");
      else sameLink.setAttribute("data-highlighted", "true");
    }
  }

  // unhighlight all links
  function unhighlightAll() {
    const links = getLinks();
    for (const link of links) {
      link.setAttribute("data-selected", "false");
      link.setAttribute("data-highlighted", "false");
    }
  }

  // get links with same target
  function getSameLinks(link) {
    const results = [];
    const links = getLinks();
    for (const otherLink of links) {
      if (otherLink.getAttribute("href") === link.getAttribute("href"))
        results.push(otherLink);
    }
    return results;
  }

  // get all links of types we wish to handle
  function getLinks() {
    let query = "a";
    if (externalLinks !== "true") query += '[href^="#"]';
    // exclude buttons, anchor links, toc links, etc
    query += ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    return document.querySelectorAll(query);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<style>
  @media only screen {
    /* anything with data-highlighted attribute true */
    [data-highlighted="true"] {
      background: #ffeb3b;
    }

    /* anything with data-selected attribute true */
    [data-selected="true"] {
      background: #ff8a65 !important;
    }

    /* animation definition for glow */
    @keyframes highlight_glow {
      0% {
        background: none;
      }
      10% {
        background: #bbdefb;
      }
      100% {
        background: none;
      }
    }

    /* anything with data-glow attribute true */
    [data-glow="true"] {
      animation: highlight_glow 2s;
    }
  }
</style>
<!--
  Table of Contents Plugin

  Provides a "table of contents" (toc) panel on the side of the document that
  allows the user to conveniently navigate between sections of the document.
-->

<script type="module">
  // which types of elements to add links for, in "document.querySelector" format
  const typesQuery = "h1, h2, h3";
  // whether toc starts open. use 'true' or 'false', or 'auto' to
  // use 'true' behavior when screen wide enough and 'false' when not
  const startOpen = "false";
  // whether toc closes when clicking on toc link. use 'true' or
  // 'false', or 'auto' to use 'false' behavior when screen wide
  // enough and 'true' when not
  const clickClose = "auto";
  // if list item is more than this many characters, text will be
  // truncated
  const charLimit = "50";
  // whether or not to show bullets next to each toc item
  const bullets = "false";

  // start script
  function start() {
    // make toc panel and populate with entries (links to document
    // sections)
    const panel = makePanel();
    if (!panel) return;
    makeEntries(panel);
    // attach panel to document after making entries, so 'toc' heading
    // in panel isn't included in toc
    document.body.insertBefore(panel, document.body.firstChild);

    // initial panel state
    if (startOpen === "true" || (startOpen === "auto" && !isSmallScreen()))
      openPanel();
    else closePanel();

    // attach click, scroll, and hash change listeners to window
    window.addEventListener("click", onClick);
    window.addEventListener("scroll", onScroll);
    window.addEventListener("hashchange", onScroll);
    window.addEventListener("keyup", onKeyUp);
    onScroll();

    // add class to push document body down out of way of toc button
    document.body.classList.add("toc_body_nudge");
  }

  // determine if screen wide enough to fit toc panel
  function isSmallScreen() {
    // in default theme:
    // 816px = 8.5in = width of "page" (<body>) element
    // 260px = min width of toc panel (*2 for both sides of <body>)
    return window.innerWidth < 816 + 260 * 2;
  }

  // when mouse is clicked anywhere in window
  function onClick() {
    if (isSmallScreen()) closePanel();
  }

  // when window is scrolled or hash changed
  function onScroll() {
    highlightViewed();
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    // close on esc
    if (event.key === "Escape") closePanel();
  }

  // find entry of currently viewed document section in toc and highlight
  function highlightViewed() {
    const firstId = getFirstInView(typesQuery);

    // get toc entries (links), unhighlight all, then highlight viewed
    const list = document.getElementById("toc_list");
    if (!firstId || !list) return;
    const links = list.querySelectorAll("a");
    for (const link of links) link.dataset.viewing = "false";
    const link = list.querySelector('a[href="#' + firstId + '"]');
    if (!link) return;
    link.dataset.viewing = "true";
  }

  // get first or previous toc listed element in top half of view
  function getFirstInView(query) {
    // get all elements matching query and with id
    const elements = document.querySelectorAll(query);
    const elementsWithIds = [];
    for (const element of elements) {
      if (element.id) elementsWithIds.push(element);
    }

    // get first or previous element in top half of view
    for (let i = 0; i < elementsWithIds.length; i++) {
      const element = elementsWithIds[i];
      const prevElement = elementsWithIds[Math.max(0, i - 1)];
      if (element.getBoundingClientRect().top >= 0) {
        if (element.getBoundingClientRect().top < window.innerHeight / 2)
          return element.id;
        else return prevElement.id;
      }
    }
  }

  // make panel
  function makePanel() {
    // create panel
    const panel = document.createElement("div");
    panel.id = "toc_panel";
    if (bullets === "true") panel.dataset.bullets = "true";

    // create header
    const header = document.createElement("div");
    header.id = "toc_header";

    // create toc button
    const button = document.createElement("button");
    button.id = "toc_button";
    button.innerHTML = document.querySelector(".icon_th_list").innerHTML;
    button.title = "Table of Contents";
    button.classList.add("icon_button");

    // create header text
    const text = document.createElement("h4");
    text.innerHTML = "Table of Contents";

    // create container for toc list
    const list = document.createElement("div");
    list.id = "toc_list";

    // attach click listeners
    panel.addEventListener("click", onPanelClick);
    header.addEventListener("click", onHeaderClick);
    button.addEventListener("click", onButtonClick);

    // attach elements
    header.appendChild(button);
    header.appendChild(text);
    panel.appendChild(header);
    panel.appendChild(list);

    return panel;
  }

  // create toc entries (links) to each element of the specified types
  function makeEntries(panel) {
    const elements = document.querySelectorAll(typesQuery);
    for (const element of elements) {
      // do not add link if element doesn't have assigned id
      if (!element.id) continue;

      // create link/list item
      const link = document.createElement("a");
      link.classList.add("toc_link");
      switch (element.tagName.toLowerCase()) {
        case "h1":
          link.dataset.level = "1";
          break;
        case "h2":
          link.dataset.level = "2";
          break;
        case "h3":
          link.dataset.level = "3";
          break;
        case "h4":
          link.dataset.level = "4";
          break;
      }
      link.title = element.innerText;
      let text = element.innerText;
      if (text.length > charLimit) text = text.slice(0, charLimit) + "...";
      link.innerHTML = text;
      link.href = "#" + element.id;
      link.addEventListener("click", onLinkClick);

      // attach link
      panel.querySelector("#toc_list").appendChild(link);
    }
  }

  // when panel is clicked
  function onPanelClick(event) {
    // stop click from propagating to window/document and closing panel
    event.stopPropagation();
  }

  // when header itself is clicked
  function onHeaderClick(event) {
    togglePanel();
  }

  // when button is clicked
  function onButtonClick(event) {
    togglePanel();
    // stop header underneath button from also being clicked
    event.stopPropagation();
  }

  // when link is clicked
  function onLinkClick(event) {
    if (clickClose === "true" || (clickClose === "auto" && isSmallScreen()))
      closePanel();
    else openPanel();
  }

  // open panel if closed, close if opened
  function togglePanel() {
    const panel = document.getElementById("toc_panel");
    if (!panel) return;

    if (panel.dataset.open === "true") closePanel();
    else openPanel();
  }

  // open panel
  function openPanel() {
    const panel = document.getElementById("toc_panel");
    if (panel) panel.dataset.open = "true";
  }

  // close panel
  function closePanel() {
    const panel = document.getElementById("toc_panel");
    if (panel) panel.dataset.open = "false";
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- th list icon -->

<template class="icon_th_list">
  <!-- modified from: https://fontawesome.com/icons/th-list -->
  <svg width="16" height="16" viewBox="0 0 512 512" tabindex="-1">
    <path
      fill="currentColor"
      d="M96 96c0 26.51-21.49 48-48 48S0 122.51 0 96s21.49-48 48-48 48 21.49 48 48zM48 208c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm0 160c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm96-236h352c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"
      tabindex="-1"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* toc panel */
    #toc_panel {
      box-sizing: border-box;
      position: fixed;
      top: 0;
      left: 0;
      background: #ffffff;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      z-index: 2;
    }

    /* toc panel when closed */
    #toc_panel[data-open="false"] {
      min-width: 60px;
      width: 60px;
      height: 60px;
      border-right: solid 1px #bdbdbd;
      border-bottom: solid 1px #bdbdbd;
    }

    /* toc panel when open */
    #toc_panel[data-open="true"] {
      min-width: 260px;
      max-width: 480px;
      /* keep panel edge consistent distance away from "page" edge */
      width: calc(((100vw - 8.5in) / 2) - 30px - 40px);
      bottom: 0;
      border-right: solid 1px #bdbdbd;
    }

    /* toc panel header */
    #toc_header {
      box-sizing: border-box;
      display: flex;
      flex-direction: row;
      align-items: center;
      height: 60px;
      margin: 0;
      padding: 20px;
    }

    /* toc panel header when hovered */
    #toc_header:hover {
      cursor: pointer;
    }

    /* toc panel header when panel open */
    #toc_panel[data-open="true"] > #toc_header {
      border-bottom: solid 1px #bdbdbd;
    }

    /* toc open/close header button */
    #toc_button {
      margin-right: 20px;
    }

    /* hide toc list and header text when closed */
    #toc_panel[data-open="false"] > #toc_header > *:not(#toc_button),
    #toc_panel[data-open="false"] > #toc_list {
      display: none;
    }

    /* toc list of entries */
    #toc_list {
      box-sizing: border-box;
      width: 100%;
      padding: 20px;
      position: absolute;
      top: calc(60px + 1px);
      bottom: 0;
      overflow: auto;
    }

    /* toc entry, link to section in document */
    .toc_link {
      display: block;
      padding: 5px;
      position: relative;
      font-weight: 600;
      text-decoration: none;
    }

    /* toc entry when hovered or when "viewed" */
    .toc_link:hover,
    .toc_link[data-viewing="true"] {
      background: #f5f5f5;
    }

    /* toc entry, level 1 indentation */
    .toc_link[data-level="1"] {
      margin-left: 0;
    }

    /* toc entry, level 2 indentation */
    .toc_link[data-level="2"] {
      margin-left: 20px;
    }

    /* toc entry, level 3 indentation */
    .toc_link[data-level="3"] {
      margin-left: 40px;
    }

    /* toc entry, level 4 indentation */
    .toc_link[data-level="4"] {
      margin-left: 60px;
    }

    /* toc entry bullets */
    #toc_panel[data-bullets="true"] .toc_link[data-level]:before {
      position: absolute;
      left: -15px;
      top: -1px;
      font-size: 1.5em;
    }

    /* toc entry, level 2 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="2"]:before {
      content: "\2022";
    }

    /* toc entry, level 3 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="3"]:before {
      content: "\25AB";
    }

    /* toc entry, level 4 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="4"]:before {
      content: "-";
    }
  }

  /* when on screen < 8.5in wide */
  @media only screen and (max-width: 8.5in) {
    /* push <body> ("page") element down to make room for toc icon */
    .toc_body_nudge {
      padding-top: 60px;
    }

    /* toc icon when panel closed and not hovered */
    #toc_panel[data-open="false"]:not(:hover) {
      background: rgba(255, 255, 255, 0.75);
    }
  }

  /* always hide toc panel on print */
  @media only print {
    #toc_panel {
      display: none;
    }
  }
</style>
<!-- 
  Tooltips Plugin

  Makes it such that when the user hovers or focuses a link to a citation or
  figure, a tooltip appears with a preview of the reference content, along with
  arrows to navigate between instances of the same reference in the document.
-->

<script type="module">
  // whether user must click off to close tooltip instead of just un-hovering
  const clickClose = "false";
  // delay (in ms) between opening and closing tooltip
  const delay = "100";

  // start script
  function start() {
    const links = getLinks();
    for (const link of links) {
      // attach hover and focus listeners to link
      link.addEventListener("mouseover", onLinkHover);
      link.addEventListener("mouseleave", onLinkUnhover);
      link.addEventListener("focus", onLinkFocus);
      link.addEventListener("touchend", onLinkTouch);
    }

    // attach mouse, key, and resize listeners to window
    window.addEventListener("mousedown", onClick);
    window.addEventListener("touchstart", onClick);
    window.addEventListener("keyup", onKeyUp);
    window.addEventListener("resize", onResize);
  }

  // when link is hovered
  function onLinkHover() {
    // function to open tooltip
    const delayOpenTooltip = function () {
      openTooltip(this);
    }.bind(this);

    // run open function after delay
    this.openTooltipTimer = window.setTimeout(delayOpenTooltip, delay);
  }

  // when mouse leaves link
  function onLinkUnhover() {
    // cancel opening tooltip
    window.clearTimeout(this.openTooltipTimer);

    // don't close on unhover if option specifies
    if (clickClose === "true") return;

    // function to close tooltip
    const delayCloseTooltip = function () {
      // if tooltip open and if mouse isn't over tooltip, close
      const tooltip = document.getElementById("tooltip");
      if (tooltip && !tooltip.matches(":hover")) closeTooltip();
    };

    // run close function after delay
    this.closeTooltipTimer = window.setTimeout(delayCloseTooltip, delay);
  }

  // when link is focused (tabbed to)
  function onLinkFocus(event) {
    openTooltip(this);
  }

  // when link is touched on touch screen
  function onLinkTouch(event) {
    // attempt to force hover state on first tap always, and trigger
    // regular link click (and navigation) on second tap
    if (event.target === document.activeElement) event.target.click();
    else {
      document.activeElement.blur();
      event.target.focus();
    }
    if (event.cancelable) event.preventDefault();
    event.stopPropagation();
    return false;
  }

  // when mouse is clicked anywhere in window
  function onClick(event) {
    closeTooltip();
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    switch (event.key) {
      // trigger click of prev button
      case "ArrowLeft":
        const prevButton = document.getElementById("tooltip_prev_button");
        if (prevButton) prevButton.click();
        break;
      // trigger click of next button
      case "ArrowRight":
        const nextButton = document.getElementById("tooltip_next_button");
        if (nextButton) nextButton.click();
        break;
      // close on esc
      case "Escape":
        closeTooltip();
        break;
    }
  }

  // when window is resized or zoomed
  function onResize() {
    closeTooltip();
  }

  // get all links of types we wish to handle
  function getLinks() {
    const queries = [];
    // exclude buttons, anchor links, toc links, etc
    const exclude =
      ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    queries.push('a[href^="#ref-"]' + exclude); // citation links
    queries.push('a[href^="#fig:"]' + exclude); // figure links
    const query = queries.join(", ");
    return document.querySelectorAll(query);
  }

  // get links with same target, get index of link in set, get total
  // same links
  function getSameLinks(link) {
    const sameLinks = [];
    const links = getLinks();
    for (const otherLink of links) {
      if (otherLink.getAttribute("href") === link.getAttribute("href"))
        sameLinks.push(otherLink);
    }

    return {
      elements: sameLinks,
      index: sameLinks.indexOf(link),
      total: sameLinks.length,
    };
  }

  // open tooltip
  function openTooltip(link) {
    // delete tooltip if it exists, start fresh
    closeTooltip();

    // make tooltip element
    const tooltip = makeTooltip(link);

    // if source couldn't be found and tooltip not made, exit
    if (!tooltip) return;

    // make navbar elements
    const navBar = makeNavBar(link);
    if (navBar) tooltip.firstElementChild.appendChild(navBar);

    // attach tooltip to page
    document.body.appendChild(tooltip);

    // position tooltip
    const position = function () {
      positionTooltip(link);
    };
    position();

    // if tooltip contains images, position again after they've loaded
    const imgs = tooltip.querySelectorAll("img");
    for (const img of imgs) img.addEventListener("load", position);
  }

  // close (delete) tooltip
  function closeTooltip() {
    const tooltip = document.getElementById("tooltip");
    if (tooltip) tooltip.remove();
  }

  // make tooltip
  function makeTooltip(link) {
    // get target element that link points to
    const source = getSource(link);

    // if source can't be found, exit
    if (!source) return;

    // create new tooltip
    const tooltip = document.createElement("div");
    tooltip.id = "tooltip";
    const tooltipContent = document.createElement("div");
    tooltipContent.id = "tooltip_content";
    tooltip.appendChild(tooltipContent);

    // make copy of source node and put in tooltip
    const sourceCopy = makeCopy(source);
    tooltipContent.appendChild(sourceCopy);

    // attach mouse event listeners
    tooltip.addEventListener("click", onTooltipClick);
    tooltip.addEventListener("mousedown", onTooltipClick);
    tooltip.addEventListener("touchstart", onTooltipClick);
    tooltip.addEventListener("mouseleave", onTooltipUnhover);

    // (for interaction with lightbox plugin)
    // transfer click on tooltip copied img to original img
    const sourceImg = source.querySelector("img");
    const sourceCopyImg = sourceCopy.querySelector("img");
    if (sourceImg && sourceCopyImg) {
      const clickImg = function () {
        sourceImg.click();
        closeTooltip();
      };
      sourceCopyImg.addEventListener("click", clickImg);
    }

    return tooltip;
  }

  // make carbon copy of html dom element
  function makeCopy(source) {
    const sourceCopy = source.cloneNode(true);

    // delete elements marked with ignore (eg anchor and jump buttons)
    const deleteFromCopy = sourceCopy.querySelectorAll('[data-ignore="true"]');
    for (const element of deleteFromCopy) element.remove();

    // delete certain element attributes
    const attributes = [
      "id",
      "data-collapsed",
      "data-selected",
      "data-highlighted",
      "data-glow",
      "class",
    ];
    for (const attribute of attributes) {
      sourceCopy.removeAttribute(attribute);
      const elements = sourceCopy.querySelectorAll("[" + attribute + "]");
      for (const element of elements) element.removeAttribute(attribute);
    }

    return sourceCopy;
  }

  // when tooltip is clicked
  function onTooltipClick(event) {
    // when user clicks on tooltip, stop click from transferring
    // outside of tooltip (eg, click off to close tooltip, or eg click
    // off to unhighlight same refs)
    event.stopPropagation();
  }

  // when tooltip is unhovered
  function onTooltipUnhover(event) {
    if (clickClose === "true") return;

    // make sure new mouse/touch/focus no longer over tooltip or any
    // element within it
    const tooltip = document.getElementById("tooltip");
    if (!tooltip) return;
    if (this.contains(event.relatedTarget)) return;

    closeTooltip();
  }

  // make nav bar to go betwen prev/next instances of same reference
  function makeNavBar(link) {
    // find other links to the same source
    const sameLinks = getSameLinks(link);

    // don't show nav bar when singular reference
    if (sameLinks.total <= 1) return;

    // find prev/next links with same target
    const prevLink = getPrevLink(link, sameLinks);
    const nextLink = getNextLink(link, sameLinks);

    // create nav bar
    const navBar = document.createElement("div");
    navBar.id = "tooltip_nav_bar";
    const text = sameLinks.index + 1 + " of " + sameLinks.total;

    // create nav bar prev/next buttons
    const prevButton = document.createElement("button");
    const nextButton = document.createElement("button");
    prevButton.id = "tooltip_prev_button";
    nextButton.id = "tooltip_next_button";
    prevButton.title =
      "Jump to the previous occurence of this item in the document [←]";
    nextButton.title =
      "Jump to the next occurence of this item in the document [→]";
    prevButton.classList.add("icon_button");
    nextButton.classList.add("icon_button");
    prevButton.innerHTML = document.querySelector(".icon_caret_left").innerHTML;
    nextButton.innerHTML =
      document.querySelector(".icon_caret_right").innerHTML;
    navBar.appendChild(prevButton);
    navBar.appendChild(document.createTextNode(text));
    navBar.appendChild(nextButton);

    // attach click listeners to buttons
    prevButton.addEventListener("click", function () {
      onPrevNextClick(link, prevLink);
    });
    nextButton.addEventListener("click", function () {
      onPrevNextClick(link, nextLink);
    });

    return navBar;
  }

  // get previous link with same target
  function getPrevLink(link, sameLinks) {
    if (!sameLinks) sameLinks = getSameLinks(link);
    // wrap index to other side if < 1
    let index;
    if (sameLinks.index - 1 >= 0) index = sameLinks.index - 1;
    else index = sameLinks.total - 1;
    return sameLinks.elements[index];
  }

  // get next link with same target
  function getNextLink(link, sameLinks) {
    if (!sameLinks) sameLinks = getSameLinks(link);
    // wrap index to other side if > total
    let index;
    if (sameLinks.index + 1 <= sameLinks.total - 1) index = sameLinks.index + 1;
    else index = 0;
    return sameLinks.elements[index];
  }

  // get element that is target of link or url hash
  function getSource(link) {
    const hash = link ? link.hash : window.location.hash;
    const id = hash.slice(1);
    let target = document.querySelector('[id="' + id + '"]');
    if (!target) return;

    // if ref or figure, modify target to get expected element
    if (id.indexOf("ref-") === 0) target = target.querySelector(":nth-child(2)");
    else if (id.indexOf("fig:") === 0) target = target.querySelector("figure");

    return target;
  }

  // when prev/next arrow button is clicked
  function onPrevNextClick(link, prevNextLink) {
    if (link && prevNextLink)
      goToElement(prevNextLink, window.innerHeight * 0.5);
  }

  // scroll to and focus element
  function goToElement(element, offset) {
    // expand accordion section if collapsed
    expandElement(element);
    const y =
      getRectInView(element).top -
      getRectInView(document.documentElement).top -
      (offset || 0);
    // trigger any function listening for "onscroll" event
    window.dispatchEvent(new Event("scroll"));
    window.scrollTo(0, y);
    document.activeElement.blur();
    element.focus();
  }

  // determine position to place tooltip based on link position in
  // viewport and tooltip size
  function positionTooltip(link, left, top) {
    const tooltipElement = document.getElementById("tooltip");
    if (!tooltipElement) return;

    // get convenient vars for position/dimensions of
    // link/tooltip/page/view
    link = getRectInPage(link);
    const tooltip = getRectInPage(tooltipElement);
    const view = getRectInPage();

    // horizontal positioning
    if (left)
      // use explicit value
      left = left;
    else if (link.left + tooltip.width < view.right)
      // fit tooltip to right of link
      left = link.left;
    else if (link.right - tooltip.width > view.left)
      // fit tooltip to left of link
      left = link.right - tooltip.width;
    // center tooltip in view
    else left = (view.right - view.left) / 2 - tooltip.width / 2;

    // vertical positioning
    if (top)
      // use explicit value
      top = top;
    else if (link.top - tooltip.height > view.top)
      // fit tooltip above link
      top = link.top - tooltip.height;
    else if (link.bottom + tooltip.height < view.bottom)
      // fit tooltip below link
      top = link.bottom;
    else {
      // center tooltip in view
      top = view.top + view.height / 2 - tooltip.height / 2;
      // nudge off of link to left/right if possible
      if (link.right + tooltip.width < view.right) left = link.right;
      else if (link.left - tooltip.width > view.left)
        left = link.left - tooltip.width;
    }

    tooltipElement.style.left = left + "px";
    tooltipElement.style.top = top + "px";
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
  <!-- modified from: https://fontawesome.com/icons/caret-left -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
    ></path>
  </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
  <!-- modified from: https://fontawesome.com/icons/caret-right -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* tooltip container */
    #tooltip {
      position: absolute;
      width: 50%;
      min-width: 240px;
      max-width: 75%;
      z-index: 1;
    }

    /* tooltip content */
    #tooltip_content {
      margin-bottom: 5px;
      padding: 20px;
      border-radius: 5px;
      border: solid 1px #bdbdbd;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      background: #ffffff;
      overflow-wrap: break-word;
    }

    /* tooltip copy of paragraphs and figures */
    #tooltip_content > p,
    #tooltip_content > figure {
      margin: 0;
      max-height: 320px;
      overflow-y: auto;
    }

    /* tooltip copy of <img> */
    #tooltip_content > figure > img,
    #tooltip_content > figure > svg {
      max-height: 260px;
    }

    /* navigation bar */
    #tooltip_nav_bar {
      margin-top: 10px;
      text-align: center;
    }

    /* navigation bar previous/next buton */
    #tooltip_nav_bar > .icon_button {
      position: relative;
      top: 3px;
    }

    /* navigation bar previous button */
    #tooltip_nav_bar > .icon_button:first-of-type {
      margin-right: 5px;
    }

    /* navigation bar next button */
    #tooltip_nav_bar > .icon_button:last-of-type {
      margin-left: 5px;
    }
  }

  /* always hide tooltip on print */
  @media only print {
    #tooltip {
      display: none;
    }
  }
</style>
<!--
  Analytics Plugin (third-party) 
  
  Copy and paste code from Google Analytics or similar service here.
-->
<!-- 
  Annotations Plugin

  Allows public annotation of the  manuscript. See https://web.hypothes.is/.
-->

<script type="module">
  // configuration
  window.hypothesisConfig = function () {
    return {
      branding: {
        accentColor: "#2196f3",
        appBackgroundColor: "#f8f8f8",
        ctaBackgroundColor: "#f8f8f8",
        ctaTextColor: "#000000",
        selectionFontFamily: "Open Sans, Helvetica, sans serif",
        annotationFontFamily: "Open Sans, Helvetica, sans serif",
      },
    };
  };

  // hypothesis client script
  const embed = "https://hypothes.is/embed.js";
  // hypothesis annotation count query url
  const query = "https://api.hypothes.is/api/search?limit=0&url=";

  // start script
  function start() {
    const button = makeButton();
    document.body.insertBefore(button, document.body.firstChild);
    insertCount(button);
  }

  // make button
  function makeButton() {
    // create button
    const button = document.createElement("button");
    button.id = "hypothesis_button";
    button.innerHTML = document.querySelector(".icon_hypothesis").innerHTML;
    button.title = "Hypothesis annotations";
    button.classList.add("icon_button");

    function onClick(event) {
      onButtonClick(event, button);
    }

    // attach click listeners
    button.addEventListener("click", onClick);

    return button;
  }

  // insert annotations count
  async function insertCount(button) {
    // get annotation count from Hypothesis based on url
    let count = "-";
    try {
      const canonical = document.querySelector('link[rel="canonical"]');
      const location = window.location;
      const url = encodeURIComponent((canonical || location).href);
      const response = await fetch(query + url);
      const json = await response.json();
      count = json.total || "-";
    } catch (error) {
      console.log(error);
    }

    // put count into button
    const counter = document.createElement("span");
    counter.id = "hypothesis_count";
    counter.innerHTML = count;
    button.title = "View " + count + " Hypothesis annotations";
    button.append(counter);
  }

  // when button is clicked
  function onButtonClick(event, button) {
    const script = document.createElement("script");
    script.src = embed;
    document.body.append(script);
    button.remove();
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- hypothesis icon -->

<template class="icon_hypothesis">
  <!-- modified from: https://simpleicons.org/icons/hypothesis.svg / https://git.io/Jf1VB -->
  <svg width="16" height="16" viewBox="0 0 24 24" tabindex="-1">
    <path
      fill="currentColor"
      d="M3.43 0C2.5 0 1.72 .768 1.72 1.72V18.86C1.72 19.8 2.5 20.57 3.43 20.57H9.38L12 24L14.62 20.57H20.57C21.5 20.57 22.29 19.8 22.29 18.86V1.72C22.29 .77 21.5 0 20.57 0H3.43M5.14 3.43H7.72V9.43S8.58 7.72 10.28 7.72C12 7.72 13.74 8.57 13.74 11.24V17.14H11.16V12C11.16 10.61 10.28 10.07 9.43 10.29C8.57 10.5 7.72 11.41 7.72 13.29V17.14H5.14V3.43M18 13.72C18.95 13.72 19.72 14.5 19.72 15.42A1.71 1.71 0 0 1 18 17.13A1.71 1.71 0 0 1 16.29 15.42C16.29 14.5 17.05 13.71 18 13.71Z"
      tabindex="-1"
    ></path>
  </svg>
</template>

<style>
  /* hypothesis activation button */
  #hypothesis_button {
    box-sizing: border-box;
    position: fixed;
    top: 0;
    right: 0;
    width: 60px;
    height: 60px;
    background: #ffffff;
    border-radius: 0;
    border-left: solid 1px #bdbdbd;
    border-bottom: solid 1px #bdbdbd;
    box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
    z-index: 2;
  }

  /* hypothesis button svg */
  #hypothesis_button > svg {
    position: relative;
    top: -4px;
  }

  /* hypothesis annotation count */
  #hypothesis_count {
    position: absolute;
    left: 0;
    right: 0;
    bottom: 5px;
  }

  /* side panel */
  .annotator-frame {
    width: 280px !important;
  }

  /* match highlight color to rest of theme */
  .annotator-highlights-always-on .annotator-hl {
    background-color: #ffeb3b !important;
  }

  /* match focused color to rest of theme */
  .annotator-hl.annotator-hl-focused {
    background-color: #ff8a65 !important;
  }

  /* match bucket bar color to rest of theme */
  .annotator-bucket-bar {
    background: #f5f5f5 !important;
  }

  /* always hide button, toolbar, and tooltip on print */
  @media only print {
    #hypothesis_button {
      display: none;
    }

    .annotator-frame {
      display: none !important;
    }

    hypothesis-adder {
      display: none !important;
    }
  }
</style>
<!-- 
  Mathjax Plugin (third-party) 

  Allows the proper rendering of math/equations written in LaTeX.
  See https://www.mathjax.org/.
-->

<script type="text/x-mathjax-config">
  // configuration
  MathJax.Hub.Config({
    "CommonHTML": { linebreaks: { automatic: true } },
    "HTML-CSS": { linebreaks: { automatic: true } },
    "SVG": { linebreaks: { automatic: true } },
    "fast-preview": { disabled: true }
  });
</script>

<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A=="
  crossorigin="anonymous"
></script>

<style>
  /* mathjax containers */
  .math.display > span:not(.MathJax_Preview) {
    /* turn inline element (no dimensions) into block (allows fixed width and thus scrolling) */
    display: flex !important;
    overflow-x: auto !important;
    overflow-y: hidden !important;
    justify-content: center;
    align-items: center;
    margin: 0 !important;
  }

  /* right click menu */
  .MathJax_Menu {
    border-radius: 5px !important;
    border: solid 1px #bdbdbd !important;
    box-shadow: none !important;
  }

  /* equation auto-number */
  span[id^="eq:"] > span.math.display + span {
    font-weight: 600;
  }

  /* equation */
  span[id^="eq:"] > span.math.display > span {
    /* nudge to make room for equation auto-number and anchor */
    margin-right: 60px !important;
  }
</style>
</body>
</html>
