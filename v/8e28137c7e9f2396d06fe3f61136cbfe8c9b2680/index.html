<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="David N. Nicholson" />
  <meta name="author" content="Daniel S. Himmelstein" />
  <meta name="author" content="Casey S. Greene" />
  <meta name="dcterms.date" content="2022-03-29" />
  <meta name="keywords" content="machine learning, weak supervision, natural language processing, heterogenous netowrks, text mining" />
  <title>Expanding a Database-derived Biomedical Knowledge Graph via Multi-relation Extraction from Biomedical Abstracts</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <!--
  Manubot generated metadata rendered from header-includes-template.html.
  Suggest improvements at https://github.com/manubot/manubot/blob/main/manubot/process/header-includes-template.html
  -->
  <meta name="dc.format" content="text/html" />
  <meta name="dc.title" content="Expanding a Database-derived Biomedical Knowledge Graph via Multi-relation Extraction from Biomedical Abstracts" />
  <meta name="citation_title" content="Expanding a Database-derived Biomedical Knowledge Graph via Multi-relation Extraction from Biomedical Abstracts" />
  <meta property="og:title" content="Expanding a Database-derived Biomedical Knowledge Graph via Multi-relation Extraction from Biomedical Abstracts" />
  <meta property="twitter:title" content="Expanding a Database-derived Biomedical Knowledge Graph via Multi-relation Extraction from Biomedical Abstracts" />
  <meta name="dc.date" content="2022-03-29" />
  <meta name="citation_publication_date" content="2022-03-29" />
  <meta name="dc.language" content="en-US" />
  <meta name="citation_language" content="en-US" />
  <meta name="dc.relation.ispartof" content="Manubot" />
  <meta name="dc.publisher" content="Manubot" />
  <meta name="citation_journal_title" content="Manubot" />
  <meta name="citation_technical_report_institution" content="Manubot" />
  <meta name="citation_author" content="David N. Nicholson" />
  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania" />
  <meta name="citation_author_orcid" content="0000-0003-0002-5761" />
  <meta name="twitter:creator" content="@None" />
  <meta name="citation_author" content="Daniel S. Himmelstein" />
  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania" />
  <meta name="citation_author_orcid" content="0000-0002-3012-7446" />
  <meta name="twitter:creator" content="@dhimmel" />
  <meta name="citation_author" content="Casey S. Greene" />
  <meta name="citation_author_institution" content="Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania" />
  <meta name="citation_author_orcid" content="0000-0001-8713-9213" />
  <meta name="twitter:creator" content="@GreeneScientist" />
  <link rel="canonical" href="https://greenelab.github.io/text_mined_hetnet_manuscript/" />
  <meta property="og:url" content="https://greenelab.github.io/text_mined_hetnet_manuscript/" />
  <meta property="twitter:url" content="https://greenelab.github.io/text_mined_hetnet_manuscript/" />
  <meta name="citation_fulltext_html_url" content="https://greenelab.github.io/text_mined_hetnet_manuscript/" />
  <meta name="citation_pdf_url" content="https://greenelab.github.io/text_mined_hetnet_manuscript/manuscript.pdf" />
  <link rel="alternate" type="application/pdf" href="https://greenelab.github.io/text_mined_hetnet_manuscript/manuscript.pdf" />
  <link rel="alternate" type="text/html" href="https://greenelab.github.io/text_mined_hetnet_manuscript/v/8e28137c7e9f2396d06fe3f61136cbfe8c9b2680/" />
  <meta name="manubot_html_url_versioned" content="https://greenelab.github.io/text_mined_hetnet_manuscript/v/8e28137c7e9f2396d06fe3f61136cbfe8c9b2680/" />
  <meta name="manubot_pdf_url_versioned" content="https://greenelab.github.io/text_mined_hetnet_manuscript/v/8e28137c7e9f2396d06fe3f61136cbfe8c9b2680/manuscript.pdf" />
  <meta property="og:type" content="article" />
  <meta property="twitter:card" content="summary_large_image" />
  <meta property="og:image" content="https://github.com/greenelab/text_mined_hetnet_manuscript/raw/8e28137c7e9f2396d06fe3f61136cbfe8c9b2680/thumbnail.png" />
  <meta property="twitter:image" content="https://github.com/greenelab/text_mined_hetnet_manuscript/raw/8e28137c7e9f2396d06fe3f61136cbfe8c9b2680/thumbnail.png" />
  <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />
  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" />
  <meta name="theme-color" content="#ad1457" />
  <!-- end Manubot generated metadata -->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Expanding a Database-derived Biomedical Knowledge Graph via Multi-relation Extraction from Biomedical Abstracts</h1>
</header>
<p><em>A DOI-citable version of this manuscript is available at <a href="https://doi.org/10.1101/730085" class="uri">https://doi.org/10.1101/730085</a></em>.</p>
<p><small><em>
This manuscript
(<a href="https://greenelab.github.io/text_mined_hetnet_manuscript/v/8e28137c7e9f2396d06fe3f61136cbfe8c9b2680/">permalink</a>)
was automatically generated
from <a href="https://github.com/greenelab/text_mined_hetnet_manuscript/tree/8e28137c7e9f2396d06fe3f61136cbfe8c9b2680">greenelab/text_mined_hetnet_manuscript@8e28137</a>
on March 29, 2022.
</em></small></p>
<h2 id="authors">Authors</h2>
<ul>
<li><p><strong>David N. Nicholson</strong><br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-0002-5761">0000-0003-0002-5761</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/danich1">danich1</a><br>
<small>
Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania
· Funded by GBMF4552
</small></p></li>
<li><p><strong>Daniel S. Himmelstein</strong><br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-3012-7446">0000-0002-3012-7446</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/dhimmel">dhimmel</a>
· <img src="images/twitter.svg" class="inline_icon" width="16" height="16" alt="Twitter icon" />
<a href="https://twitter.com/dhimmel">dhimmel</a><br>
<small>
Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania
· Funded by GBMF4552
</small></p></li>
<li><p><strong>Casey S. Greene</strong><br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-8713-9213">0000-0001-8713-9213</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/cgreene">cgreene</a>
· <img src="images/twitter.svg" class="inline_icon" width="16" height="16" alt="Twitter icon" />
<a href="https://twitter.com/GreeneScientist">GreeneScientist</a><br>
<small>
Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania
· Funded by GBMF4552 and R01 HG010067
</small></p></li>
</ul>
<h2 class="page_break_before" id="abstract">Abstract</h2>
<p>Knowledge graphs support multiple research efforts by providing contextual information for biomedical entities, constructing networks, and supporting the interpretation of high-throughput analyses.
These databases are populated via some form of manual curation, which is difficult to scale in the context of an increasing publication rate.
Data programming is a paradigm that circumvents this arduous manual process by combining databases with simple rules and heuristics written as label functions, which are programs designed to automatically annotate textual data.
Unfortunately, writing a useful label function requires substantial error analysis and is a nontrivial task that takes multiple days per function.
This makes populating a knowledge graph with multiple nodes and edge types practically infeasible.
We sought to accelerate the label function creation process by evaluating the extent to which label functions could be re-used across multiple edge types.
We used a subset of an existing knowledge graph centered on disease, compound, and gene entities to evaluate label function re-use.
We determined the best label function combination by comparing a baseline database-only model with the same model but added edge-specific or edge-mismatch label functions.
We confirmed that adding additional edge-specific rather than edge-mismatch label functions often improves text annotation and shows that this approach can incorporate novel edges into our source knowledge graph. 
We expect that continued development of this strategy has the potential to swiftly populate knowledge graphs with new discoveries, ensuring that these resources include cutting-edge results.</p>
<h2 id="introduction">Introduction</h2>
<p>Knowledge bases are important resources that hold complex structured and unstructured information.
These resources have been used in important tasks such as network analysis for drug repurposing discovery <span class="citation" data-cites="u8pIAt5j bPvC638e O21tn8vf"><a href="#ref-u8pIAt5j" role="doc-biblioref">[1]</a>–<a href="#ref-O21tn8vf" role="doc-biblioref">[3]</a></span> or as a source of training labels for text mining systems <span class="citation" data-cites="EHeTvZht CVHSURuI HS4ARwmZ"><a href="#ref-EHeTvZht" role="doc-biblioref">[4]</a>–<a href="#ref-HS4ARwmZ" role="doc-biblioref">[6]</a></span>.
Populating knowledge bases often requires highly trained scientists to read biomedical literature and summarize the results <span class="citation" data-cites="N1Ai0gaI"><a href="#ref-N1Ai0gaI" role="doc-biblioref">[7]</a></span>.
This time-consuming process is referred to as manual curation.
In 2007, researchers estimated that filling a knowledge base via manual curation would require approximately 8.4 years to complete <span class="citation" data-cites="UdzvLgBM"><a href="#ref-UdzvLgBM" role="doc-biblioref">[8]</a></span>.
The rate of publications continues to exponentially increase <span class="citation" data-cites="1DBISRlwN"><a href="#ref-1DBISRlwN" role="doc-biblioref">[9]</a></span>, so using only manual curation to fully populate a knowledge base has become impractical.</p>
<p>Relationship extraction has been studied as a solution towards handling the challenge posed by an exponentially growing body of literature <span class="citation" data-cites="N1Ai0gaI"><a href="#ref-N1Ai0gaI" role="doc-biblioref">[7]</a></span>.
This process consists of creating an expert system to automatically scan, detect and extract relationships from textual sources.
Typically, these systems utilize machine learning techniques that require extensive corpora of well-labeled training data.
These corpora are difficult to obtain, because they are constructed via extensive manual curation pipelines.</p>
<p>Distant supervision is a technique also designed to sidestep the dependence on manual curation and quickly generate large training datasets.
This technique assumes that positive examples established in selected databases can be applied to any sentence that contains them <span class="citation" data-cites="EHeTvZht"><a href="#ref-EHeTvZht" role="doc-biblioref">[4]</a></span>.
The central problem with this technique is that generated labels are often of low quality which results in an expansive amount of false positives <span class="citation" data-cites="raw:Jiang2018RevisitingDS"><a href="#ref-raw:Jiang2018RevisitingDS" role="doc-biblioref"><strong>raw:Jiang2018RevisitingDS?</strong></a></span>.</p>
<p>Ratner et al. <span class="citation" data-cites="5Il3kN32"><a href="#ref-5Il3kN32" role="doc-biblioref">[10]</a></span> recently introduced “data programming” as a solution.
Data programming is a paradigm that combines distant supervision with simple rules and heuristics written as small programs called label functions.
These label functions are consolidated via a noise aware generative model that is designed to produce training labels for large datasets.
Using this paradigm can dramatically reduce the time required to obtain sufficient training data; however, writing a useful label function requires a significant amount of time and error analysis.
This dependency makes constructing a knowledge base with a myriad of heterogenous relationships nearly impossible as tens or possibly hundreds of label functions are required per relationship type.</p>
<p>In this paper, we seek to accelerate the label function creation process by measuring the extent to which label functions can be re-used across different relationship types.
We hypothesize that sentences describing one relationship type may share linguistic features such as keywords or sentence structure with sentences describing other relationship types.
We conducted a series of experiments to determine the degree to which label function re-use enhanced performance over distant supervision alone.
We focus on relationships that indicate similar types of physical interactions (i.e., gene-binds-gene and compound-binds-gene) as well as different types (i.e., disease-associates-gene and compound-treats-disease).
Re-using label functions could dramatically reduce the time required to populate a knowledge base with a multitude of heterogeneous relationships.</p>
<h3 id="related-work">Related Work</h3>
<p>Relationship extraction is the process of detecting semantic relationships from a collection of text.
This process can be broken down into three different categories: (1) the use of natural language processing techniques such as manually crafted rules and heuristics for relationship extraction (Rule Based Extractors), (2) the use of unsupervised methods such as co-occurrence scores or clustering to find patterns within sentences and documents (Unsupervised Extractors), and (3) the use of supervised or semi-supervised machine learning for classifying the presence of a relation within documents or sentences (Supervised Extractors).
In this section, we briefly discuss selected efforts under each category.</p>
<h4 id="rule-based-extractors">Rule Based Extractors</h4>
<p>Rule based extractors rely heavily on expert knowledge to perform extraction.
Typically, these systems use linguistic rules and heuristics to identify key sentences or phrases.
For example, a hypothetical extractor focused on protein phosphorylation events would identify sentences containing the phrase “gene X phosphorylates gene Y” <span class="citation" data-cites="KEkjqdB0"><a href="#ref-KEkjqdB0" role="doc-biblioref">[11]</a></span>.
This phrase is a straightforward indication that two genes have a fundamental role in protein phosphorylation.
Other phrase extractors have been used to identify drug-disease treatments <span class="citation" data-cites="tag:ctd_medline"><a href="#ref-tag:ctd_medline" role="doc-biblioref"><strong>tag:ctd_medline?</strong></a></span>, pharmcogenomic events <span class="citation" data-cites="tag:pharmpresso"><a href="#ref-tag:pharmpresso" role="doc-biblioref"><strong>tag:pharmpresso?</strong></a></span> and protein-protein interactions <span class="citation" data-cites="tag:ppinterfinder tag:hpiminer"><a href="#ref-tag:ppinterfinder" role="doc-biblioref"><strong>tag:ppinterfinder?</strong></a>, <a href="#ref-tag:hpiminer" role="doc-biblioref"><strong>tag:hpiminer?</strong></a></span>.
These extractors provide a simple and effective way to extract sentences; however, they depend on extensive knowledge about the text to be properly constructed.</p>
<p>A sentence’s grammatical structure can also support relationship extraction via dependency trees.
Dependency trees are data structures that depict a sentence’s grammatical relation structure in the form of nodes and edges.
Nodes represent words and edges represent the dependency type each word shares between one another.
For example, a possible extractor would classify sentences as a positive if a sentence contained the following dependency tree path: “gene X (subject)-&gt; promotes (verb)&lt;- cell death (direct object) &lt;- in (preposition) &lt;-tumors (object of preposition)” <span class="citation" data-cites="tag:pkde4j"><a href="#ref-tag:pkde4j" role="doc-biblioref"><strong>tag:pkde4j?</strong></a></span>.
This approach provides extremely precise results, but the quantity of positive results remains modest as sentences appear in distinct forms and structure.
Because of this limitation, recent approaches have incorporated methods on top of rule based extractors such as co-occurrence and machine learning systems <span class="citation" data-cites="d3rG3TXb tag:limtox"><a href="#ref-d3rG3TXb" role="doc-biblioref">[12]</a>, <a href="#ref-tag:limtox" role="doc-biblioref"><strong>tag:limtox?</strong></a></span>.
We discuss the pros and cons of added methods in a later section.
For this project, we constructed our label functions without the aid of these works; however, approaches discussed in this section provide substantial inspiration for novel label functions in future endeavors.</p>
<h4 id="unsupervised-extractors">Unsupervised Extractors</h4>
<p>Unsupervised extractors detect relationships without the need of annotated text.
Notable approaches exploit the fact that two entities can occur together in text.
This event is referred to as co-occurrence.
Extractors utilize these events by generating statistics on the frequency of entity pairs occurring in text.
For example, a possible extractor would say gene X is associated with disease Y, because gene X and disease Y appear together more often than individually <span class="citation" data-cites="tag:diseases"><a href="#ref-tag:diseases" role="doc-biblioref"><strong>tag:diseases?</strong></a></span>.
This approach has been used to establish the following relationship types: disease-gene relationships <span class="citation" data-cites="tag:diseases tag:polysearch tag:dg_text_pubmed tag:lgscore tag:full_text_co_abstracts tag:copub_discovery"><a href="#ref-tag:diseases" role="doc-biblioref"><strong>tag:diseases?</strong></a>, <a href="#ref-tag:polysearch" role="doc-biblioref"><strong>tag:polysearch?</strong></a>, <a href="#ref-tag:dg_text_pubmed" role="doc-biblioref"><strong>tag:dg_text_pubmed?</strong></a>, <a href="#ref-tag:lgscore" role="doc-biblioref"><strong>tag:lgscore?</strong></a>, <a href="#ref-tag:full_text_co_abstracts" role="doc-biblioref"><strong>tag:full_text_co_abstracts?</strong></a>, <a href="#ref-tag:copub_discovery" role="doc-biblioref"><strong>tag:copub_discovery?</strong></a></span>, protein-protein interactions <span class="citation" data-cites="tag:protein_protein_co_network B8EOgoNA tag:full_text_co_abstracts"><a href="#ref-B8EOgoNA" role="doc-biblioref">[13]</a>, <a href="#ref-tag:protein_protein_co_network" role="doc-biblioref"><strong>tag:protein_protein_co_network?</strong></a>, <a href="#ref-tag:full_text_co_abstracts" role="doc-biblioref"><strong>tag:full_text_co_abstracts?</strong></a></span>, drug-disease treatments <span class="citation" data-cites="tag:abc_drugs"><a href="#ref-tag:abc_drugs" role="doc-biblioref"><strong>tag:abc_drugs?</strong></a></span>, and tissue-gene relations <span class="citation" data-cites="6QECA6Hm"><a href="#ref-6QECA6Hm" role="doc-biblioref">[14]</a></span>.
Extractors using the co-occurrence strategy provide exceptional recall results; however, these methods may fail to detect underreported relationships, because they depend on entity-pair frequency for detection.
Junge et al. created a hybrid approach to account for this issue using distant supervision to train a classifier to learn the context of each sentence <span class="citation" data-cites="tag:cocoscore"><a href="#ref-tag:cocoscore" role="doc-biblioref"><strong>tag:cocoscore?</strong></a></span>.
Once the classifier was trained, they scored every sentence within their corpus, and each sentence’s score was incorporated into calculating co-occurrence frequencies to establish relationship existence <span class="citation" data-cites="tag:cocoscore"><a href="#ref-tag:cocoscore" role="doc-biblioref"><strong>tag:cocoscore?</strong></a></span>.
Co-occurrence approaches are powerful in establishing edges on the global scale; however, they cannot identify individual sentences without the need for supervised methods.</p>
<p>Clustering is an unsupervised approach that extracts relationships from text by grouping similar sentences together.
Percha et al. used this technique to group sentences based on their grammatical structure <span class="citation" data-cites="tag:global_network"><a href="#ref-tag:global_network" role="doc-biblioref"><strong>tag:global_network?</strong></a></span>.
Using Stanford’s Core NLP Parser <span class="citation" data-cites="RQkLuc5t"><a href="#ref-RQkLuc5t" role="doc-biblioref">[15]</a></span>, a dependency tree was generated for every sentence in each Pubmed abstract <span class="citation" data-cites="tag:global_network"><a href="#ref-tag:global_network" role="doc-biblioref"><strong>tag:global_network?</strong></a></span>.
Each tree was clustered based on similarity and each cluster was manually annotated to determine which relationship each group represented <span class="citation" data-cites="tag:global_network"><a href="#ref-tag:global_network" role="doc-biblioref"><strong>tag:global_network?</strong></a></span>.
For our project we incorporated the results of this work as domain heuristic label functions.
Overall, unsupervised approaches are desirable since they do not require well-annotated training data.
Such approaches provide excellent recall; however, performance can be limited in terms of precision when compared to supervised machine learning methods <span class="citation" data-cites="199TFjkrC 1ZjlFRHa"><a href="#ref-199TFjkrC" role="doc-biblioref">[16]</a>, <a href="#ref-1ZjlFRHa" role="doc-biblioref">[17]</a></span>.</p>
<h4 id="supervised-extractors">Supervised Extractors</h4>
<p>Supervised extractors consist of training a machine learning classifier to predict the existence of a relationship within text.
These classifiers require access to well-annotated datasets, which are usually created via some form of manual curation.
Previous work consists of research experts curating their own datasets to train classifiers <span class="citation" data-cites="tag:befree tag:eu_adr tag:aimed tag:bioinfer tag:hprd50"><a href="#ref-tag:befree" role="doc-biblioref"><strong>tag:befree?</strong></a>, <a href="#ref-tag:eu_adr" role="doc-biblioref"><strong>tag:eu_adr?</strong></a>, <a href="#ref-tag:aimed" role="doc-biblioref"><strong>tag:aimed?</strong></a>, <a href="#ref-tag:bioinfer" role="doc-biblioref"><strong>tag:bioinfer?</strong></a>, <a href="#ref-tag:hprd50" role="doc-biblioref"><strong>tag:hprd50?</strong></a></span>; however, there have been community-wide efforts to create datasets for shared tasks <span class="citation" data-cites="tag:biocreative_v 16As8893j DR8XM4Ff"><a href="#ref-16As8893j" role="doc-biblioref">[18]</a>, <a href="#ref-DR8XM4Ff" role="doc-biblioref">[19]</a>, <a href="#ref-tag:biocreative_v" role="doc-biblioref"><strong>tag:biocreative_v?</strong></a></span>.
Shared tasks are open challenges that aim to build the best classifier for natural language processing tasks such as named entity tagging or relationship extraction.
A notable example is the BioCreative community that hosted a number of shared tasks such as predicting compound-protein interactions (BioCreative VI track 5) <span class="citation" data-cites="16As8893j"><a href="#ref-16As8893j" role="doc-biblioref">[18]</a></span> and compound induced diseases <span class="citation" data-cites="DR8XM4Ff"><a href="#ref-DR8XM4Ff" role="doc-biblioref">[19]</a></span>.
Often these datasets are well annotated, but are modest in size (2,432 abstracts for BioCreative VI <span class="citation" data-cites="16As8893j"><a href="#ref-16As8893j" role="doc-biblioref">[18]</a></span> and 1500 abstracts for BioCreative V <span class="citation" data-cites="DR8XM4Ff"><a href="#ref-DR8XM4Ff" role="doc-biblioref">[19]</a></span>).
As machine learning classifiers become increasingly complex, these small dataset sizes cannot suffice.
Plus, these multitude of datasets are uniquely annotated which can generate noticeable differences in terms of classifier performance <span class="citation" data-cites="DR8XM4Ff"><a href="#ref-DR8XM4Ff" role="doc-biblioref">[19]</a></span>.
Overall, obtaining large well-annotated datasets still remains as an open non-trivial task.</p>
<p>Before the rise of deep learning, a classifier that was most frequently used was support vector machines.
This classifier uses a projection function called a kernel to map data onto a high dimensional space so datapoints can be easily discerned between classes <span class="citation" data-cites="uujIm995"><a href="#ref-uujIm995" role="doc-biblioref">[20]</a></span>.
This method was used to extract disease-gene associations <span class="citation" data-cites="tag:befree tag:dtminer tag:ensemble_svm"><a href="#ref-tag:befree" role="doc-biblioref"><strong>tag:befree?</strong></a>, <a href="#ref-tag:dtminer" role="doc-biblioref"><strong>tag:dtminer?</strong></a>, <a href="#ref-tag:ensemble_svm" role="doc-biblioref"><strong>tag:ensemble_svm?</strong></a></span>, protein-protein interactions<span class="citation" data-cites="tag:ppi_graph_kernels tag:limtox tag:lptk"><a href="#ref-tag:ppi_graph_kernels" role="doc-biblioref"><strong>tag:ppi_graph_kernels?</strong></a>, <a href="#ref-tag:limtox" role="doc-biblioref"><strong>tag:limtox?</strong></a>, <a href="#ref-tag:lptk" role="doc-biblioref"><strong>tag:lptk?</strong></a></span> and protein docking information <span class="citation" data-cites="tag:protein_docking"><a href="#ref-tag:protein_docking" role="doc-biblioref"><strong>tag:protein_docking?</strong></a></span>.
Generally, support vector machines perform well on small datasets with large feature spaces but are slow to train as the number of datapoints becomes asymptotically large.</p>
<p>Deep learning has been increasingly popular as these methods can outperform common machine learning methods <span class="citation" data-cites="BQS8ClV0"><a href="#ref-BQS8ClV0" role="doc-biblioref">[21]</a></span>.
Approaches in this field consist of using various neural network architectures, such as recurrent neural networks <span class="citation" data-cites="tag:ppi_bilstm tag:cbg_ensemble_dl tag:cbg_neural_attention tag:recursive_nn tag:semi_supervised_vae tag:biobert"><a href="#ref-tag:ppi_bilstm" role="doc-biblioref"><strong>tag:ppi_bilstm?</strong></a>, <a href="#ref-tag:cbg_ensemble_dl" role="doc-biblioref"><strong>tag:cbg_ensemble_dl?</strong></a>, <a href="#ref-tag:cbg_neural_attention" role="doc-biblioref"><strong>tag:cbg_neural_attention?</strong></a>, <a href="#ref-tag:recursive_nn" role="doc-biblioref"><strong>tag:recursive_nn?</strong></a>, <a href="#ref-tag:semi_supervised_vae" role="doc-biblioref"><strong>tag:semi_supervised_vae?</strong></a>, <a href="#ref-tag:biobert" role="doc-biblioref"><strong>tag:biobert?</strong></a></span> and convolutional neural networks <span class="citation" data-cites="tag:ppi_deep_conv tag:mcdepcnn tag:cbg_ensemble_dl tag:semi_supervised_vae tag:cbg_transfer_learning"><a href="#ref-tag:ppi_deep_conv" role="doc-biblioref"><strong>tag:ppi_deep_conv?</strong></a>, <a href="#ref-tag:mcdepcnn" role="doc-biblioref"><strong>tag:mcdepcnn?</strong></a>, <a href="#ref-tag:cbg_ensemble_dl" role="doc-biblioref"><strong>tag:cbg_ensemble_dl?</strong></a>, <a href="#ref-tag:semi_supervised_vae" role="doc-biblioref"><strong>tag:semi_supervised_vae?</strong></a>, <a href="#ref-tag:cbg_transfer_learning" role="doc-biblioref"><strong>tag:cbg_transfer_learning?</strong></a></span>, to extract relationships from text.
In fact approaches in this field were the winning model within the BioCreative VI shared task <span class="citation" data-cites="16As8893j raw:chemprot_winner"><a href="#ref-16As8893j" role="doc-biblioref">[18]</a>, <a href="#ref-raw:chemprot_winner" role="doc-biblioref"><strong>raw:chemprot_winner?</strong></a></span>.
Despite the substantial success of these models, they often require large amounts of data to perform well.
Obtaining large datasets is a time-consuming task, which makes training these models a non-trivial challenge.
Distant supervision has been used as a solution to fix the barren amount of large datasets <span class="citation" data-cites="EHeTvZht"><a href="#ref-EHeTvZht" role="doc-biblioref">[4]</a></span>.
Approaches have used this paradigm to extract chemical-gene interactions <span class="citation" data-cites="tag:semi_supervised_vae"><a href="#ref-tag:semi_supervised_vae" role="doc-biblioref"><strong>tag:semi_supervised_vae?</strong></a></span>, disease-gene associations <span class="citation" data-cites="tag:cocoscore"><a href="#ref-tag:cocoscore" role="doc-biblioref"><strong>tag:cocoscore?</strong></a></span> and protein-protein interactions <span class="citation" data-cites="tag:deep_dive tag:cocoscore tag:semi_supervised_vae"><a href="#ref-tag:deep_dive" role="doc-biblioref"><strong>tag:deep_dive?</strong></a>, <a href="#ref-tag:cocoscore" role="doc-biblioref"><strong>tag:cocoscore?</strong></a>, <a href="#ref-tag:semi_supervised_vae" role="doc-biblioref"><strong>tag:semi_supervised_vae?</strong></a></span>.
In fact, efforts done in <span class="citation" data-cites="tag:deep_dive"><a href="#ref-tag:deep_dive" role="doc-biblioref"><strong>tag:deep_dive?</strong></a></span> served as one of the motivating rationales for our work.</p>
<p>Overall, deep learning has provided exceptional results in terms of relationships extraction.
Thus, we decided to use a deep neural network as our discriminative model.</p>
<style> 
span.gene_color { color:#02b3e4 } 
span.disease_color { color:#875442 } 
span.compound_color { color:#e91e63 }
 </style>
<h2 id="methods-and-materials">Methods and Materials</h2>
<h3 id="hetionet">Hetionet</h3>
<p>Hetionet v1 <span class="citation" data-cites="O21tn8vf"><a href="#ref-O21tn8vf" role="doc-biblioref">[3]</a></span> is a heterogeneous network that contains pharmacological and biological information.
This network depicts information in the form of nodes and edges of different types.
Nodes in this network represent biological and pharmacological entities, while edges represent relationships between entities.
Hetionet v1 contains 47,031 nodes with 11 different data types and 2,250,197 edges that represent 24 different relationship types (Figure <a href="#fig:hetionet">1</a>).
Edges in Hetionet v1 were obtained from open databases, such as the GWAS Catalog <span class="citation" data-cites="16cIDAXhG"><a href="#ref-16cIDAXhG" role="doc-biblioref">[22]</a></span>, Human Interaction database <span class="citation" data-cites="LCyCrr7W"><a href="#ref-LCyCrr7W" role="doc-biblioref">[23]</a></span> and DrugBank <span class="citation" data-cites="1FI8iuYiQ"><a href="#ref-1FI8iuYiQ" role="doc-biblioref">[24]</a></span>.
For this project, we analyzed performance over a subset of the Hetionet v1 edge types: disease associates with a gene (DaG), compound binds to a gene (CbG), compound treating a disease (CtD), and gene interacts with gene (GiG) (bolded in Figure <a href="#fig:hetionet">1</a>).</p>
<div id="fig:hetionet" class="fignos">
<figure>
<img src="images/figures/hetionet/metagraph_highlighted_edges.png" alt="Figure 1: A metagraph (schema) of Hetionet v1 where biomedical entities are represented as nodes and the relationships between them are represented as edges. We examined performance on the highlighted subgraph; however, the long-term vision is to capture edges for the entire graph." /><figcaption aria-hidden="true"><span>Figure 1:</span> A metagraph (schema) of Hetionet v1 where biomedical entities are represented as nodes and the relationships between them are represented as edges.
We examined performance on the highlighted subgraph; however, the long-term vision is to capture edges for the entire graph.</figcaption>
</figure>
</div>
<h3 id="dataset">Dataset</h3>
<p>We used PubTator Central <span class="citation" data-cites="18ZyyTcTe"><a href="#ref-18ZyyTcTe" role="doc-biblioref">[25]</a></span> as input to our analysis.
PubTator Central provides MEDLINE abstracts that have been annotated with well-established entity recognition tools including Tagger One <span class="citation" data-cites="11YUuHulp"><a href="#ref-11YUuHulp" role="doc-biblioref">[26]</a></span> for disease, chemical and cell line entities, tmVar <span class="citation" data-cites="17LQKv7vO"><a href="#ref-17LQKv7vO" role="doc-biblioref">[27]</a></span> for genetic variation tagging, GNormPlus <span class="citation" data-cites="aOPX10e0"><a href="#ref-aOPX10e0" role="doc-biblioref">[28]</a></span> for gene entities and SR4GN <span class="citation" data-cites="NXIFrudx"><a href="#ref-NXIFrudx" role="doc-biblioref">[29]</a></span> for species entities.
We downloaded PubTator Central on March 1, 2020, at which point it contained approximately 30,000,000 documents.
After downloading, we filtered out annotated entities that were not contained in Hetionet v1.
We extracted sentences with two or more annotations and termed these sentences as candidate sentences.
We used the Spacy’s English natural language processing (NLP) pipeline (en_core_web_sm) <span class="citation" data-cites="q2fFAZTG"><a href="#ref-q2fFAZTG" role="doc-biblioref">[30]</a></span> to generate dependency trees and parts of speech tags for every extracted candidate sentence.
Each candidate sentence was stratified by their corresponding abstract ID to produce a training set, tuning set, and a testing set.
We used random assortment to assign dataset labels to each abstract.
Every abstract had a 70% chance of being labeled training, 20% chance of being labeled tuning, and 10% chance of being labeled testing.
Despite the power of data programming, all text mining systems need to have ground truth labels to be well-calibrated.
We hand-labeled five hundred to a thousand candidate sentences of each edge type to obtain a ground truth set (Table <a href="#tbl:candidate-sentences">1</a>).</p>
<div id="tbl:candidate-sentences" class="tablenos">
<table id="tbl:candidate-sentences">
<caption><span>Table 1:</span> Statistics of Candidate Sentences.
We sorted each abstract into a training, tuning and testing set.
Numbers in parentheses show the number of positives and negatives that resulted from the hand-labeling process.
</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Relationship</th>
<th style="text-align: center;">Train</th>
<th style="text-align: center;">Tune</th>
<th style="text-align: center;">Test</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Disease Associates Gene</td>
<td style="text-align: center;">2.49 M</td>
<td style="text-align: center;">696K (397+, 603-)</td>
<td style="text-align: center;">348K (351+, 649-)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Compound Binds Gene</td>
<td style="text-align: center;">2.4M</td>
<td style="text-align: center;">684K (37+, 463-)</td>
<td style="text-align: center;">341k (31+, 469-)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Compound Treats Disease</td>
<td style="text-align: center;">1.5M</td>
<td style="text-align: center;">441K (96+, 404-)</td>
<td style="text-align: center;">223K (112+, 388-)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Gene Interacts Gene</td>
<td style="text-align: center;">11.2M</td>
<td style="text-align: center;">2.19M (60+, 440-)</td>
<td style="text-align: center;">1.62M (76+, 424-)</td>
</tr>
</tbody>
</table>
</div>
<h3 id="label-functions-for-annotating-sentences">Label Functions for Annotating Sentences</h3>
<p>The challenge of having too few ground truth annotations is familiar to many natural language processing applications, even when unannotated text is abundant.
Data programming circumvents this issue by quickly annotating large datasets using multiple noisy signals emitted by label functions <span class="citation" data-cites="5Il3kN32"><a href="#ref-5Il3kN32" role="doc-biblioref">[10]</a></span>.
Label functions are simple pythonic functions that emit: a positive label (1), a negative label (0), or abstain from emitting a label (-1).
These functions can use different approaches or techniques to emit a label; however, these functions can be grouped into simple categories discussed below.
Once constructed, these functions are combined using a generative model to output a single annotation.
This single annotation is a consensus probability score bounded between 0 (low chance of mentioning a relationship) and 1 (high chance of mentioning a relationship).
We used these annotations to train a discriminative model for the final classification step.</p>
<h4 id="label-function-categories">Label Function Categories</h4>
<p>Label functions can be constructed in various ways; however, they also share similar characteristics.
We grouped functions into databases and text patterns.
The majority of our label functions fall into the text pattern category (Supplemental Table <a href="#tbl:label-functions">2</a>).
Further, we described each label function category and provided an example that refers to the following candidate sentence: “<span class="gene_color">PTK6</span> may be a novel therapeutic target for <span class="disease_color">pancreatic cancer</span>”.</p>
<p><strong>Databases</strong>: These label functions incorporate existing databases to generate a signal, as seen in distant supervision <span class="citation" data-cites="EHeTvZht"><a href="#ref-EHeTvZht" role="doc-biblioref">[4]</a></span>.
These functions detect if a candidate sentence’s co-mention pair is present in a given database.
Our label function emits a positive label if the pair is present and abstains otherwise.
If the pair is not present in any existing database, a separate label function emits a negative label.
We used a separate label function to prevent a label imbalance problem, which can occur when a single function labels every possible sentence despite being correct or not.
If this problem isn’t handled correctly, the generative model could become biased and only emit one prediction (solely positive or solely negative) for every sentence.</p>
<p><span class="math display">\[ \Lambda_{DB}(\color{#875442}{D}, \color{#02b3e4}{G}) = 
\begin{cases}
 1 &amp; (\color{#875442}{D}, \color{#02b3e4}{G}) \in DB \\
0 &amp; otherwise \\
\end{cases} \]</span></p>
<p><span class="math display">\[ \Lambda_{\neg DB}(\color{#875442}{D}, \color{#02b3e4}{G}) = 
\begin{cases}
 -1 &amp; (\color{#875442}{D}, \color{#02b3e4}{G}) \notin DB \\
0 &amp; otherwise \\
\end{cases} \]</span></p>
<p><strong>Text Patterns</strong>: These label functions are designed to use keywords or sentence context to generate a signal.
For example, a label function could focus on the number of words between two mentions and emit a label if two mentions are too close.
Alternatively, a label function could focus on the parts of speech contained within a sentence and ensures a verb is present.
Besides parts of speech, a label function could exploit dependency parse trees to emit a label.
These trees are akin to the tree data structure where words are nodes and edges are how each word modifies each other.
Label functions that use these parse trees will test if the generated tree matches a pattern and emits a positive label if true.
For our analysis, we used previously identified patterns designed for biomedical text to generate our label functions <span class="citation" data-cites="tag:global_network"><a href="#ref-tag:global_network" role="doc-biblioref"><strong>tag:global_network?</strong></a></span>.</p>
<p><span class="math display">\[ \Lambda_{TP}(\color{#875442}{D}, \color{#02b3e4}{G}) = 
\begin{cases}
 1 &amp; &quot;target&quot; \&gt; \in Candidate \&gt; Sentence \\
 -1 &amp; otherwise \\
\end{cases} \]</span></p>
<p><span class="math display">\[ \Lambda_{TP}(\color{#875442}{D}, \color{#02b3e4}{G}) = 
\begin{cases}
 0 &amp;    &quot;VB&quot; \&gt; \notin pos\_tags(Candidate \&gt; Sentence) \\
 -1 &amp; otherwise \\
\end{cases} \]</span></p>
<p><span class="math display">\[
\Lambda_{TP}(\color{#875442}{D}, \color{#02b3e4}{G}) = \begin{cases}
    1 &amp; dep(Candidate \&gt; Sentence) \in Cluster \&gt; Theme\\
    -1 &amp; otherwise \\
    \end{cases}
\]</span></p>
<p>Each text pattern label function was constructed via manual examination of sentences within the training set.
For example, using the candidate sentence above, one would identify the phrase “novel therapeutic target” and incorporate this phrase into a global list that a label function would use to check if present in a sentence.
After initial construction, we tested and augmented the label function using sentences in the tune set.
We repeated this process for every label function in our repertoire.</p>
<div id="tbl:label-functions" class="tablenos">
<table id="tbl:label-functions">
<caption><span>Table 2:</span> The distribution of each label function per relationship. </caption>
<thead>
<tr class="header">
<th>Relationship</th>
<th style="text-align: center;">Databases (DB)</th>
<th style="text-align: center;">Text Patterns (TP)</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>DaG</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>CtD</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td>CbG</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>GiG</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">28</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
</div>
<h3 id="experimental-design">Experimental Design</h3>
<p>Being able to re-use label functions across edge types would substantially reduce the number of label functions required to extract multiple relationships from biomedical literature.
We first established a baseline by training a generative model using only distant supervision label functions designed for the target edge type (see Supplemental Methods).
For example, in the Gene interacts Gene (GiG) edge type we used label functions that returned a 1 if the pair of genes were included in the Human Interaction database <span class="citation" data-cites="LCyCrr7W"><a href="#ref-LCyCrr7W" role="doc-biblioref">[23]</a></span>, the iRefIndex database <span class="citation" data-cites="gtV3bOpd"><a href="#ref-gtV3bOpd" role="doc-biblioref">[31]</a></span> or in the Incomplete Interactome database <span class="citation" data-cites="2jkcXYxN"><a href="#ref-2jkcXYxN" role="doc-biblioref">[32]</a></span>.
Then we compared the baseline model with models that also included text and domain-heuristic label functions.
Using a sampling with replacement approach, we sampled these text and domain-heuristic label functions separately within edge types, across edge types, and from a pool of all label functions.
We compared within-edge-type performance to across-edge-type and all-edge-type performance.
For each edge type we sampled a fixed number of label functions consisting of five evenly spaced numbers between one and the total number of possible label functions.
We repeated this sampling process 50 times for each point.
Furthermore, at each point we also trained the discriminative model using annotations from the generative model trained on edge-specific label functions (see Supplemental Methods).
We report performance of both models in terms of the area under the receiver operating characteristic curve (AUROC) and the area under the precision-recall curve (AUPR).
Ensuing model evaluations, we quantified the number of edges we could incorporate into Hetionet v1.
Using a calibrated discriminative model (see Supplemental Methods), we scored every candidate sentence within our dataset and grouped candidates based on their mention pair.
We took the max score within each candidate group and this score represents the probability of the existence of an edge.
We established edges by using a cutoff score that produced an equal error rate between the false positives and false negatives.
We report the number of preexisting edges we could recall as well as the number of novel edges we can incorporate.
Lastly, we compared our framework with a previously established unsupervised approach <span class="citation" data-cites="tag:cocoscore"><a href="#ref-tag:cocoscore" role="doc-biblioref"><strong>tag:cocoscore?</strong></a></span>.</p>
<h2 id="results">Results</h2>
<h3 id="generative-model-using-randomly-sampled-label-functions">Generative Model Using Randomly Sampled Label Functions</h3>
<p>Creating label functions is a labor-intensive process that can take days to accomplish.
We sought to accelerate this process by measuring the extent to which label functions can be reused.
Our hypothesis was that certain edge types share similar linguistic features such as keywords and/or sentence structure.
This shared characteristic would make certain edge types amenable to label function reuse.
We designed a set of experiments to test this hypothesis on an individual level (edge vs edge) as well as a global level (collective pool of sources).
We observed that performance increased when edge-specific label functions were added to an edge-specific baseline model, while label function reuse usually provided less benefit (AUROC Figure <a href="#fig:auroc_gen_model_test_set">2</a>, AUPR Supplemental Figure <a href="#fig:aupr_gen_model_test_set">5</a>).
We also evaluated randomly selecting label functions from among all sets and observed similar performance (AUROC Supplemental Figure <a href="#fig:auroc_grabbag_gen_model_test_set">6</a>, AUPR Supplemental Figure <a href="#fig:aupr_grabbag_gen_model_test_set">7</a>)
The quintessential example of this overarching trend is the Compound treats Disease (CtD) edge type, where edge-specific label functions always outperformed transferred label functions.
However, there are hints of label function transferability for selected edge types and label function sources.
Performance increases as more CbG label functions are incorporated to the GiG baseline model and vice versa.
This suggests that sentences for GiG and CbG may share similar linguistic features or terminology that allows for label functions to be reused.
Perplexingly, edge-specific Disease associates Gene (DaG) label functions did not improve performance over label functions drawn from other edge types.
Overall, only CbG and GiG showed significant signs of reusability which suggests label functions could be shared between the two edge types.</p>
<div id="fig:auroc_gen_model_test_set" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling/86037d185a299a1f6dd4dd68605073849c72af6f/figures/label_sampling_experiment/transfer_test_set_auroc.png" alt="Figure 2: Edge-specific label functions are better performing than edge-mismatch label functions, but certain mismatch situations show signs of successful transfer. Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions. For example, orange represents sampling label functions designed to predict the Compound treats Disease (CtD) edge type. The x axis shows the number of randomly sampled label functions being incorporated into the database-only baseline model (point at 0). The y axis shows area under the receiver operating curve (AUROC). Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs. The baseline and “All” data points consist of sampling from the entire fixed set of label functions." /><figcaption aria-hidden="true"><span>Figure 2:</span> Edge-specific label functions are better performing than edge-mismatch label functions, but certain mismatch situations show signs of successful transfer.
Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions.
For example, orange represents sampling label functions designed to predict the Compound treats Disease (CtD) edge type.
The x axis shows the number of randomly sampled label functions being incorporated into the database-only baseline model (point at 0).
The y axis shows area under the receiver operating curve (AUROC).
Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.</figcaption>
</figure>
</div>
<p>We found that sampling from all label function sources at once usually underperformed relative to edge-specific label functions (Supplemental Figures <a href="#fig:auroc_grabbag_gen_model_test_set">6</a> and <a href="#fig:aupr_grabbag_gen_model_test_set">7</a>).
As more label functions were sampled, the gap between edge-specific sources and all sources widened.
CbG is a prime example of this trend (Supplemental Figures <a href="#fig:auroc_grabbag_gen_model_test_set">6</a> and <a href="#fig:aupr_grabbag_gen_model_test_set">7</a>), while CtD and GiG show a similar but milder trend.
DaG was the exception to the general rule: the pooled set of label functions improved performance over the edge-specific ones, which aligns with the previously observed results for individual edge types (Figure <a href="#fig:auroc_gen_model_test_set">2</a>).
The decreasing trend when pooling all label functions supports the notion that label functions cannot easily transfer between edge types (exception being CbG on GiG and vice versa).</p>
<h3 id="discriminative-model-performance">Discriminative Model Performance</h3>
<p>The discriminative model is designed to augment performance over the generative model by incorporating textual features along with estimated training labels.
The discriminative model is a piecewise convolutional neural network trained over word embeddings (See Methods and Materials).
We found that the discriminative model generally out-performed the generative model as more edge-specific label functions are incorporated (Figure <a href="#fig:auroc_discriminative_model_performance">3</a> and Supplemental Figure <a href="#fig:aupr_discriminative_model_performance">8</a>).
The discriminative model’s performance is often poorest when very few edge-specific label functions are added to the baseline model (seen in Disease associates Gene (DaG), Compound binds Gene (CbG) and Gene interacts Gene (GiG)).
This suggests that generative models trained with more label functions produce outputs that are more suitable for training discriminative models.
An exception to this trend is Compound treats Disease (CtD) where the discriminative model out-performs the generative model at all levels of sampling.
We observed the opposite trend with the Compound-binds-Gene (CbG) edges: the discriminative model was always poorer or indistinguishable from the generative model.
Interestingly, the AUPR for CbG plateaus below the generative model and decreases when all edge-specific label functions are used (Supplemental Figure <a href="#fig:aupr_discriminative_model_performance">8</a>).
This suggests that the discriminative model might be predicting more false positives in this setting.
Incorporating more edge-specific label functions usually improves performance for the discriminative model over the generative model.</p>
<div id="fig:auroc_discriminative_model_performance" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling/c76e683a7bbc97482335ed4ac9ef8ab81c46114d/figures/disc_model_experiment/disc_model_test_auroc.png" alt="Figure 3: The discriminative model usually improves at a faster rate than the generative model as more edge-specific label function are included. The line plot headers represent the specific edge type the discriminative model is trying to predict. The x-axis shows the number of randomly sampled label functions that are incorporated into the baseline model (point at 0). The y axis shows the area under the receiver operating curve (AUROC). Each datapoint represents the average of 50 sample runs and the error bars represent the 95% confidence interval of each run. The baseline and “All” data points consist of sampling from the entire fixed set of label functions." /><figcaption aria-hidden="true"><span>Figure 3:</span> The discriminative model usually improves at a faster rate than the generative model as more edge-specific label function are included.
The line plot headers represent the specific edge type the discriminative model is trying to predict.
The x-axis shows the number of randomly sampled label functions that are incorporated into the baseline model (point at 0).
The y axis shows the area under the receiver operating curve (AUROC).
Each datapoint represents the average of 50 sample runs and the error bars represent the 95% confidence interval of each run.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.</figcaption>
</figure>
</div>
<h2 id="discussion">Discussion</h2>
<p>We measured the extent to which label functions can be re-used across multiple edge types to extract relationships from literature.
Through our sampling experiment, we found that adding edge-specific label functions increases performance for the generative model (Figure <a href="#fig:auroc_gen_model_test_set">2</a>).
We found that label functions designed from relatively related edge types can increase performance (Gene interacts Gene (GiG) label functions predicting the Compound binds Gene (CbG) edge and vice versa), while the Disease associates Gene (DaG) edge type remained agnostic to label function sources (Figure <a href="#fig:auroc_gen_model_test_set">2</a> and Supplemental Figure <a href="#fig:aupr_gen_model_test_set">5</a>).
Furthermore, we found that using all label functions at once generally hurts performance with the exception being the DaG edge type (Supplemental Figures <a href="#fig:auroc_grabbag_gen_model_test_set">6</a> and <a href="#fig:aupr_grabbag_gen_model_test_set">7</a>).
One possibility for this observation is that DaG is a broadly defined edge type.
For example, DaG may contain many concepts related to other edge types such as Disease (up/down) regulating a Gene, which makes it more agnostic to label function sources (examples highlighted in our <a href="https://github.com/greenelab/text_mined_hetnet_manuscript/tree/master/supplementary_materials/annotated_sentences">annotated sentences</a>).</p>
<p>Regarding the discriminative model, adding edge-specific label function substantially improved performance for two out of the four edge types (Compound treats Disease (CtD) and Disease associates Gene (DaG)) (Figure <a href="#fig:auroc_discriminative_model_performance">3</a> and Supplemental Figure <a href="#fig:aupr_discriminative_model_performance">8</a>).
Gene interacts Gene (GiG) and Compound binds Gene (CbG) discriminative models showed minor improvements compared to the generative model, but only when nearly all edge-specific label functions are included (Figure <a href="#fig:auroc_discriminative_model_performance">3</a> and Supplemental Figure <a href="#fig:aupr_discriminative_model_performance">8</a>).
We came across a large amount of spurious gene mentions when working with the discriminative model and believe that these mentions contributed to CbG and GiG’s hindered performance.
We encountered difficulty in calibrating each discriminative model (Supplemental Figure <a href="#fig:discriminative_model_calibration">9</a>).
The temperature scaling algorithm appears to improve calibration for the highest scores for each model but did not successfully calibrate throughout the entire range of predictions.
Improving performance for all predictions may require more labeled examples or may be a limitation of the approach in this setting.
Even with these limitations, this early-stage approach could recall many existing edges from an existing knowledge base, Hetionet v1, and suggest many new high-confidence edges for inclusion (Supplemental Figure <a href="#fig:hetionet_reconstruction">10</a>).
Our findings suggest that further work, including an expansion of edge types and a move to full text from abstracts, may make this approach suitable for building continuously updated knowledge bases to address drug repositioning and other biomedical challenges.</p>
<h2 id="conclusion-and-future-direction">Conclusion and Future Direction</h2>
<p>Filling out knowledge bases via manual curation can be an arduous and erroneous task <span class="citation" data-cites="UdzvLgBM"><a href="#ref-UdzvLgBM" role="doc-biblioref">[8]</a></span>.
As the rate of publications increases, relying on manual curation alone becomes impractical.
Data programming, a paradigm that uses label functions as a means to speed up the annotation process, can be used as a solution for this problem.
An obstacle for this paradigm, however, is creating useful label functions, which takes a considerable amount of time.
We tested the feasibility of reusing label functions as a way to reduce the total number of label functions required for strong prediction performance.
We conclude that label functions may be re-used with closely related edge types, but that re-use does not improve performance for most pairings.
The discriminative model’s performance improves as more edge-specific label functions are incorporated into the generative model; however, we did notice that performance greatly depends on the annotations provided by the generative model.</p>
<p>This work sets up the foundation for creating a common framework that mines text to create edges.
Within this framework we would continuously incorporate new knowledge as novel findings are published, while providing a single confidence score for an edge via sentence score consolidation.
As opposed to many existing knowledge graphs (for example, Hetionet v1 where text-derived edges generally cannot be exactly attributed to excerpts from literature <span class="citation" data-cites="O21tn8vf L2B5V7XC"><a href="#ref-O21tn8vf" role="doc-biblioref">[3]</a>, <a href="#ref-L2B5V7XC" role="doc-biblioref">[33]</a></span>), our approach has the potential to annotate each edge based on its source sentences.
In addition, edges generated with this approach would be unencumbered from upstream licensing or copyright restrictions, enabling openly licensed hetnets at a scale not previously possible <span class="citation" data-cites="4G0GW8oe 137tbemL9 1GwdMLPbV"><a href="#ref-4G0GW8oe" role="doc-biblioref">[34]</a>–<a href="#ref-1GwdMLPbV" role="doc-biblioref">[36]</a></span>.
New multitask learning <span class="citation" data-cites="9Jo1af7Z"><a href="#ref-9Jo1af7Z" role="doc-biblioref">[37]</a></span> strategies may make it even more practical to reuse label functions to construct continuously updating literature-derived knowledge graphs.</p>
<h2 id="supplemental-information">Supplemental Information</h2>
<p>An online version of this manuscript is available at <a href="https://greenelab.github.io/text_mined_hetnet_manuscript/" class="uri">https://greenelab.github.io/text_mined_hetnet_manuscript/</a>.
Labeled sentences are available at <a href="https://github.com/greenelab/text_mined_hetnet_manuscript/tree/master/supplementary_materials/annotated_sentences">https://github.com/greenelab/text_mined_hetnet_manuscript/tree/master/supplementary_materials/annotated_sentences</a>.
Source code for this work is available under open licenses at: <a href="https://github.com/greenelab/snorkeling/" class="uri">https://github.com/greenelab/snorkeling/</a>.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>The authors would like to thank Christopher Ré’s group at Stanford University, especially Alex Ratner and Steven Bach, for their assistance with this project.
We also want to thank Graciela Gonzalez-Hernandez for her advice and input with this project.
This work was support by <a href="https://www.moore.org/grant-detail?grantId=GBMF4552">Grant GBMF4552</a> from the Gordon Betty Moore Foundation.</p>
<h2 class="page_break_before" id="references">References</h2>
<!-- Explicitly insert bibliography here -->
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-u8pIAt5j" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">R. Gramatica, T. Di Matteo, S. Giorgetti, M. Barbiani, D. Bevec, and T. Aste, <span>“Graph Theory Enables Drug Repurposing – How a Mathematical Model Can Drive the Discovery of Hidden Mechanisms of Action,”</span> <em>PLoS ONE</em>, vol. 9, no. 1, p. e84912, Jan. 2014 [Online]. Available: <a href="https://doi.org/gf45zp">https://doi.org/gf45zp</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-bPvC638e" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">M. Alshahrani and R. Hoehndorf, <span>“Drug repurposing through joint learning on knowledge graphs and literature,”</span> Bioinformatics, preprint, Aug. 2018 [Online]. Available: <a href="https://doi.org/gf45zk">https://doi.org/gf45zk</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-O21tn8vf" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">D. S. Himmelstein <em>et al.</em>, <span>“Systematic integration of biomedical knowledge prioritizes drugs for repurposing,”</span> <em>eLife</em>, vol. 6, p. e26726, Sep. 2017 [Online]. Available: <a href="https://doi.org/cdfk">https://doi.org/cdfk</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-EHeTvZht" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">M. Mintz, S. Bills, R. Snow, and D. Jurafsky, <span>“Distant supervision for relation extraction without labeled data,”</span> in <em>Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2 - ACL-IJCNLP '09</em>, Suntec, Singapore, 2009, vol. 2, p. 1003 [Online]. Available: <a href="https://doi.org/fg9q43">https://doi.org/fg9q43</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-CVHSURuI" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">A. Junge and L. J. Jensen, <span>“CoCoScore: Context-aware co-occurrence scoring for text mining applications using distant supervision,”</span> Bioinformatics, preprint, Oct. 2018 [Online]. Available: <a href="https://doi.org/gf45zm">https://doi.org/gf45zm</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-HS4ARwmZ" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">H. Zhou, C. Lang, Z. Liu, S. Ning, Y. Lin, and L. Du, <span>“Knowledge-guided convolutional networks for chemical-disease relation extraction,”</span> <em>BMC Bioinformatics</em>, vol. 20, no. 1, p. 260, Dec. 2019 [Online]. Available: <a href="https://doi.org/gf45zn">https://doi.org/gf45zn</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-N1Ai0gaI" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">R. Winnenburg, T. Wachter, C. Plake, A. Doms, and M. Schroeder, <span>“Facts from text: can text mining help to scale-up high-quality manual curation of gene products with ontologies?”</span> <em>Briefings in Bioinformatics</em>, vol. 9, no. 6, pp. 466–478, Jul. 2008 [Online]. Available: <a href="https://doi.org/bfsnwg">https://doi.org/bfsnwg</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-UdzvLgBM" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">W. A. Baumgartner, K. B. Cohen, L. M. Fox, G. Acquaah-Mensah, and L. Hunter, <span>“Manual curation is not sufficient for annotation of genomic databases,”</span> <em>Bioinformatics</em>, vol. 23, no. 13, pp. i41–i48, Jul. 2007 [Online]. Available: <a href="https://doi.org/dtck86">https://doi.org/dtck86</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-1DBISRlwN" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">L. Bornmann and R. Mutz, <span>“Growth rates of modern science: A bibliometric analysis based on the number of publications and cited references: Growth Rates of Modern Science: A Bibliometric Analysis Based on the Number of Publications and Cited References,”</span> <em>Journal of the Association for Information Science and Technology</em>, vol. 66, no. 11, pp. 2215–2222, Nov. 2015 [Online]. Available: <a href="https://doi.org/gfj5zc">https://doi.org/gfj5zc</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-5Il3kN32" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">A. Ratner, C. De Sa, S. Wu, D. Selsam, and C. Ré, <span>“Data Programming: Creating Large Training Sets, Quickly,”</span> arXiv, 1605.07723, Dec. 2018 [Online]. Available: <a href="https://arxiv.org/abs/1605.07723">https://arxiv.org/abs/1605.07723</a></div>
</div>
<div id="ref-KEkjqdB0" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">M. Torii, C. N. Arighi, G. Li, Q. Wang, C. H. Wu, and K. Vijay-Shanker, <span>“RLIMS-P 2.0: A Generalizable Rule-Based Information Extraction System for Literature Mining of Protein Phosphorylation Information,”</span> <em>IEEE/ACM Transactions on Computational Biology and Bioinformatics</em>, vol. 12, no. 1, pp. 17–29, Jan. 2015 [Online]. Available: <a href="https://doi.org/gf8fpv">https://doi.org/gf8fpv</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-d3rG3TXb" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">H.-M. Müller, K. M. Van Auken, Y. Li, and P. W. Sternberg, <span>“Textpresso Central: a customizable platform for searching, text mining, viewing, and curating biomedical literature,”</span> <em>BMC Bioinformatics</em>, vol. 19, no. 1, p. 94, Dec. 2018 [Online]. Available: <a href="https://doi.org/gf7rbz">https://doi.org/gf7rbz</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-B8EOgoNA" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">J. X. Binder <em>et al.</em>, <span>“COMPARTMENTS: unification and visualization of protein subcellular localization evidence,”</span> <em>Database</em>, vol. 2014, no. 0, pp. bau012–bau012, Feb. 2014 [Online]. Available: <a href="https://doi.org/btbm">https://doi.org/btbm</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-6QECA6Hm" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">A. Santos, K. Tsafou, C. Stolte, S. Pletscher-Frankild, S. I. O’Donoghue, and L. J. Jensen, <span>“Comprehensive comparison of large-scale tissue expression datasets,”</span> <em>PeerJ</em>, vol. 3, p. e1054, Jun. 2015 [Online]. Available: <a href="https://doi.org/f3mn6p">https://doi.org/f3mn6p</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-RQkLuc5t" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">C. Manning, M. Surdeanu, J. Bauer, J. Finkel, S. Bethard, and D. McClosky, <span>“The Stanford CoreNLP Natural Language Processing Toolkit,”</span> in <em>Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</em>, Baltimore, Maryland, 2014, pp. 55–60 [Online]. Available: <a href="https://doi.org/gf3xhp">https://doi.org/gf3xhp</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-199TFjkrC" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline">L. J. Jensen, J. Saric, and P. Bork, <span>“Literature mining for the biologist: from information retrieval to biological discovery,”</span> <em>Nature Reviews Genetics</em>, vol. 7, no. 2, pp. 119–129, Feb. 2006 [Online]. Available: <a href="https://doi.org/bgq7q9">https://doi.org/bgq7q9</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-1ZjlFRHa" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[17] </div><div class="csl-right-inline">W. W. M. Fleuren and W. Alkema, <span>“Application of text mining in the biomedical domain,”</span> <em>Methods</em>, vol. 74, pp. 97–106, Mar. 2015 [Online]. Available: <a href="https://doi.org/f64p6n">https://doi.org/f64p6n</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-16As8893j" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[18] </div><div class="csl-right-inline">M. Krallinger, O. Rabal, S. A. Akhondi, <em>et al.</em>, <span>“Overview of the biocreative vi chemical-protein interaction track,”</span> in <em>Proceedings of the sixth biocreative challenge evaluation workshop</em>, 2017, vol. 1, pp. 141–146 [Online]. Available: <a href="https://www.semanticscholar.org/paper/Overview-of-the-BioCreative-VI-chemical-protein-Krallinger-Rabal/eed781f498b563df5a9e8a241c67d63dd1d92ad5">https://www.semanticscholar.org/paper/Overview-of-the-BioCreative-VI-chemical-protein-Krallinger-Rabal/eed781f498b563df5a9e8a241c67d63dd1d92ad5</a></div>
</div>
<div id="ref-DR8XM4Ff" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[19] </div><div class="csl-right-inline">S. Pyysalo, A. Airola, J. Heimonen, J. Björne, F. Ginter, and T. Salakoski, <span>“Comparative analysis of five protein-protein interaction corpora,”</span> <em>BMC Bioinformatics</em>, vol. 9, no. S3, p. S6, Apr. 2008 [Online]. Available: <a href="https://doi.org/fh3df7">https://doi.org/fh3df7</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-uujIm995" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[20] </div><div class="csl-right-inline">M. A. Hearst, S. T. Dumais, E. Osuna, J. Platt, and B. Scholkopf, <span>“Support vector machines,”</span> <em>IEEE Intelligent Systems and their Applications</em>, vol. 13, no. 4, pp. 18–28, Jul. 1998 [Online]. Available: <a href="https://doi.org/fwgxrj">https://doi.org/fwgxrj</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-BQS8ClV0" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[21] </div><div class="csl-right-inline">J. Schmidhuber, <span>“Deep learning in neural networks: An overview,”</span> <em>Neural Networks</em>, vol. 61, pp. 85–117, Jan. 2015 [Online]. Available: <a href="https://doi.org/f6v78n">https://doi.org/f6v78n</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-16cIDAXhG" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[22] </div><div class="csl-right-inline">J. MacArthur <em>et al.</em>, <span>“The new NHGRI-EBI Catalog of published genome-wide association studies (GWAS Catalog),”</span> <em>Nucleic Acids Research</em>, vol. 45, no. D1, pp. D896–D901, Jan. 2017 [Online]. Available: <a href="https://doi.org/f9v7cp">https://doi.org/f9v7cp</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-LCyCrr7W" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[23] </div><div class="csl-right-inline">T. Rolland <em>et al.</em>, <span>“A Proteome-Scale Map of the Human Interactome Network,”</span> <em>Cell</em>, vol. 159, no. 5, pp. 1212–1226, Nov. 2014 [Online]. Available: <a href="https://doi.org/f3mn6x">https://doi.org/f3mn6x</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-1FI8iuYiQ" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[24] </div><div class="csl-right-inline">D. S. Wishart <em>et al.</em>, <span>“DrugBank 5.0: a major update to the DrugBank database for 2018,”</span> <em>Nucleic Acids Research</em>, vol. 46, no. D1, pp. D1074–D1082, Jan. 2018 [Online]. Available: <a href="https://doi.org/gcwtzk">https://doi.org/gcwtzk</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-18ZyyTcTe" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[25] </div><div class="csl-right-inline">C.-H. Wei, A. Allot, R. Leaman, and Z. Lu, <span>“PubTator central: automated concept annotation for biomedical full text articles,”</span> <em>Nucleic Acids Research</em>, vol. 47, no. W1, pp. W587–W593, Jul. 2019 [Online]. Available: <a href="https://doi.org/ggzfsc">https://doi.org/ggzfsc</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-11YUuHulp" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[26] </div><div class="csl-right-inline">R. Leaman and Z. Lu, <span>“TaggerOne: joint named entity recognition and normalization with semi-Markov Models,”</span> <em>Bioinformatics</em>, vol. 32, no. 18, pp. 2839–2846, Sep. 2016 [Online]. Available: <a href="https://doi.org/f855dg">https://doi.org/f855dg</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-17LQKv7vO" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[27] </div><div class="csl-right-inline">C.-H. Wei, L. Phan, J. Feltz, R. Maiti, T. Hefferon, and Z. Lu, <span>“tmVar 2.0: integrating genomic variant information from literature with dbSNP and ClinVar for precision medicine,”</span> <em>Bioinformatics</em>, vol. 34, no. 1, pp. 80–87, Jan. 2018 [Online]. Available: <a href="https://doi.org/gbzsmc">https://doi.org/gbzsmc</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-aOPX10e0" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[28] </div><div class="csl-right-inline">C.-H. Wei, H.-Y. Kao, and Z. Lu, <span>“GNormPlus: An Integrative Approach for Tagging Genes, Gene Families, and Protein Domains,”</span> <em>BioMed Research International</em>, vol. 2015, pp. 1–7, 2015 [Online]. Available: <a href="https://doi.org/gb85jb">https://doi.org/gb85jb</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-NXIFrudx" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[29] </div><div class="csl-right-inline">C.-H. Wei, H.-Y. Kao, and Z. Lu, <span>“SR4GN: A Species Recognition Software Tool for Gene Normalization,”</span> <em>PLoS ONE</em>, vol. 7, no. 6, p. e38460, Jun. 2012 [Online]. Available: <a href="https://doi.org/gpq498">https://doi.org/gpq498</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-q2fFAZTG" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[30] </div><div class="csl-right-inline">M. Honnibal and I. Montani, <span>“spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing,”</span> 2017. </div>
</div>
<div id="ref-gtV3bOpd" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[31] </div><div class="csl-right-inline">S. Razick, G. Magklaras, and I. M. Donaldson, <span>“iRefIndex: A consolidated protein interaction database with provenance,”</span> <em>BMC Bioinformatics</em>, vol. 9, no. 1, p. 405, Dec. 2008 [Online]. Available: <a href="https://doi.org/b99bjj">https://doi.org/b99bjj</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-2jkcXYxN" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[32] </div><div class="csl-right-inline">J. Menche <em>et al.</em>, <span>“Uncovering disease-disease relationships through the incomplete interactome,”</span> <em>Science</em>, vol. 347, no. 6224, pp. 1257601–1257601, Feb. 2015 [Online]. Available: <a href="https://doi.org/f3mn6z">https://doi.org/f3mn6z</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-L2B5V7XC" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[33] </div><div class="csl-right-inline"><span>“[No title found].”</span> [Online]. Available: <a href="https://doi.org/f3mqwp">https://doi.org/f3mqwp</a></div>
</div>
<div id="ref-4G0GW8oe" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[34] </div><div class="csl-right-inline"><span>“[No title found].”</span> [Online]. Available: <a href="https://doi.org/bfmk">https://doi.org/bfmk</a></div>
</div>
<div id="ref-137tbemL9" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[35] </div><div class="csl-right-inline">S. Oxenham, <span>“Legal confusion threatens to slow data science,”</span> <em>Nature</em>, vol. 536, no. 7614, pp. 16–17, Aug. 2016 [Online]. Available: <a href="https://doi.org/bndt">https://doi.org/bndt</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-1GwdMLPbV" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[36] </div><div class="csl-right-inline">S. Carbon, R. Champieux, J. A. McMurry, L. Winfree, L. R. Wyatt, and M. A. Haendel, <span>“An analysis and metric of reusable data licensing practices for biomedical resources,”</span> <em>PLOS ONE</em>, vol. 14, no. 3, p. e0213090, Mar. 2019 [Online]. Available: <a href="https://doi.org/gf5m8v">https://doi.org/gf5m8v</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-9Jo1af7Z" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[37] </div><div class="csl-right-inline">A. Ratner, B. Hancock, J. Dunnmon, R. Goldman, and C. Ré, <span>“Snorkel MeTaL: Weak Supervision for Multi-Task Learning,”</span> in <em>Proceedings of the Second Workshop on Data Management for End-To-End Machine Learning</em>, Houston TX USA, 2018, pp. 1–4 [Online]. Available: <a href="https://doi.org/gf3xk7">https://doi.org/gf3xk7</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-vzoBuh4l" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[38] </div><div class="csl-right-inline">A. Ratner, S. H. Bach, H. Ehrenberg, J. Fries, S. Wu, and C. Ré, <span>“Snorkel: rapid training data creation with weak supervision,”</span> <em>Proceedings of the VLDB Endowment</em>, vol. 11, no. 3, pp. 269–282, Nov. 2017 [Online]. Available: <a href="https://doi.org/ch44">https://doi.org/ch44</a>. [Accessed: 29-Mar-2022]</div>
</div>
<div id="ref-fs8rAHoJ" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[39] </div><div class="csl-right-inline">Y. Zhang and B. Wallace, <span>“A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification,”</span> arXiv, 1510.03820, Apr. 2016 [Online]. Available: <a href="https://arxiv.org/abs/1510.03820">https://arxiv.org/abs/1510.03820</a></div>
</div>
<div id="ref-c6d3lKFX" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[40] </div><div class="csl-right-inline">D. P. Kingma and J. Ba, <span>“Adam: A Method for Stochastic Optimization,”</span> arXiv, 1412.6980, Jan. 2017 [Online]. Available: <a href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a></div>
</div>
<div id="ref-u5iJzbp9" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[41] </div><div class="csl-right-inline">T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean, <span>“Distributed Representations of Words and Phrases and their Compositionality,”</span> arXiv, 1310.4546, Oct. 2013 [Online]. Available: <a href="https://arxiv.org/abs/1310.4546">https://arxiv.org/abs/1310.4546</a></div>
</div>
<div id="ref-qUpCDz2v" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[42] </div><div class="csl-right-inline">P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, <span>“Enriching Word Vectors with Subword Information,”</span> arXiv, 1607.04606, Jun. 2017 [Online]. Available: <a href="https://arxiv.org/abs/1607.04606">https://arxiv.org/abs/1607.04606</a></div>
</div>
<div id="ref-1GhHIDxuW" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[43] </div><div class="csl-right-inline">T. Mikolov, K. Chen, G. Corrado, and J. Dean, <span>“Efficient Estimation of Word Representations in Vector Space,”</span> arXiv, 1301.3781, Sep. 2013 [Online]. Available: <a href="https://arxiv.org/abs/1301.3781">https://arxiv.org/abs/1301.3781</a></div>
</div>
<div id="ref-QJ6hYH8N" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[44] </div><div class="csl-right-inline">C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger, <span>“On Calibration of Modern Neural Networks,”</span> arXiv, 1706.04599, Aug. 2017 [Online]. Available: <a href="https://arxiv.org/abs/1706.04599">https://arxiv.org/abs/1706.04599</a></div>
</div>
<div id="ref-rLVjMJ5l" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[45] </div><div class="csl-right-inline">V. Kuleshov, N. Fenner, and S. Ermon, <span>“Accurate Uncertainties for Deep Learning Using Calibrated Regression,”</span> arXiv, 1807.00263, Jul. 2018 [Online]. Available: <a href="https://arxiv.org/abs/1807.00263">https://arxiv.org/abs/1807.00263</a></div>
</div>
</div>
<h2 id="supplemental-methods">Supplemental Methods</h2>
<h3 id="training-models">Training Models</h3>
<h4 id="generative-model">Generative Model</h4>
<p>The generative model is a core part of this automatic annotation framework.
It integrates multiple signals emitted by label functions and assigns a training class to each candidate sentence.
This model assigns training classes by estimating the joint probability distribution of the latent true class (<span class="math inline">\(Y\)</span>) and label function signals (<span class="math inline">\(\Lambda\)</span>), (<span class="math inline">\(P_{\theta}(\Lambda, Y)\)</span>).
Assuming each label function is conditionally independent, the joint distribution is defined as follows:</p>
<p><span class="math display">\[
P_{\theta}(\Lambda, Y) = \frac{\exp(\sum_{i=1}^{m} \theta^{T}F_{i}(\Lambda, y))}
{\sum_{\Lambda&#39;}\sum_{y&#39;} \exp(\sum_{i=1}^{m} \theta^{T}F_{i}(\Lambda&#39;, y&#39;))}
\]</span></p>
<p>where <span class="math inline">\(m\)</span> is the number of candidate sentences, <span class="math inline">\(F\)</span> is the vector of summary statistics and <span class="math inline">\(\theta\)</span> is a vector of weights for each summary statistic.
The summary statistics used by the generative model are as follows:</p>
<p><span class="math display">\[F^{Lab}_{i,j}(\Lambda, Y) = \unicode{x1D7D9}\{\Lambda_{i,j} \neq 0\}\]</span>
<span class="math display">\[F^{Acc}_{i,j}(\Lambda, Y) = \unicode{x1D7D9}\{\Lambda_{i,j} = y_{i,j}\}\]</span></p>
<p><em>Lab</em> is the label function’s propensity (the frequency of a label function emitting a signal).
<em>Acc</em> is the individual label function’s accuracy given the training class.
This model optimizes the weights (<span class="math inline">\(\theta\)</span>) by minimizing the negative log likelihood:</p>
<p><span class="math display">\[\hat{\theta} = argmin_{\theta} -\sum_{\Lambda} \sum_{Y} log P_{\theta}(\Lambda, Y)\]</span></p>
<p>In the framework we used predictions from the generative model, <span class="math inline">\(\hat{Y} = P_{\hat{\theta}}(Y \mid \Lambda)\)</span>, as training classes for our dataset <span class="citation" data-cites="vzoBuh4l 9Jo1af7Z"><a href="#ref-9Jo1af7Z" role="doc-biblioref">[37]</a>, <a href="#ref-vzoBuh4l" role="doc-biblioref">[38]</a></span>.</p>
<h4 id="discriminative-model">Discriminative Model</h4>
<p>The discriminative model is a neural network trained to produce classification labels by integrating predicted probabilities from the generative model along with sentence representations via word embeddings.
The goal of this combined approach is to develop models that learn text features associated with the overall task, beyond the supplied label functions.
We used a piecewise convolutional neural network that contains multiple kernel filters as our discriminative model.
We built a network with multiple filters using a fixed width of 300 (size of word embeddings) and a fixed height of 7 (Figure <a href="#fig:convolutional_network">4</a>).
We chose a fixed height of 7 because this height was previously reported to optimize performance in relationship classification <span class="citation" data-cites="fs8rAHoJ"><a href="#ref-fs8rAHoJ" role="doc-biblioref">[39]</a></span>.
We trained this model for 15 epochs using the Adam optimizer <span class="citation" data-cites="c6d3lKFX"><a href="#ref-c6d3lKFX" role="doc-biblioref">[40]</a></span> with PyTorch’s default parameter settings and a learning rate of 0.001 that decreases by half every epoch until the lower bound of 1e-5 is reached, which we observed was often sufficient for convergence.
We added a L2 penalty (lambda=0.002) on the network weights to prevent overfitting.
Lastly, we added a dropout layer (p=0.25) between the fully connected layer and the softmax layer.</p>
<div id="fig:convolutional_network" class="fignos">
<figure>
<img src="images/figures/convolutional_neural_network/convolutional_neural_nework.png" alt="Figure 4: The architecture of the discriminative model was a convolutional neural network. We performed a convolution step using multiple filters. The filters generated a feature map that was sent into a maximum pooling layer that was designed to extract the largest feature in each map. The extracted features were concatenated into a singular vector that was passed into a fully connected network. The fully connected network had 300 neurons for the first layer, 100 neurons for the second layer and 50 neurons for the last layer. The last step of the fully connected network was to generate predictions using a softmax layer." /><figcaption aria-hidden="true"><span>Figure 4:</span> The architecture of the discriminative model was a convolutional neural network.
We performed a convolution step using multiple filters.
The filters generated a feature map that was sent into a maximum pooling layer that was designed to extract the largest feature in each map.
The extracted features were concatenated into a singular vector that was passed into a fully connected network.
The fully connected network had 300 neurons for the first layer, 100 neurons for the second layer and 50 neurons for the last layer.
The last step of the fully connected network was to generate predictions using a softmax layer.</figcaption>
</figure>
</div>
<h4 id="word-embeddings">Word Embeddings</h4>
<p>Word embeddings are representations that map individual words to real valued vectors of user-specified dimensions.
These embeddings have been shown to capture the semantic and syntactic information between words <span class="citation" data-cites="u5iJzbp9"><a href="#ref-u5iJzbp9" role="doc-biblioref">[41]</a></span>.
We trained Facebook’s fastText <span class="citation" data-cites="qUpCDz2v"><a href="#ref-qUpCDz2v" role="doc-biblioref">[42]</a></span> using all candidate sentences for each individual relationship pair to generate word embeddings.
FastText uses a skip-gram model <span class="citation" data-cites="1GhHIDxuW"><a href="#ref-1GhHIDxuW" role="doc-biblioref">[43]</a></span> that aims to predict the surrounding context for a candidate word and pairs the model with a novel scoring function that treats each word as a bag of character n-grams.
We trained this model for 20 epochs using a window size of 2 and generated 300-dimensional word embeddings.
We use the optimized word embeddings as input to our discriminative model.</p>
<h4 id="calibration-of-the-discriminative-model">Calibration of the Discriminative Model</h4>
<p>Often many tasks require a machine learning model to output reliable probability predictions.
A model is well calibrated if the probabilities emitted from the model match the observed probabilities.
For example, a well-calibrated model that assigns a class label with 80% probability should have that class appear 80% of the time.
Deep neural network models can often be poorly calibrated <span class="citation" data-cites="QJ6hYH8N rLVjMJ5l"><a href="#ref-QJ6hYH8N" role="doc-biblioref">[44]</a>, <a href="#ref-rLVjMJ5l" role="doc-biblioref">[45]</a></span>.
These models are usually over-confident in their predictions.
For this reason, we calibrated our convolutional neural network using temperature scaling <span class="citation" data-cites="QJ6hYH8N"><a href="#ref-QJ6hYH8N" role="doc-biblioref">[44]</a></span>.
Temperature scaling uses a parameter T to scale each value of the logit vector (z) before being passed into the softmax (SM) function.</p>
<p><span class="math display">\[\sigma_{SM}(\frac{z_{i}}{T}) = \frac{\exp(\frac{z_{i}}{T})}{\sum_{i}\exp(\frac{z_{i}}{T})}\]</span></p>
<p>We found the optimal T by minimizing the negative log likelihood (NLL) of the tune set.</p>
<h2 id="supplemental-figures">Supplemental Figures</h2>
<h3 id="generative-model-using-randomly-sampled-label-functions-1">Generative Model Using Randomly Sampled Label Functions</h3>
<h4 id="individual-sources">Individual Sources</h4>
<div id="fig:aupr_gen_model_test_set" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling/86037d185a299a1f6dd4dd68605073849c72af6f/figures/label_sampling_experiment/transfer_test_set_aupr.png" alt="Figure 5: Edge-specific label functions improves performance over edge-mismatch label functions. Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions. For example orange represents sampling label functions designed to predict the Compound treats Disease (CtD) edge type. The x axis shows the number of randomly sampled label functions being incorporated into the database-only baseline model (point at 0). The y axis shows area under the precision recall curve (AUPR). Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs. The baseline and “All” data points consist of sampling from the entire fixed set of label functions." /><figcaption aria-hidden="true"><span>Figure 5:</span> Edge-specific label functions improves performance over edge-mismatch label functions.
Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions.
For example orange represents sampling label functions designed to predict the Compound treats Disease (CtD) edge type.
The x axis shows the number of randomly sampled label functions being incorporated into the database-only baseline model (point at 0).
The y axis shows area under the precision recall curve (AUPR).
Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.</figcaption>
</figure>
</div>
<h4 id="collective-pool-of-sources">Collective Pool of Sources</h4>
<div id="fig:auroc_grabbag_gen_model_test_set" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling/86037d185a299a1f6dd4dd68605073849c72af6f/figures/label_sampling_experiment/all_lf_test_set_auroc.png" alt="Figure 6: Using all label functions generally hinders generative model performance. Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions. For example, orange represents sampling label functions designed to predict the Compound treats Disease (CtD) edge type. The x axis shows the number of randomly sampled label functions being incorporated into the database-only baseline model (point at 0). The y axis shows area under the receiver operating curve (AUROC). Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs. The baseline and “All” data points consist of sampling from the entire fixed set of label functions." /><figcaption aria-hidden="true"><span>Figure 6:</span> Using all label functions generally hinders generative model performance.
Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions.
For example, orange represents sampling label functions designed to predict the Compound treats Disease (CtD) edge type.
The x axis shows the number of randomly sampled label functions being incorporated into the database-only baseline model (point at 0).
The y axis shows area under the receiver operating curve (AUROC).
Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.</figcaption>
</figure>
</div>
<div id="fig:aupr_grabbag_gen_model_test_set" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling/86037d185a299a1f6dd4dd68605073849c72af6f/figures/label_sampling_experiment/all_lf_test_set_aupr.png" alt="Figure 7: Using all label functions generally hinders generative model performance. Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions. For example, orange represents sampling label functions designed to predict the Compound treats Disease (CtD) edge type. The x axis shows the number of randomly sampled label functions being incorporated into the database-only baseline model (point at 0). The y axis shows area under the precision recall curve (AUPR). Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs. The baseline and “All” data points consist of sampling from the entire fixed set of label functions." /><figcaption aria-hidden="true"><span>Figure 7:</span> Using all label functions generally hinders generative model performance.
Each line plot header depicts the edge type the generative model is trying to predict, while the colors represent the source of label functions.
For example, orange represents sampling label functions designed to predict the Compound treats Disease (CtD) edge type.
The x axis shows the number of randomly sampled label functions being incorporated into the database-only baseline model (point at 0).
The y axis shows area under the precision recall curve (AUPR).
Each point on the plot shows the average of 50 sample runs, while the error bars show the 95% confidence intervals of all runs.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.</figcaption>
</figure>
</div>
<h3 id="discriminative-model-performance-1">Discriminative Model Performance</h3>
<div id="fig:aupr_discriminative_model_performance" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling/c76e683a7bbc97482335ed4ac9ef8ab81c46114d/figures/disc_model_experiment/disc_model_test_aupr.png" alt="Figure 8: The discriminator model improves performance as the number of edge-specific label functions is added to the baseline model. The line plot headers represents the specific edge type the discriminator model is trying to predict. The x-axis shows the number of randomly sampled label functions incorporated on top of the baseline model (point at 0). The y axis shows the area under the precision recall curve (AUPR). Each datapoint shows the average of 50 sample runs, while the error bars represents the 95% confidence interval at each point. The baseline and “All” data points consist of sampling from the entire fixed set of label functions." /><figcaption aria-hidden="true"><span>Figure 8:</span> The discriminator model improves performance as the number of edge-specific label functions is added to the baseline model.
The line plot headers represents the specific edge type the discriminator model is trying to predict.
The x-axis shows the number of randomly sampled label functions incorporated on top of the baseline model (point at 0).
The y axis shows the area under the precision recall curve (AUPR).
Each datapoint shows the average of 50 sample runs, while the error bars represents the 95% confidence interval at each point.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.</figcaption>
</figure>
</div>
<h3 id="discriminative-model-calibration">Discriminative Model Calibration</h3>
<div id="fig:discriminative_model_calibration" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling/c76e683a7bbc97482335ed4ac9ef8ab81c46114d/figures/model_calibration_experiment/model_calibration.png" alt="Figure 9: Deep learning models are overconfident in their predictions and need to be calibrated after training. These are calibration plots for the discriminative model, where the green line represents the predictions before calibration and the blue line shows predictions after calibration. Data points that lie closer to the diagonal line show better model calibration, while data points far from the diagonal line show poor performance. A perfectly calibrated model would align straight along the diagonal line." /><figcaption aria-hidden="true"><span>Figure 9:</span> Deep learning models are overconfident in their predictions and need to be calibrated after training.
These are calibration plots for the discriminative model, where the green line represents the predictions before calibration and the blue line shows predictions after calibration.
Data points that lie closer to the diagonal line show better model calibration, while data points far from the diagonal line show poor performance.
A perfectly calibrated model would align straight along the diagonal line.</figcaption>
</figure>
</div>
<p>Even deep learning models with impressive AUROC and AUPR statistics can be subject to poor calibration.
Typically, these models are overconfident in their predictions <span class="citation" data-cites="QJ6hYH8N rLVjMJ5l"><a href="#ref-QJ6hYH8N" role="doc-biblioref">[44]</a>, <a href="#ref-rLVjMJ5l" role="doc-biblioref">[45]</a></span>.
We attempted to use temperature scaling to fix the calibration of the best performing discriminative models (Figure <a href="#fig:discriminative_model_calibration">9</a>).
Before calibration (green lines), our models were aligned with the ideal calibration only when predicting low probability scores (close to 0.25).
Applying the temperature scaling calibration algorithm (blue lines) did not substantially improve the calibration of the model in most cases.
The exception to this pattern is the Disease associates Gene (DaG) model where high confidence scores are shown to be better calibrated.
Overall, calbrating deep learning models is a nontrivial task that requires more complex approaches to accomplish.</p>
<h3 id="text-mined-edges-can-expand-a-database-derived-knowledge-graph">Text Mined Edges Can Expand a Database-derived Knowledge Graph</h3>
<div id="fig:hetionet_reconstruction" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling/c76e683a7bbc97482335ed4ac9ef8ab81c46114d/figures/edge_prediction_experiment/edges_added.png" alt="Figure 10: Text-mined edges recreate a substantial fraction of an existing knowledge graph and include new predictions. This bar chart shows the number of edges we can successfully recall in green and shows the number of new edges that can be added in blue. The recall for the Hetionet v1 knowledge graph is shown as a percentage in parentheses. For example, for the Compound treats Disease (CtD) edge our method recalls 85% of existing edges and adds 6,088 new edges." /><figcaption aria-hidden="true"><span>Figure 10:</span> Text-mined edges recreate a substantial fraction of an existing knowledge graph and include new predictions.
This bar chart shows the number of edges we can successfully recall in green and shows the number of new edges that can be added in blue.<br />
The recall for the Hetionet v1 knowledge graph is shown as a percentage in parentheses.
For example, for the Compound treats Disease (CtD) edge our method recalls 85% of existing edges and adds 6,088 new edges.</figcaption>
</figure>
</div>
<p>One of the goals in our work is to measure the extent to which learning multiple edge types could construct a biomedical knowledge graph.
Using Hetionet v1 as an evaluation set, we measured this framework’s recall and quantified how many new edges could be added with high confidence.
Overall, we were able to recall more than half of preexisting edges for all edge types (Figure <a href="#fig:hetionet_reconstruction">10</a>) and report our top ten scoring sentences for each edge type in Supplemental Table <a href="#tbl:edge_prediction_tbl">11</a>.
Our best recall is with the Compound treats Disease (CtD) edge type, where we retain 85% of preexisting edges.
Plus, we can add over 6,000 new edges to that category.
In contrast, we could only recall close to 70% of existing edges for the other categories; however, we can add over 40,000 novel edges to each category.
This highlights the fact that Hetionet v1 is missing a compelling amount of biomedical information and this framework is a viable way to close the information gap.</p>
<h3 id="comparison-with-cocoscore-using-hetionet-v1-as-an-evaluation-set">Comparison with CoCoScore using Hetionet v1 as an Evaluation Set</h3>
<div id="fig:cocoscore_comparison" class="fignos">
<figure>
<img src="https://raw.githubusercontent.com/danich1/snorkeling/b6e707ea843ac5d66f62ed09277e6b1d3d4b8bf3/figures/literature_models/coco_score_auroc.png" alt="Figure 11: Our extractor shows similar performance to a previously published method when using Hetionet v1 as an evaluation set. We compared our model (blue) with the CoCoScore model tag:cocoscore? (green). The y axis represents AUROC and the x axis represents the edge type both models are trying to predict." /><figcaption aria-hidden="true"><span>Figure 11:</span> Our extractor shows similar performance to a previously published method when using Hetionet v1 as an evaluation set.
We compared our model (blue) with the CoCoScore model <span class="citation" data-cites="tag:cocoscore"><a href="#ref-tag:cocoscore" role="doc-biblioref"><strong>tag:cocoscore?</strong></a></span> (green).
The y axis represents AUROC and the x axis represents the edge type both models are trying to predict.</figcaption>
</figure>
</div>
<p>Our model showed promising performance in terms of recalling edges in Hetionet v1.
We assessed our model’s performance relative to a recently published method <span class="citation" data-cites="tag:cocoscore"><a href="#ref-tag:cocoscore" role="doc-biblioref"><strong>tag:cocoscore?</strong></a></span>.
Though our method is primarily designed to predict assertions, not edges, we compared performance at an edge level because this was available for CoCoScore.
We found that a simple summary approach, max sentence score, provided comparable performance to the CoCoScore for the compound treats disease (CtD) edge type and slightly poorer performance for other edge types (Supplemental Figure <a href="#fig:cocoscore_comparison">11</a>).
Sentence-level scores can be integrated in multiple ways, and approaches that consider more complexity (e.g., the number of sentences with high-probability) should be evaluated in future work.</p>
<h2 id="supplemental-tables">Supplemental Tables</h2>
<h3 id="discriminative-model-calibration-tables">Discriminative Model Calibration Tables</h3>
<div id="tbl:dg_top_ten_table" class="tablenos">
<table id="tbl:dg_top_ten_table">
<caption><span>Table 3:</span> Contains the top ten Disease-associates-Gene confidence scores before and after model calbration. Disease mentions are highlighted in <span class="disease_color">brown</span> and Gene mentions are highlighted in <span class="gene_color">blue</span>. </caption>
<colgroup>
<col style="width: 18%" />
<col style="width: 9%" />
<col style="width: 42%" />
<col style="width: 15%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="header">
<th>Disease Name</th>
<th>Gene Symbol</th>
<th>Text</th>
<th>Before Calibration</th>
<th>After Calibration</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>prostate cancer</td>
<td>DKK1</td>
<td>conclusion : high <span class="gene_color">dkk-1</span> serum levels are associated with a poor survival in patients with <span class="disease_color">prostate cancer</span> .</td>
<td>0.999</td>
<td>0.916</td>
</tr>
<tr class="even">
<td>breast cancer</td>
<td>ERBB2</td>
<td>conclusion : <span class="gene_color">her-2 / neu</span> overexpression in primary <span class="disease_color">breast carcinoma</span> is correlated with patients ’ age ( under age 50 ) and calcifications at mammography .</td>
<td>0.998</td>
<td>0.906</td>
</tr>
<tr class="odd">
<td>breast cancer</td>
<td>ERBB2</td>
<td>the results of multiple linear regression analysis , with her2 as the dependent variable , showed that family history of <span class="disease_color">breast cancer</span> was significantly associated with elevated <span class="gene_color">her2</span> levels in the tumors ( p = 0.0038 ) , after controlling for the effects of age , tumor estrogen receptor , and dna index .</td>
<td>0.998</td>
<td>0.904</td>
</tr>
<tr class="even">
<td>colon cancer</td>
<td>SP3</td>
<td>ba also decreased expression of sp1 , <span class="gene_color">sp3</span> and sp4 transcription factors which are overexpressed in <span class="disease_color">colon cancer</span> cells and decreased levels of several sp-regulated genes including survivin , vascular endothelial growth factor , p65 sub-unit of nfkb , epidermal growth factor receptor , cyclin d1 , and pituitary tumor transforming gene-1 .</td>
<td>0.998</td>
<td>0.902</td>
</tr>
<tr class="odd">
<td>breast cancer</td>
<td>ERBB2</td>
<td>in <span class="disease_color">breast cancer</span> , overexpression of <span class="gene_color">her2</span> is associated with an aggressive tumor phenotype and poor prognosis .</td>
<td>0.998</td>
<td>0.898</td>
</tr>
<tr class="even">
<td>breast cancer</td>
<td>BCL2</td>
<td>in clinical <span class="disease_color">breast cancer</span> samples , high <span class="gene_color">bcl2</span> expression was associated with poor prognosis .</td>
<td>0.997</td>
<td>0.886</td>
</tr>
<tr class="odd">
<td>adrenal gland cancer</td>
<td>TP53</td>
<td>the mechanisms of adrenal tumorigenesis remain poorly established ; the r337h germline mutation in the <span class="gene_color">p53</span> gene has previously been associated with <span class="disease_color">acts</span> in brazilian children .</td>
<td>0.996</td>
<td>0.883</td>
</tr>
<tr class="even">
<td>prostate cancer</td>
<td>AR</td>
<td>the <span class="gene_color">androgen receptor</span> was expressed in all primary and metastatic <span class="disease_color">prostate cancer</span> tissues and no mutations were identified .</td>
<td>0.996</td>
<td>0.881</td>
</tr>
<tr class="odd">
<td>urinary bladder cancer</td>
<td>PIK3CA</td>
<td>conclusions : increased levels of fgfr3 and <span class="gene_color">pik3ca</span> mutated dna in urine and plasma are indicative of later progression and metastasis in <span class="disease_color">bladder cancer</span> .</td>
<td>0.995</td>
<td>0.866</td>
</tr>
<tr class="even">
<td>ovarian cancer</td>
<td>EPAS1</td>
<td>the log-rank test showed that nuclear positive immunostaining for hif-1alpha ( p = .002 ) and cytoplasmic positive immunostaining for <span class="gene_color">hif-2alpha</span> ( p = .0112 ) in tumor cells are associated with poor prognosis of patients with <span class="disease_color">ovarian carcinoma</span> .</td>
<td>0.994</td>
<td>0.86</td>
</tr>
</tbody>
</table>
</div>
<div id="tbl:dg_bottom_ten_table" class="tablenos">
<table id="tbl:dg_bottom_ten_table">
<caption><span>Table 4:</span> Contains the bottom ten Disease-associates-Gene confidence scores before and after model calbration. Disease mentions are highlighted in <span class="disease_color">brown</span> and Gene mentions are highlighted in <span class="gene_color">blue</span>. </caption>
<colgroup>
<col style="width: 27%" />
<col style="width: 11%" />
<col style="width: 28%" />
<col style="width: 16%" />
<col style="width: 16%" />
</colgroup>
<thead>
<tr class="header">
<th>Disease Name</th>
<th>Gene Symbol</th>
<th>Text</th>
<th>Before Calibration</th>
<th>After Calibration</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>endogenous depression</td>
<td>EP300</td>
<td>from a clinical point of view , <span class="gene_color">p300</span> amplitude should be considered as a psychophysiological index of suicidal risk in major <span class="disease_color">depressive disorder</span> .</td>
<td>0.202</td>
<td>0.379</td>
</tr>
<tr class="even">
<td>Alzheimer’s disease</td>
<td>PDK1</td>
<td><span class="gene_color">from prion diseases to <span class="disease_color">alzheimer ’s disease</span> : a common therapeutic target , [pdk1 ]</span> .</td>
<td>0.2</td>
<td>0.378</td>
</tr>
<tr class="odd">
<td>endogenous depression</td>
<td>HTR1A</td>
<td>gepirone , a selective serotonin ( <span class="gene_color">5ht1a )</span> partial agonist in the treatment of <span class="disease_color">major depression</span> .</td>
<td>0.199</td>
<td>0.378</td>
</tr>
<tr class="even">
<td>Gilles de la Tourette syndrome</td>
<td>FGF9</td>
<td>there were no differences in gender distribution , age at tic onset or <span class="disease_color">td</span> diagnosis , tic severity , proportion with current diagnoses of ocd/oc behavior or attention deficit hyperactivity disorder ( adhd ) , cbcl internalizing , externalizing , or total problems scores , ygtss scores , or <span class="gene_color">gaf</span> scores .</td>
<td>0.185</td>
<td>0.37</td>
</tr>
<tr class="odd">
<td>hematologic cancer</td>
<td>MLANA</td>
<td>methods : the sln sections ( n = 214 ) were assessed by qrt assay for 4 established messenger rna biomarkers : <span class="gene_color">mart-1</span> , mage-a3 , <span class="disease_color">galnac-t</span> , and pax3 .</td>
<td>0.18</td>
<td>0.368</td>
</tr>
<tr class="even">
<td>endogenous depression</td>
<td>MAOA</td>
<td>alpha 2-adrenoceptor responsivity in <span class="disease_color">depression</span> : effect of chronic treatment with moclobemide , a selective <span class="gene_color">mao-a-inhibitor</span> , versus maprotiline .</td>
<td>0.179</td>
<td>0.367</td>
</tr>
<tr class="odd">
<td>chronic kidney failure</td>
<td>B2M</td>
<td>to evaluate comparative <span class="gene_color">beta 2-m</span> removal we studied six stable <span class="disease_color">end-stage renal failure</span> patients during high-flux 3-h haemodialysis , haemodia-filtration , and haemofiltration , using acrylonitrile , cellulose triacetate , polyamide and polysulphone capillary devices .</td>
<td>0.178</td>
<td>0.366</td>
</tr>
<tr class="even">
<td>hematologic cancer</td>
<td>C7</td>
<td>serum antibody responses to four haemophilus influenzae type b capsular polysaccharide-protein conjugate vaccines ( prp-d , hboc , <span class="gene_color">c7p</span> , and <span class="disease_color">prp-t )</span> were studied and compared in 175 infants , 85 adults and 140 2-year-old children .</td>
<td>0.174</td>
<td>0.364</td>
</tr>
<tr class="odd">
<td>hypertension</td>
<td>AVP</td>
<td>portohepatic pressures , hepatic function , and blood gases in the combination of nitroglycerin and <span class="gene_color">vasopressin</span> : search for additive effects in <span class="disease_color">cirrhotic portal hypertension</span> .</td>
<td>0.168</td>
<td>0.361</td>
</tr>
<tr class="even">
<td>endogenous depression</td>
<td>GAD1</td>
<td>within-individual deflections in gad , physical , and social symptoms predicted later deflections in <span class="disease_color">depressive symptoms</span> , and deflections in depressive symptoms predicted later deflections in <span class="gene_color">gad</span> and separation anxiety symptoms .</td>
<td>0.149</td>
<td>0.349</td>
</tr>
</tbody>
</table>
</div>
<div id="tbl:cd_top_ten_table" class="tablenos">
<table id="tbl:cd_top_ten_table">
<caption><span>Table 5:</span> Contains the top ten Compound-treats-Disease confidence scores after model calbration. Disease mentions are highlighted in <span class="disease_color">brown</span> and Compound mentions are highlighted in <span class="compound_color">red</span>. </caption>
<colgroup>
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 41%" />
<col style="width: 14%" />
<col style="width: 13%" />
</colgroup>
<thead>
<tr class="header">
<th>Compound Name</th>
<th>Disease Name</th>
<th>Text</th>
<th>Before Calibration</th>
<th>After Calibration</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Prazosin</td>
<td>hypertension</td>
<td>experience with <span class="compound_color">prazosin</span> in the treatment of <span class="disease_color">hypertension</span> .</td>
<td>0.997</td>
<td>0.961</td>
</tr>
<tr class="even">
<td>Methyldopa</td>
<td>hypertension</td>
<td>oxprenolol plus cyclopenthiazide-kcl versus <span class="compound_color">methyldopa</span> in the treatment of <span class="disease_color">hypertension</span> .</td>
<td>0.997</td>
<td>0.961</td>
</tr>
<tr class="odd">
<td>Methyldopa</td>
<td>hypertension</td>
<td>atenolol and <span class="compound_color">methyldopa</span> in the treatment of <span class="disease_color">hypertension</span> .</td>
<td>0.996</td>
<td>0.957</td>
</tr>
<tr class="even">
<td>Prednisone</td>
<td>asthma</td>
<td><span class="compound_color">prednisone</span> and beclomethasone for treatment of <span class="disease_color">asthma</span> .</td>
<td>0.995</td>
<td>0.953</td>
</tr>
<tr class="odd">
<td>Sulfasalazine</td>
<td>ulcerative colitis</td>
<td><span class="compound_color">sulphasalazine</span> , used in the treatment of <span class="disease_color">ulcerative colitis</span> , is cleaved in the colon by the metabolic action of colonic bacteria on the diazo bond to release 5-aminosalicylic acid ( 5-asa ) and sulpharidine .</td>
<td>0.994</td>
<td>0.949</td>
</tr>
<tr class="even">
<td>Prazosin</td>
<td>hypertension</td>
<td>letter : <span class="compound_color">prazosin</span> in treatment of <span class="disease_color">hypertension</span> .</td>
<td>0.994</td>
<td>0.949</td>
</tr>
<tr class="odd">
<td>Methylprednisolone</td>
<td>asthma</td>
<td>use of tao without <span class="compound_color">methylprednisolone</span> in the treatment of severe <span class="disease_color">asthma</span> .</td>
<td>0.994</td>
<td>0.948</td>
</tr>
<tr class="even">
<td>Budesonide</td>
<td>asthma</td>
<td>thus , a regimen of <span class="compound_color">budesonide</span> treatment that consistently attenuates bronchial responsiveness in <span class="disease_color">asthmatic</span> subjects had no effect in these men ; larger and longer trials will be required to establish whether a subgroup of smokers shows a favorable response .</td>
<td>0.994</td>
<td>0.946</td>
</tr>
<tr class="odd">
<td>Methyldopa</td>
<td>hypertension</td>
<td>pressor and chronotropic responses to bilateral carotid occlusion ( bco ) and tyramine were also markedly reduced following treatment with <span class="compound_color">methyldopa</span> , which is consistent with the clinical findings that chronic methyldopa treatment in <span class="disease_color">hypertensive</span> patients impairs cardiovascular reflexes .</td>
<td>0.994</td>
<td>0.946</td>
</tr>
<tr class="even">
<td>Fluphenazine</td>
<td>schizophrenia</td>
<td>low dose <span class="compound_color">fluphenazine decanoate</span> in maintenance treatment of <span class="disease_color">schizophrenia</span> .</td>
<td>0.994</td>
<td>0.946</td>
</tr>
</tbody>
</table>
</div>
<div id="tbl:cd_bottom_ten_table" class="tablenos">
<table id="tbl:cd_bottom_ten_table">
<caption><span>Table 6:</span> Contains the bottom ten Compound-treats-Disease confidence scores before and after model calbration. Disease mentions are highlighted in <span class="disease_color">brown</span> and Compound mentions are highlighted in <span class="compound_color">red</span>. </caption>
<colgroup>
<col style="width: 12%" />
<col style="width: 21%" />
<col style="width: 35%" />
<col style="width: 15%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="header">
<th>Compound Name</th>
<th>Disease Name</th>
<th>Text</th>
<th>Before Calibration</th>
<th>After Calibration</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Indomethacin</td>
<td>hypertension</td>
<td>effects of <span class="compound_color">indomethacin</span> in rabbit <span class="disease_color">renovascular hypertension</span> .</td>
<td>0.033</td>
<td>0.13</td>
</tr>
<tr class="even">
<td>Alprazolam</td>
<td>panic disorder</td>
<td>according to logistic regression analysis , the relationships between plasma <span class="compound_color">alprazolam</span> concentration and response , as reflected by number of <span class="disease_color">panic attacks</span> reported , phobia ratings , physicians ’ and patients ’ ratings of global improvement , and the emergence of side effects , were significant .</td>
<td>0.03</td>
<td>0.124</td>
</tr>
<tr class="odd">
<td>Mestranol</td>
<td>polycystic ovary syndrome</td>
<td>the binding capacity of plasma testosterone-estradiol-binding globulin ( tebg ) and testosterone ( t ) levels were measured in four women with proved <span class="disease_color">polycystic ovaries</span> and three women with a clinical diagnosis of polycystic ovarian disease before , during , and after administration of norethindrone , 2 mg. , and <span class="compound_color">mestranol</span> , 0.1 mg .</td>
<td>0.03</td>
<td>0.123</td>
</tr>
<tr class="even">
<td>Creatine</td>
<td>coronary artery disease</td>
<td>during successful and uncomplicated angioplasty ( ptca ) , we studied the effect of a short lasting <span class="disease_color">myocardial ischemia</span> on plasma creatine kinase , creatine kinase mb-activity , and <span class="compound_color">creatine</span> kinase mm-isoforms ( mm1 , mm2 , mm3 ) in 23 patients .</td>
<td>0.028</td>
<td>0.12</td>
</tr>
<tr class="odd">
<td>Creatine</td>
<td>coronary artery disease</td>
<td>in 141 patients with <span class="disease_color">acute myocardial infarction</span> , <span class="compound_color">creatine</span> phosphokinase isoenzyme ( cpk-mb ) was determined by the activation method with dithiothreitol ( rao et al. : clin .</td>
<td>0.027</td>
<td>0.117</td>
</tr>
<tr class="even">
<td>Morphine</td>
<td>brain cancer</td>
<td>the tissue to serum ratio of <span class="compound_color">morphine</span> in the <span class="disease_color">hypothalamus</span> , hippocampus , striatum , midbrain and cortex were also smaller in morphine tolerant than in non-tolerant rats .</td>
<td>0.026</td>
<td>0.115</td>
</tr>
<tr class="odd">
<td>Glutathione</td>
<td>anemia</td>
<td>our results suggest that an association between <span class="compound_color">gsh</span> px <span class="disease_color">deficiency and hemolytic anemia</span> need not represent a cause-and-effect relationship .</td>
<td>0.026</td>
<td>0.114</td>
</tr>
<tr class="even">
<td>Dinoprostone</td>
<td>stomach cancer</td>
<td>prostaglandin e2 ( <span class="compound_color">pge2 )</span> - and 6-keto-pgf1 alpha-like immunoactivity was measured in incubates of <span class="disease_color">forestomach and gastric corpus mucosa</span> in ( a ) unoperated rats , ( b ) rats with sham-operation of the kidneys and ( c ) rats with bilateral nephrectomy .</td>
<td>0.023</td>
<td>0.107</td>
</tr>
<tr class="odd">
<td>Creatine</td>
<td>coronary artery disease</td>
<td>the value of the electrocardiogram in assessing infarct size was studied using serial estimates of the mb isomer of <span class="compound_color">creatine</span> kinase ( ck mb ) in plasma , serial 35 lead praecordial maps in 28 patients with <span class="disease_color">anterior myocardial infarction</span> , and serial 12 lead electrocardiograms in 17 patients with inferior myocardial infarction .</td>
<td>0.022</td>
<td>0.105</td>
</tr>
<tr class="even">
<td>Sulfamethazine</td>
<td>multiple sclerosis</td>
<td>quantitation and confirmation of <span class="compound_color">sulfamethazine</span> residues in swine muscle and liver by lc and <span class="disease_color">gc/ms</span> .</td>
<td>0.017</td>
<td>0.093</td>
</tr>
</tbody>
</table>
</div>
<div id="tbl:cg_top_ten_table" class="tablenos">
<table id="tbl:cg_top_ten_table">
<caption><span>Table 7:</span> Contains the top ten Compound-binds-Gene confidence scores before and after model calbration. Gene mentions are highlighted in <span class="gene_color">blue</span> and Compound mentions are highlighted in <span class="compound_color">red</span>. </caption>
<colgroup>
<col style="width: 29%" />
<col style="width: 11%" />
<col style="width: 22%" />
<col style="width: 18%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="header">
<th>Compound Name</th>
<th>Gene Symbol</th>
<th>Text</th>
<th>Before Calibration</th>
<th>After Calibration</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Cyclic Adenosine Monophosphate</td>
<td>B3GNT2</td>
<td>in sk-n-mc human neuroblastoma cells , the <span class="compound_color">camp</span> response to 10 nm isoproterenol ( iso ) is mediated primarily by <span class="gene_color">beta 1-adrenergic</span> receptors .</td>
<td>0.903</td>
<td>0.93</td>
</tr>
<tr class="even">
<td>Indomethacin</td>
<td>AGT</td>
<td><span class="compound_color">indomethacin</span> , a potent inhibitor of prostaglandin synthesis , is known to increase the maternal blood pressure response to <span class="gene_color">angiotensin ii</span> infusion .</td>
<td>0.894</td>
<td>0.922</td>
</tr>
<tr class="odd">
<td>Tretinoin</td>
<td>RXRA</td>
<td>the vitamin a derivative <span class="compound_color">retinoic acid</span> exerts its effects on transcription through two distinct classes of nuclear receptors , the retinoic acid receptor ( rar ) and the <span class="gene_color">retinoid x receptor</span> ( rxr ) .</td>
<td>0.882</td>
<td>0.912</td>
</tr>
<tr class="even">
<td>Tretinoin</td>
<td>RXRA</td>
<td>the vitamin a derivative retinoic acid exerts its effects on transcription through two distinct classes of nuclear receptors , the <span class="compound_color">retinoic acid</span> receptor ( rar ) and the <span class="gene_color">retinoid x receptor</span> ( rxr ) .</td>
<td>0.872</td>
<td>0.903</td>
</tr>
<tr class="odd">
<td>D-Tyrosine</td>
<td>CSF1</td>
<td>however , the extent of gap <span class="compound_color">tyrosine</span> phosphorylation induced by <span class="gene_color">csf-1</span> was approximately 10 % of that induced by pdgf-bb in the nih3t3 fibroblasts .</td>
<td>0.851</td>
<td>0.883</td>
</tr>
<tr class="even">
<td>D-Glutamic Acid</td>
<td>GLB1</td>
<td>thus , the negatively charged side chain of <span class="compound_color">glu-461</span> is important for divalent cation binding to <span class="gene_color">beta-galactosidase</span> .</td>
<td>0.849</td>
<td>0.882</td>
</tr>
<tr class="odd">
<td>D-Tyrosine</td>
<td>CD4</td>
<td>second , we use the same system to provide evidence that the physical association of <span class="gene_color">cd4</span> with the tcr is required for effective <span class="compound_color">tyrosine</span> phosphorylation of the tcr zeta-chain subunit , presumably reflecting delivery of p56lck ( lck ) to the tcr .</td>
<td>0.825</td>
<td>0.859</td>
</tr>
<tr class="even">
<td>Calcium Chloride</td>
<td>TNC</td>
<td>the possibility that the enhanced length dependence of <span class="compound_color">ca2</span> + sensitivity after cardiac tnc reconstitution was attributable to reduced <span class="gene_color">tnc</span> binding was excluded when the length dependence of partially extracted fast fibres was reduced to one-half the normal value after a 50 % deletion of the native tnc .</td>
<td>0.821</td>
<td>0.855</td>
</tr>
<tr class="odd">
<td>Metoprolol</td>
<td>KCNMB2</td>
<td>studies in difi cells of the displacement of specific 125i-cyp binding by nonselective ( propranolol ) , beta 1-selective ( <span class="compound_color">metoprolol</span> and atenolol ) , and beta 2-selective ( ici 118-551 ) antagonists revealed only a single class of <span class="gene_color">beta 2-adrenergic</span> receptors .</td>
<td>0.82</td>
<td>0.854</td>
</tr>
<tr class="even">
<td>D-Tyrosine</td>
<td>PLCG1</td>
<td>epidermal growth factor ( egf ) or platelet-derived growth factor binding to their receptor on fibroblasts induces tyrosine phosphorylation of plc gamma 1 and stable association of <span class="gene_color">plc gamma 1</span> with the receptor protein <span class="compound_color">tyrosine</span> kinase .</td>
<td>0.818</td>
<td>0.851</td>
</tr>
</tbody>
</table>
</div>
<div id="tbl:cg_bottom_ten_table" class="tablenos">
<table id="tbl:cg_bottom_ten_table">
<caption><span>Table 8:</span> Contains the bottom ten Compound-binds-Gene confidence scores before and after model calbration. Gene mentions are highlighted in <span class="gene_color">blue</span> and Compound mentions are highlighted in <span class="compound_color">red</span>. </caption>
<colgroup>
<col style="width: 13%" />
<col style="width: 9%" />
<col style="width: 48%" />
<col style="width: 14%" />
<col style="width: 13%" />
</colgroup>
<thead>
<tr class="header">
<th>Compound Name</th>
<th>Gene Symbol</th>
<th>Text</th>
<th>Before Calibration</th>
<th>After Calibration</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Deferoxamine</td>
<td>TF</td>
<td>the mechanisms of fe uptake have been characterised using 59fe complexes of citrate , nitrilotriacetate , <span class="compound_color">desferrioxamine</span> , and 59fe added to eagle ’s minimum essential medium ( mem ) and compared with human transferrin ( <span class="gene_color">tf )</span> labelled with 59fe and iodine-125 .</td>
<td>0.02</td>
<td>0.011</td>
</tr>
<tr class="even">
<td>Hydrocortisone</td>
<td>GH1</td>
<td>group iv patients had normal basal levels of lh and normal lh , <span class="gene_color">gh</span> and <span class="compound_color">cortisol</span> responses .</td>
<td>0.02</td>
<td>0.011</td>
</tr>
<tr class="odd">
<td>Carbachol</td>
<td>INS</td>
<td>at the same concentration , however , iapp significantly ( p less than 0.05 ) inhibited <span class="compound_color">carbachol-stimulated</span> ( 10 ( -7 ) m ) release of insulin by 30 % , and cgrp significantly inhibited carbachol-stimulated release of <span class="gene_color">insulin</span> by 33 % when compared with the control group .</td>
<td>0.02</td>
<td>0.011</td>
</tr>
<tr class="even">
<td>Adenosine</td>
<td>ME2</td>
<td>at physiological concentrations , atp , adp , and <span class="compound_color">amp</span> all inhibit the enzyme from atriplex spongiosa and panicum miliaceum ( <span class="gene_color">nad-me-type</span> plants ) , with atp the most inhibitory species .</td>
<td>0.019</td>
<td>0.01</td>
</tr>
<tr class="odd">
<td>Naloxone</td>
<td>POMC</td>
<td>specifically , opioids , including 2-n-pentyloxy-2-phenyl-4-methyl-morpholine , <span class="compound_color">naloxone</span> , and <span class="gene_color">beta-endorphin</span> , have been shown to interact with il-2 receptors ( 134 ) and regulate production of il-1 and il-2 ( 48-50 , 135 ) .</td>
<td>0.018</td>
<td>0.01</td>
</tr>
<tr class="even">
<td>Cortisone acetate</td>
<td>POMC</td>
<td>sarcoidosis therapy with <span class="compound_color">cortisone</span> and <span class="gene_color">acth –</span> the role of acth therapy .</td>
<td>0.017</td>
<td>0.009</td>
</tr>
<tr class="odd">
<td>Epinephrine</td>
<td>INS</td>
<td>thermogenic effect of thyroid hormones : interactions with <span class="compound_color">epinephrine</span> and <span class="gene_color">insulin</span> .</td>
<td>0.017</td>
<td>0.009</td>
</tr>
<tr class="even">
<td>Aldosterone</td>
<td>KNG1</td>
<td>important vasoconstrictor , fluid - and sodium-retaining factors are the <span class="compound_color">renin-angiotensin-aldosterone</span> system , sympathetic nerve activity , and vasopressin ; vasodilator , volume , and sodium-eliminating factors are atrial natriuretic peptide , vasodilator prostaglandins like prostacyclin and prostaglandin e2 , dopamine , <span class="gene_color">bradykinin</span> , and possibly , endothelial derived relaxing factor ( edrf ) .</td>
<td>0.016</td>
<td>0.008</td>
</tr>
<tr class="odd">
<td>D-Leucine</td>
<td>POMC</td>
<td>cross-reactivities of <span class="compound_color">leucine-enkephalin</span> and <span class="gene_color">beta-endorphin</span> with the eia were less than 0.1 % , while that with gly-gly-phe-met and oxidized gly-gly-phe-met were 2.5 % and 10.2 % , respectively .</td>
<td>0.011</td>
<td>0.005</td>
</tr>
<tr class="even">
<td>Estriol</td>
<td>LGALS1</td>
<td>[ diagnostic value of serial determination of <span class="compound_color">estriol</span> and <span class="gene_color">hpl</span> in plasma and of total estrogens in 24-h-urine compared to single values for diagnosis of fetal danger ] .</td>
<td>0.01</td>
<td>0.005</td>
</tr>
</tbody>
</table>
</div>
<div id="tbl:gg_top_ten_table" class="tablenos">
<table id="tbl:gg_top_ten_table">
<caption><span>Table 9:</span> Contains the top ten Gene-interacts-Gene confidence scores before and after model calbration. Both gene mentions highlighted in <span class="gene_color">blue</span>. </caption>
<colgroup>
<col style="width: 18%" />
<col style="width: 18%" />
<col style="width: 12%" />
<col style="width: 25%" />
<col style="width: 24%" />
</colgroup>
<thead>
<tr class="header">
<th>Gene1 Symbol</th>
<th>Gene2 Symbol</th>
<th>Text</th>
<th>Before Calibration</th>
<th>After Calibration</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ESR1</td>
<td>HSP90AA1</td>
<td>previous studies have suggested that the 90-kda heat shock protein ( <span class="gene_color">hsp90 )</span> interacts with the <span class="gene_color">er</span> , thus stabilizing the receptor in an inactive state .</td>
<td>0.812</td>
<td>0.864</td>
</tr>
<tr class="even">
<td>TP53</td>
<td>TP73</td>
<td>cyclin g interacts with p53 as well as <span class="gene_color">p73</span> , and its binding to <span class="gene_color">p53</span> or p73 presumably mediates downregulation of p53 and p73 .</td>
<td>0.785</td>
<td>0.837</td>
</tr>
<tr class="odd">
<td>TP53</td>
<td>AKT1</td>
<td>treatment of c81 cells with ly294002 resulted in an increase in the <span class="gene_color">p53-responsive</span> gene mdm2 , suggesting a role for <span class="gene_color">akt</span> in the tax-mediated regulation of p53 transcriptional activity .</td>
<td>0.773</td>
<td>0.825</td>
</tr>
<tr class="even">
<td>ABCB1</td>
<td>NR1I3</td>
<td>valproic acid induces cyp3a4 and <span class="gene_color">mdr1</span> gene expression by activation of <span class="gene_color">constitutive androstane receptor</span> and pregnane x receptor pathways .</td>
<td>0.762</td>
<td>0.813</td>
</tr>
<tr class="odd">
<td>PTH2R</td>
<td>PTH2</td>
<td>thus , the juxtamembrane receptor domain specifies the signaling and binding selectivity of <span class="gene_color">tip39</span> for the <span class="gene_color">pth2 receptor</span> over the pth1 receptor .</td>
<td>0.761</td>
<td>0.812</td>
</tr>
<tr class="even">
<td>CCND1</td>
<td>ABL1</td>
<td>synergy with <span class="gene_color">v-abl</span> depended on a motif in <span class="gene_color">cyclin d1</span> that mediates its binding to the retinoblastoma protein , suggesting that abl oncogenes in part mediate their mitogenic effects via a retinoblastoma protein-dependent pathway .</td>
<td>0.757</td>
<td>0.808</td>
</tr>
<tr class="odd">
<td>CTNND1</td>
<td>CDH1</td>
<td>these complexes are formed independently of ddr1 activation and of beta-catenin and <span class="gene_color">p120-catenin</span> binding to <span class="gene_color">e-cadherin</span> ; they are ubiquitous in epithelial cells .</td>
<td>0.748</td>
<td>0.798</td>
</tr>
<tr class="even">
<td>CSF1</td>
<td>CSF1R</td>
<td>this is in agreement with current thought that the <span class="gene_color">c-fms</span> proto-oncogene product functions as the <span class="gene_color">csf-1</span> receptor specific to this pathway .</td>
<td>0.745</td>
<td>0.795</td>
</tr>
<tr class="odd">
<td>EZR</td>
<td>CFTR</td>
<td>without <span class="gene_color">ezrin</span> binding , the cytoplasmic tail of <span class="gene_color">cftr</span> only interacts strongly with the first amino-terminal pdz domain to form a 1:1 c-cftr .</td>
<td>0.732</td>
<td>0.78</td>
</tr>
<tr class="even">
<td>SRC</td>
<td>PIK3CG</td>
<td>we have demonstrated that the sh2 ( <span class="gene_color">src</span> homology 2 ) domains of the 85 kda subunit of pi-3k are sufficient to mediate binding of the <span class="gene_color">pi-3k</span> complex to tyrosine phosphorylated , but not non-phosphorylated il-2r beta , suggesting that tyrosine phosphorylation is an integral component of the activation of pi-3k by the il-2r .</td>
<td>0.731</td>
<td>0.78</td>
</tr>
</tbody>
</table>
</div>
<div id="tbl:gg_bottom_ten_table" class="tablenos">
<table id="tbl:gg_bottom_ten_table">
<caption><span>Table 10:</span> Contains the bottom ten Gene-interacts-Gene confidence scores before and after model calbration. Both gene mentions highlighted in <span class="gene_color">blue</span>. </caption>
<colgroup>
<col style="width: 18%" />
<col style="width: 18%" />
<col style="width: 12%" />
<col style="width: 25%" />
<col style="width: 24%" />
</colgroup>
<thead>
<tr class="header">
<th>Gene1 Symbol</th>
<th>Gene2 Symbol</th>
<th>Text</th>
<th>Before Calibration</th>
<th>After Calibration</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>AGTR1</td>
<td>ACE</td>
<td>result ( s ) : the luteal tissue is the major site of ang ii , <span class="gene_color">ace</span> , <span class="gene_color">at1r</span> , and vegf , with highest staining intensity found during the midluteal phase and at pregnancy .</td>
<td>0.009</td>
<td>0.003</td>
</tr>
<tr class="even">
<td>ABCE1</td>
<td>ABCF2</td>
<td>in relation to normal melanocytes , abcb3 , abcb6 , abcc2 , abcc4 , <span class="gene_color">abce1</span> and <span class="gene_color">abcf2</span> were significantly increased in melanoma cell lines , whereas abca7 , abca12 , abcb2 , abcb4 , abcb5 and abcd1 showed lower expression levels .</td>
<td>0.008</td>
<td>0.002</td>
</tr>
<tr class="odd">
<td>IL4</td>
<td>IFNG</td>
<td>in contrast , il-13ralpha2 mrna expression was up-regulated by <span class="gene_color">ifn-gamma</span> plus <span class="gene_color">il-4</span> .</td>
<td>0.007</td>
<td>0.002</td>
</tr>
<tr class="even">
<td>FCAR</td>
<td>CD79A</td>
<td>we report here the presence of circulating soluble fcalphar ( <span class="gene_color">cd89 )</span> - <span class="gene_color">iga</span> complexes in patients with igan .</td>
<td>0.007</td>
<td>0.002</td>
</tr>
<tr class="odd">
<td>IL4</td>
<td>VCAM1</td>
<td>similarly , <span class="gene_color">il-4</span> induced <span class="gene_color">vcam-1</span> expression and augmented tnf-alpha-induced expression on huvec but did not affect vcam-1 expression on hdmec .</td>
<td>0.007</td>
<td>0.002</td>
</tr>
<tr class="even">
<td>IL2</td>
<td>IFNG</td>
<td>prostaglandin e2 at priming of naive cd4 + t cells inhibits acquisition of ability to produce <span class="gene_color">ifn-gamma</span> and <span class="gene_color">il-2</span> , but not il-4 and il-5 .</td>
<td>0.006</td>
<td>0.002</td>
</tr>
<tr class="odd">
<td>IL2</td>
<td>FOXP3</td>
<td>il-1b promotes tgf-b1 and <span class="gene_color">il-2</span> dependent <span class="gene_color">foxp3</span> expression in regulatory t cells .</td>
<td>0.006</td>
<td>0.002</td>
</tr>
<tr class="even">
<td>IL2</td>
<td>IFNG</td>
<td>the detailed distribution of lymphokine-producing cells showed that <span class="gene_color">il-2</span> and <span class="gene_color">ifn-gamma-producing</span> cells were located mainly in the follicular areas .</td>
<td>0.005</td>
<td>0.001</td>
</tr>
<tr class="odd">
<td>IFNG</td>
<td>IL10</td>
<td>results : we found weak mrna expression of interleukin-4 ( il-4 ) and il-5 , and strong expression of il-6 , <span class="gene_color">il-10</span> and <span class="gene_color">ifn-gamma</span> before therapy .</td>
<td>0.005</td>
<td>0.001</td>
</tr>
<tr class="even">
<td>PIK3R1</td>
<td>PTEN</td>
<td>both <span class="gene_color">pten</span> ( <span class="gene_color">pi3k</span> antagonist ) and pp2 ( unspecific phosphatase ) were down-regulated .</td>
<td>0.005</td>
<td>0.001</td>
</tr>
</tbody>
</table>
</div>
<h3 id="top-ten-sentences-for-each-edge-type">Top Ten Sentences for Each Edge Type</h3>
<div id="tbl:edge_prediction_tbl" class="tablenos">
<table id="tbl:edge_prediction_tbl">
<caption><span>Table 11:</span> Contains the top ten predictions for each edge type. Highlighted words represent entities mentioned within the given sentence. </caption>
<colgroup>
<col style="width: 7%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 20%" />
<col style="width: 22%" />
<col style="width: 9%" />
<col style="width: 15%" />
<col style="width: 6%" />
</colgroup>
<thead>
<tr class="header">
<th>Edge Type</th>
<th>Source Node</th>
<th>Target Node</th>
<th>Generative Model Prediction</th>
<th>Discriminative Model Prediction</th>
<th>Number of Sentences</th>
<th>In Hetionet</th>
<th>Text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>urinary bladder cancer</td>
<td>TP53</td>
<td>1</td>
<td>0.945</td>
<td>2112</td>
<td>Existing</td>
<td>conclusion : our findings indicate that the dsp53-285 can upregulate wild-type <span class="gene_color">p53</span> expression in human <span class="disease_color">bladder cancer</span> cells through rna activation , and suppresses cells proliferation and metastasis in vitro and in vivo .</td>
</tr>
<tr class="even">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>ovarian cancer</td>
<td>EGFR</td>
<td>1</td>
<td>0.937</td>
<td>1330</td>
<td>Existing</td>
<td>conclusion : our data showed that increased expression of <span class="gene_color">egfr</span> is associated with poor prognosis of patients with <span class="disease_color">eoc</span> and dacomitinib may act as a novel , useful chemotherapy drug .</td>
</tr>
<tr class="odd">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>stomach cancer</td>
<td>TP53</td>
<td>1</td>
<td>0.937</td>
<td>2679</td>
<td>Existing</td>
<td>conclusion : this meta-analysis suggests that <span class="gene_color">p53</span> arg72pro polymorphism is associated with increased risk of <span class="disease_color">gastric cancer</span> in asians .</td>
</tr>
<tr class="even">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>lung cancer</td>
<td>TP53</td>
<td>1</td>
<td>0.936</td>
<td>6813</td>
<td>Existing</td>
<td>conclusion : these results suggest that high expression of the <span class="gene_color">p53</span> oncoprotein is a favorable prognostic factor in a subset of patients with <span class="disease_color">nsclc</span> .</td>
</tr>
<tr class="odd">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>breast cancer</td>
<td>TCF7L2</td>
<td>1</td>
<td>0.936</td>
<td>56</td>
<td>Existing</td>
<td>this meta-analysis demonstrated that <span class="gene_color">tcf7l2</span> gene polymorphisms ( rs12255372 and rs7903146 ) are associated with an increased susceptibility to <span class="disease_color">breast cancer</span> .</td>
</tr>
<tr class="even">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>skin cancer</td>
<td>COX2</td>
<td>1</td>
<td>0.935</td>
<td>73</td>
<td>Novel</td>
<td>elevated expression of <span class="gene_color">cox-2</span> has been associated with tumor progression in <span class="disease_color">skin cancer</span> through multiple mechanisms .</td>
</tr>
<tr class="odd">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>thyroid cancer</td>
<td>VEGFA</td>
<td>1</td>
<td>0.933</td>
<td>592</td>
<td>Novel</td>
<td>as a conclusion , we suggest that <span class="gene_color">vegf</span> g +405 c polymorphism is associated with increased risk of <span class="disease_color">ptc</span> .</td>
</tr>
<tr class="even">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>stomach cancer</td>
<td>EGFR</td>
<td>1</td>
<td>0.933</td>
<td>1237</td>
<td>Existing</td>
<td>recently , high lymph node ratio is closely associated with <span class="gene_color">egfr</span> expression in advanced <span class="disease_color">gastric cancer</span> .</td>
</tr>
<tr class="odd">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>liver cancer</td>
<td>GPC3</td>
<td>1</td>
<td>0.933</td>
<td>1944</td>
<td>Novel</td>
<td>conclusions serum <span class="gene_color">gpc3</span> was overexpressed in <span class="disease_color">hcc</span> patients .</td>
</tr>
<tr class="even">
<td><span class="disease_color">D</span>a<span class="gene_color">G</span></td>
<td>stomach cancer</td>
<td>CCR6</td>
<td>1</td>
<td>0.931</td>
<td>24</td>
<td>Novel</td>
<td>the cox regression analysis showed that high expression of <span class="gene_color">ccr6</span> was an independent prognostic factor for <span class="disease_color">gc</span> patients .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Sorafenib</td>
<td>liver cancer</td>
<td>1</td>
<td>0.99</td>
<td>6672</td>
<td>Existing</td>
<td>tace plus <span class="compound_color">sorafenib</span> for the treatment of <span class="disease_color">hepatocellular carcinoma</span> : final results of the multicenter socrates trial .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Methotrexate</td>
<td>rheumatoid arthritis</td>
<td>1</td>
<td>0.989</td>
<td>14546</td>
<td>Existing</td>
<td>comparison of low-dose oral pulse <span class="compound_color">methotrexate</span> and placebo in the treatment of <span class="disease_color">rheumatoid arthritis</span> .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Auranofin</td>
<td>rheumatoid arthritis</td>
<td>1</td>
<td>0.988</td>
<td>419</td>
<td>Existing</td>
<td><span class="compound_color">auranofin</span> versus placebo in the treatment of <span class="disease_color">rheumatoid arthritis</span> .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Lamivudine</td>
<td>hepatitis B</td>
<td>1</td>
<td>0.988</td>
<td>6709</td>
<td>Existing</td>
<td>randomized controlled trials ( rcts ) comparing etv with <span class="compound_color">lam</span> for the treatment of <span class="disease_color">hepatitis b</span> decompensated cirrhosis were included .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Doxorubicin</td>
<td>urinary bladder cancer</td>
<td>1</td>
<td>0.988</td>
<td>930</td>
<td>Existing</td>
<td>17-year follow-up of a randomized prospective controlled trial of adjuvant intravesical <span class="compound_color">doxorubicin</span> in the treatment of superficial <span class="disease_color">bladder cancer</span> .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Docetaxel</td>
<td>breast cancer</td>
<td>1</td>
<td>0.987</td>
<td>5206</td>
<td>Existing</td>
<td>currently , randomized phase iii trials have demonstrated that <span class="compound_color">docetaxel</span> is an effective strategy in the adjuvant treatment of <span class="disease_color">breast cancer</span> .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Cimetidine</td>
<td>psoriasis</td>
<td>0.999</td>
<td>0.987</td>
<td>12</td>
<td>Novel</td>
<td><span class="compound_color">cimetidine</span> versus placebo in the treatment of <span class="disease_color">psoriasis</span> .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Olanzapine</td>
<td>schizophrenia</td>
<td>1</td>
<td>0.987</td>
<td>3324</td>
<td>Novel</td>
<td>a double-blind , randomised comparative trial of amisulpride versus <span class="compound_color">olanzapine</span> in the treatment of <span class="disease_color">schizophrenia</span> : short-term results at two months .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Fulvestrant</td>
<td>breast cancer</td>
<td>1</td>
<td>0.987</td>
<td>826</td>
<td>Existing</td>
<td>phase iii clinical trials have demonstrated the clinical benefit of <span class="compound_color">fulvestrant</span> in the endocrine treatment of <span class="disease_color">breast cancer</span> .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>t<span class="disease_color">D</span></td>
<td>Pimecrolimus</td>
<td>atopic dermatitis</td>
<td>1</td>
<td>0.987</td>
<td>531</td>
<td>Existing</td>
<td>introduction : although several controlled clinical trials have demonstrated the efficacy and good tolerability of 1 % <span class="compound_color">pimecrolimus</span> cream for the treatment of <span class="disease_color">atopic dermatitis</span> , the results of these trials may not apply to real-life usage .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>Gefitinib</td>
<td>EGFR</td>
<td>1</td>
<td>0.99</td>
<td>8746</td>
<td>Existing</td>
<td>morphologic features of adenocarcinoma of the lung predictive of response to the <span class="gene_color">epidermal growth factor receptor</span> kinase inhibitors erlotinib and <span class="compound_color">gefitinib</span> .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>Adenosine</td>
<td>EGFR</td>
<td>1</td>
<td>0.987</td>
<td>644</td>
<td>Novel</td>
<td>it is well established that inhibiting <span class="compound_color">atp</span> binding within the <span class="gene_color">egfr</span> kinase domain regulates its function .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>Rosiglitazone</td>
<td>PPARG</td>
<td>1</td>
<td>0.987</td>
<td>1498</td>
<td>Existing</td>
<td><span class="compound_color">rosiglitazone</span> is a potent <span class="gene_color">peroxisome proliferator-activated receptor gamma</span> agonist that decreases hyperglycemia by reducing insulin resistance in patients with type 2 diabetes mellitus .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>D-Tyrosine</td>
<td>INSR</td>
<td>0.998</td>
<td>0.987</td>
<td>1713</td>
<td>Novel</td>
<td>this result suggests that <span class="compound_color">tyrosine</span> phosphorylation of phosphatidylinositol 3-kinase by the <span class="gene_color">insulin receptor</span> kinase may increase the specific activity of the former enzyme in vivo .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>D-Tyrosine</td>
<td>IGF1</td>
<td>0.998</td>
<td>0.983</td>
<td>819</td>
<td>Novel</td>
<td>affinity-purified <span class="gene_color">insulin-like growth factor i</span> receptor kinase is activated by <span class="compound_color">tyrosine</span> phosphorylation of its beta subunit .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>Pindolol</td>
<td>HTR1A</td>
<td>1</td>
<td>0.983</td>
<td>175</td>
<td>Existing</td>
<td><span class="compound_color">pindolol</span> , a betablocker with weak partial <span class="gene_color">5-ht1a receptor</span> agonist activity has been shown to produce a more rapid onset of antidepressant action of ssris .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>Progesterone</td>
<td>SHBG</td>
<td>1</td>
<td>0.981</td>
<td>492</td>
<td>Existing</td>
<td>however , dng also elicits properties of <span class="compound_color">progesterone</span> derivatives like neutrality in metabolic and cardiovascular system and considerable antiandrogenic activity , the latter increased by lack of binding to <span class="gene_color">shbg</span> as specific property of dng .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>Mifepristone</td>
<td>AR</td>
<td>1</td>
<td>0.98</td>
<td>78</td>
<td>Existing</td>
<td><span class="compound_color">ru486</span> bound to the <span class="gene_color">androgen receptor</span> .</td>
</tr>
<tr class="odd">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>Alfentanil</td>
<td>OPRM1</td>
<td>1</td>
<td>0.979</td>
<td>10</td>
<td>Existing</td>
<td>purpose : <span class="compound_color">alfentanil</span> is a high potency <span class="gene_color">mu opiate receptor</span> agonist commonly used during presurgical induction of anesthesia .</td>
</tr>
<tr class="even">
<td><span class="compound_color">C</span>b<span class="gene_color">G</span></td>
<td>Candesartan</td>
<td>AGTR1</td>
<td>1</td>
<td>0.979</td>
<td>36</td>
<td>Existing</td>
<td><span class="compound_color">tcv-116</span> is a new , nonpeptide , <span class="gene_color">angiotensin ii type-1 receptor</span> antagonist that acts as a specific inhibitor of the renin-angiotensin system .</td>
</tr>
<tr class="odd">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>BRCA2</td>
<td>BRCA1</td>
<td>0.972</td>
<td>0.984</td>
<td>12257</td>
<td>Novel</td>
<td>a total of 9 families ( 16 % ) showed mutations in the <span class="gene_color">brca1</span> gene , including the one new mutation identified in this study ( 5382insc ) , and 12 families ( 21 % ) presented mutations in the <span class="gene_color">brca2</span> gene .</td>
</tr>
<tr class="even">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>MDM2</td>
<td>TP53</td>
<td>0.938</td>
<td>0.978</td>
<td>17128</td>
<td>Existing</td>
<td>no mutations in the <span class="gene_color">tp53</span> gene have been found in samples with amplification of <span class="gene_color">mdm2</span> .</td>
</tr>
<tr class="odd">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>BRCA1</td>
<td>BRCA2</td>
<td>1</td>
<td>0.978</td>
<td>12257</td>
<td>Existing</td>
<td>pathogenic truncating mutations in the <span class="gene_color">brca1</span> gene were found in two tumor samples with allelic losses , whereas no mutations were identified in the <span class="gene_color">brca2</span> gene .</td>
</tr>
<tr class="even">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>KRAS</td>
<td>TP53</td>
<td>0.992</td>
<td>0.971</td>
<td>4106</td>
<td>Novel</td>
<td>mutations in the <span class="gene_color">p53</span> gene did not correlate with mutations in the <span class="gene_color">c-k-ras</span> gene , indicating that colorectal cancer can develop through pathways independent not only of the presence of mutations in any of these genes but also of their cooperation .</td>
</tr>
<tr class="odd">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>TP53</td>
<td>HRAS</td>
<td>0.992</td>
<td>0.969</td>
<td>451</td>
<td>Novel</td>
<td>pathologic examination of the uc specimens from aa-exposed patients identified heterozygous <span class="gene_color">hras</span> changes in 3 cases , and deletion or replacement mutations in the <span class="gene_color">tp53</span> gene in 4 .</td>
</tr>
<tr class="even">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>REN</td>
<td>NR1H3</td>
<td>0.998</td>
<td>0.966</td>
<td>8</td>
<td>Novel</td>
<td>nuclear receptor <span class="gene_color">lxralpha</span> is involved in camp-mediated human <span class="gene_color">renin</span> gene expression .</td>
</tr>
<tr class="odd">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>ESR2</td>
<td>CYP19A1</td>
<td>0.999</td>
<td>0.96</td>
<td>159</td>
<td>Novel</td>
<td>dna methylation , histone modifications , and binding of estrogen receptor , <span class="gene_color">erb</span> to regulatory dna sequences of <span class="gene_color">cyp19a1</span> gene were evaluated by chromatin immunoprecipitation ( chip ) assay .</td>
</tr>
<tr class="even">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>RET</td>
<td>EDNRB</td>
<td>0.816</td>
<td>0.96</td>
<td>136</td>
<td>Novel</td>
<td>mutations in the <span class="gene_color">ret</span> gene , which codes for a receptor tyrosine kinase , and in <span class="gene_color">ednrb</span> which codes for the endothelin-b receptor , have been shown to be associated with hscr in humans .</td>
</tr>
<tr class="odd">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>PKD1</td>
<td>PKD2</td>
<td>1</td>
<td>0.959</td>
<td>1614</td>
<td>Existing</td>
<td>approximately 85 % of adpkd cases are caused by mutations in the <span class="gene_color">pkd1</span> gene , while mutations in the <span class="gene_color">pkd2</span> gene account for the remaining 15 % of cases .</td>
</tr>
<tr class="even">
<td><span class="gene_color">G</span>i<span class="gene_color">G</span></td>
<td>LYZ</td>
<td>CTCF</td>
<td>0.999</td>
<td>0.959</td>
<td>2</td>
<td>Novel</td>
<td>in conjunction with the thyroid receptor ( tr ) , <span class="gene_color">ctcf</span> binding to the <span class="gene_color">lysozyme</span> gene transcriptional silencer mediates the thyroid hormone response element ( tre ) - dependent transcriptional repression .</td>
</tr>
</tbody>
</table>
</div>
<!-- default theme -->

<style>
  /* import google fonts */
  @import url("https://fonts.googleapis.com/css?family=Open+Sans:400,600,700");
  @import url("https://fonts.googleapis.com/css?family=Source+Code+Pro");

  /* -------------------------------------------------- */
  /* global */
  /* -------------------------------------------------- */

  /* all elements */
  * {
    /* force sans-serif font unless specified otherwise */
    font-family: "Open Sans", "Helvetica", sans-serif;

    /* prevent text inflation on some mobile browsers */
    -webkit-text-size-adjust: none !important;
    -moz-text-size-adjust: none !important;
    -o-text-size-adjust: none !important;
    text-size-adjust: none !important;
  }

  @media only screen {
    /* "page" element */
    body {
      position: relative;
      box-sizing: border-box;
      font-size: 12pt;
      line-height: 1.5;
      max-width: 8.5in;
      margin: 20px auto;
      padding: 40px;
      border-radius: 5px;
      border: solid 1px #bdbdbd;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      background: #ffffff;
    }
  }

  /* when on screen < 8.5in wide */
  @media only screen and (max-width: 8.5in) {
    /* "page" element */
    body {
      padding: 20px;
      margin: 0;
      border-radius: 0;
      border: none;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05) inset;
      background: none;
    }
  }

  /* -------------------------------------------------- */
  /* headings */
  /* -------------------------------------------------- */

  /* all headings */
  h1,
  h2,
  h3,
  h4,
  h5,
  h6 {
    margin: 20px 0;
    padding: 0;
    font-weight: bold;
  }

  /* biggest heading */
  h1 {
    margin: 40px 0;
    text-align: center;
  }

  /* second biggest heading */
  h2 {
    margin-top: 30px;
    padding-bottom: 5px;
    border-bottom: solid 1px #bdbdbd;
  }

  /* heading font sizes */
  h1 {
    font-size: 2em;
  }
  h2 {
    font-size: 1.5em;
  }
  h3 {
    font-size: 1.35em;
  }
  h4 {
    font-size: 1.25em;
  }
  h5 {
    font-size: 1.15em;
  }
  h6 {
    font-size: 1em;
  }

  /* -------------------------------------------------- */
  /* manuscript header */
  /* -------------------------------------------------- */

  /* manuscript title */
  header > h1 {
    margin: 0;
  }

  /* manuscript title caption text (ie "automatically generated on") */
  header + p {
    text-align: center;
    margin-top: 10px;
  }

  /* -------------------------------------------------- */
  /* text elements */
  /* -------------------------------------------------- */

  /* links */
  a {
    color: #2196f3;
    overflow-wrap: break-word;
  }

  /* superscripts and subscripts */
  sub,
  sup {
    /* prevent from affecting line height */
    line-height: 0;
  }

  /* unordered and ordered lists*/
  ul,
  ol {
    padding-left: 20px;
  }

  /* class for styling text semibold */
  .semibold {
    font-weight: 600;
  }

  /* class for styling elements horizontally left aligned */
  .left {
    display: block;
    text-align: left;
    margin-left: auto;
    margin-right: 0;
    justify-content: left;
  }

  /* class for styling elements horizontally centered */
  .center {
    display: block;
    text-align: center;
    margin-left: auto;
    margin-right: auto;
    justify-content: center;
  }

  /* class for styling elements horizontally right aligned */
  .right {
    display: block;
    text-align: right;
    margin-left: 0;
    margin-right: auto;
    justify-content: right;
  }

  /* -------------------------------------------------- */
  /* section elements */
  /* -------------------------------------------------- */

  /* horizontal divider line */
  hr {
    border: none;
    height: 1px;
    background: #bdbdbd;
  }

  /* paragraphs, horizontal dividers, figures, tables, code */
  p,
  hr,
  figure,
  table,
  pre {
    /* treat all as "paragraphs", with consistent vertical margins */
    margin-top: 20px;
    margin-bottom: 20px;
  }

  /* -------------------------------------------------- */
  /* figures */
  /* -------------------------------------------------- */

  /* figure */
  figure {
    max-width: 100%;
    margin-left: auto;
    margin-right: auto;
  }

  /* figure caption */
  figcaption {
    padding: 0;
    padding-top: 10px;
  }

  /* figure image element */
  figure > img,
  figure > svg {
    max-width: 100%;
    display: block;
    margin-left: auto;
    margin-right: auto;
  }

  /* figure auto-number */
  img + figcaption > span:first-of-type,
  svg + figcaption > span:first-of-type {
    font-weight: bold;
    margin-right: 5px;
  }

  /* -------------------------------------------------- */
  /* tables */
  /* -------------------------------------------------- */

  /* table */
  table {
    border-collapse: collapse;
    border-spacing: 0;
    width: 100%;
    margin-left: auto;
    margin-right: auto;
  }

  /* table cells */
  th,
  td {
    border: solid 1px #bdbdbd;
    padding: 10px;
    /* squash table if too wide for page by forcing line breaks */
    overflow-wrap: break-word;
    word-break: break-word;
  }

  /* header row and even rows */
  th,
  tr:nth-child(2n) {
    background-color: #fafafa;
  }

  /* odd rows */
  tr:nth-child(2n + 1) {
    background-color: #ffffff;
  }

  /* table caption */
  caption {
    text-align: left;
    padding: 0;
    padding-bottom: 10px;
  }

  /* table auto-number */
  table > caption > span:first-of-type {
    font-weight: bold;
    margin-right: 5px;
  }

  /* -------------------------------------------------- */
  /* code */
  /* -------------------------------------------------- */

  /* multi-line code block */
  pre {
    padding: 10px;
    background-color: #eeeeee;
    color: #000000;
    border-radius: 5px;
    break-inside: avoid;
    text-align: left;
  }

  /* inline code, ie code within normal text */
  :not(pre) > code {
    padding: 0 4px;
    background-color: #eeeeee;
    color: #000000;
    border-radius: 5px;
  }

  /* code text */
  /* apply all children, to reach syntax highlighting sub-elements */
  code,
  code * {
    /* force monospace font */
    font-family: "Source Code Pro", "Courier New", monospace;
  }

  /* -------------------------------------------------- */
  /* quotes */
  /* -------------------------------------------------- */

  /* quoted text */
  blockquote {
    margin: 0;
    padding: 0;
    border-left: 4px solid #bdbdbd;
    padding-left: 16px;
    break-inside: avoid;
  }

  /* -------------------------------------------------- */
  /* banners */
  /* -------------------------------------------------- */

  /* info banners */
  .banner {
    box-sizing: border-box;
    display: block;
    position: relative;
    width: 100%;
    margin-top: 20px;
    margin-bottom: 20px;
    padding: 20px;
    text-align: center;
  }

  /* paragraph in banner */
  .banner > p {
    margin: 0;
  }

  /* -------------------------------------------------- */
  /* highlight colors */
  /* -------------------------------------------------- */

  .white {
    background: #ffffff;
  }
  .lightgrey {
    background: #eeeeee;
  }
  .grey {
    background: #757575;
  }
  .darkgrey {
    background: #424242;
  }
  .black {
    background: #000000;
  }
  .lightred {
    background: #ffcdd2;
  }
  .lightyellow {
    background: #ffecb3;
  }
  .lightgreen {
    background: #dcedc8;
  }
  .lightblue {
    background: #e3f2fd;
  }
  .lightpurple {
    background: #f3e5f5;
  }
  .red {
    background: #f44336;
  }
  .orange {
    background: #ff9800;
  }
  .yellow {
    background: #ffeb3b;
  }
  .green {
    background: #4caf50;
  }
  .blue {
    background: #2196f3;
  }
  .purple {
    background: #9c27b0;
  }
  .white,
  .lightgrey,
  .lightred,
  .lightyellow,
  .lightgreen,
  .lightblue,
  .lightpurple,
  .orange,
  .yellow,
  .white a,
  .lightgrey a,
  .lightred a,
  .lightyellow a,
  .lightgreen a,
  .lightblue a,
  .lightpurple a,
  .orange a,
  .yellow a {
    color: #000000;
  }
  .grey,
  .darkgrey,
  .black,
  .red,
  .green,
  .blue,
  .purple,
  .grey a,
  .darkgrey a,
  .black a,
  .red a,
  .green a,
  .blue a,
  .purple a {
    color: #ffffff;
  }

  /* -------------------------------------------------- */
  /* buttons */
  /* -------------------------------------------------- */

  /* class for styling links like buttons */
  .button {
    display: inline-flex;
    justify-content: center;
    align-items: center;
    margin: 5px;
    padding: 10px 20px;
    font-size: 0.75em;
    font-weight: 600;
    text-transform: uppercase;
    text-decoration: none;
    letter-spacing: 1px;
    background: none;
    color: #2196f3;
    border: solid 1px #bdbdbd;
    border-radius: 5px;
  }

  /* buttons when hovered */
  .button:hover:not([disabled]),
  .icon_button:hover:not([disabled]) {
    cursor: pointer;
    background: #f5f5f5;
  }

  /* buttons when disabled */
  .button[disabled],
  .icon_button[disabled] {
    opacity: 0.35;
    pointer-events: none;
  }

  /* class for styling buttons containg only single icon */
  .icon_button {
    display: inline-flex;
    justify-content: center;
    align-items: center;
    text-decoration: none;
    margin: 0;
    padding: 0;
    background: none;
    border-radius: 5px;
    border: none;
    width: 20px;
    height: 20px;
    min-width: 20px;
    min-height: 20px;
  }

  /* icon button inner svg image */
  .icon_button > svg {
    height: 16px;
  }

  /* -------------------------------------------------- */
  /* icons */
  /* -------------------------------------------------- */

  /* class for styling icons inline with text */
  .inline_icon {
    height: 1em;
    position: relative;
    top: 0.125em;
  }

  /* -------------------------------------------------- */
  /* references */
  /* -------------------------------------------------- */

  .csl-entry {
    margin-top: 15px;
    margin-bottom: 15px;
  }

  /* -------------------------------------------------- */
  /* print control */
  /* -------------------------------------------------- */

  @media print {
    @page {
      /* suggested printing margin */
      margin: 0.5in;
    }

    /* document and "page" elements */
    html,
    body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
    }

    /* "page" element */
    body {
      font-size: 11pt !important;
      line-height: 1.35;
    }

    /* all headings */
    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      margin: 15px 0;
    }

    /* figures and tables */
    figure,
    table {
      font-size: 0.85em;
    }

    /* table cells */
    th,
    td {
      padding: 5px;
    }

    /* shrink font awesome icons */
    i.fas,
    i.fab,
    i.far,
    i.fal {
      transform: scale(0.85);
    }

    /* decrease banner margins */
    .banner {
      margin-top: 15px;
      margin-bottom: 15px;
      padding: 15px;
    }

    /* class for centering an element vertically on its own page */
    .page_center {
      margin: auto;
      width: 100%;
      height: 100%;
      display: flex;
      align-items: center;
      vertical-align: middle;
      break-before: page;
      break-after: page;
    }

    /* always insert a page break before the element */
    .page_break_before {
      break-before: page;
    }

    /* always insert a page break after the element */
    .page_break_after {
      break-after: page;
    }

    /* avoid page break before the element */
    .page_break_before_avoid {
      break-before: avoid;
    }

    /* avoid page break after the element */
    .page_break_after_avoid {
      break-after: avoid;
    }

    /* avoid page break inside the element */
    .page_break_inside_avoid {
      break-inside: avoid;
    }
  }

  /* -------------------------------------------------- */
  /* override pandoc css quirks */
  /* -------------------------------------------------- */

  .sourceCode {
    /* prevent unsightly overflow in wide code blocks */
    overflow: auto !important;
  }

  div.sourceCode {
    /* prevent background fill on top-most code block  container */
    background: none !important;
  }

  .sourceCode * {
    /* force consistent line spacing */
    line-height: 1.5 !important;
  }

  div.sourceCode {
    /* style code block margins same as <pre> element */
    margin-top: 20px;
    margin-bottom: 20px;
  }

  /* -------------------------------------------------- */
  /* tablenos */
  /* -------------------------------------------------- */

  /* tablenos wrapper */
  .tablenos {
    width: 100%;
    margin: 20px 0;
  }

  .tablenos > table {
    /* move margins from table to table_wrapper to allow margin collapsing */
    margin: 0;
  }

  @media only screen {
    /* tablenos wrapper */
    .tablenos {
      /* show scrollbar on tables if necessary to prevent overflow */
      overflow-x: auto !important;
    }

    .tablenos th,
    .tablenos td {
      overflow-wrap: unset !important;
      word-break: unset !important;
    }

    /* table in wrapper */
    .tablenos table,
    .tablenos table * {
      /* don't break table words */
      overflow-wrap: normal !important;
    }
  }
</style>
<!-- 
    Plugin Core

    Functions needed for and shared across all first-party plugins.
-->

<script>
  // get element that is target of hash (from link element or url)
  function getHashTarget(link) {
    const hash = link ? link.hash : window.location.hash;
    const id = hash.slice(1);
    let target = document.querySelector(`[id="${id}"]`);
    if (!target) return;

    // if figure or table, modify target to get expected element
    if (id.indexOf("fig:") === 0) target = target.querySelector("figure");
    if (id.indexOf("tbl:") === 0) target = target.querySelector("table");

    return target;
  }

  // get position/dimensions of element or viewport
  function getRectInView(element) {
    let rect = {};
    rect.left = 0;
    rect.top = 0;
    rect.right = document.documentElement.clientWidth;
    rect.bottom = document.documentElement.clientHeight;
    let style = {};

    if (element instanceof HTMLElement) {
      rect = element.getBoundingClientRect();
      style = window.getComputedStyle(element);
    }

    const margin = {};
    margin.left = parseFloat(style.marginLeftWidth) || 0;
    margin.top = parseFloat(style.marginTopWidth) || 0;
    margin.right = parseFloat(style.marginRightWidth) || 0;
    margin.bottom = parseFloat(style.marginBottomWidth) || 0;

    const border = {};
    border.left = parseFloat(style.borderLeftWidth) || 0;
    border.top = parseFloat(style.borderTopWidth) || 0;
    border.right = parseFloat(style.borderRightWidth) || 0;
    border.bottom = parseFloat(style.borderBottomWidth) || 0;

    const newRect = {};
    newRect.left = rect.left + margin.left + border.left;
    newRect.top = rect.top + margin.top + border.top;
    newRect.right = rect.right + margin.right + border.right;
    newRect.bottom = rect.bottom + margin.bottom + border.bottom;
    newRect.width = newRect.right - newRect.left;
    newRect.height = newRect.bottom - newRect.top;

    return newRect;
  }

  // get position of element relative to page
  function getRectInPage(element) {
    const rect = getRectInView(element);
    const body = getRectInView(document.body);

    const newRect = {};
    newRect.left = rect.left - body.left;
    newRect.top = rect.top - body.top;
    newRect.right = rect.right - body.left;
    newRect.bottom = rect.bottom - body.top;
    newRect.width = rect.width;
    newRect.height = rect.height;

    return newRect;
  }

  // get closest element before specified element that matches query
  function firstBefore(element, query) {
    while (element && element !== document.body && !element.matches(query))
      element = element.previousElementSibling || element.parentNode;

    return element;
  }

  // check if element is part of collapsed heading
  function isCollapsed(element) {
    while (element && element !== document.body) {
      if (element.dataset.collapsed === "true") return true;
      element = element.parentNode;
    }
    return false;
  }

  // expand any collapsed parent containers of element if necessary
  function expandElement(element) {
    if (isCollapsed(element)) {
      // accordion plugin
      const heading = firstBefore(element, "h2");
      if (heading) heading.click();
      // details/summary HTML element
      const summary = firstBefore(element, "summary");
      if (summary) summary.click();
    }
  }

  // scroll to and focus element
  function goToElement(element, offset) {
    // expand accordion section if collapsed
    expandElement(element);
    const y =
      getRectInView(element).top -
      getRectInView(document.documentElement).top -
      (offset || 0);

    // trigger any function listening for "onscroll" event
    window.dispatchEvent(new Event("scroll"));
    window.scrollTo(0, y);
    document.activeElement.blur();
    element.focus();
  }

  // get list of elements after a start element up to element matching query
  function nextUntil(element, query, exclude) {
    const elements = [];
    while (((element = element.nextElementSibling), element)) {
      if (element.matches(query)) break;
      if (!element.matches(exclude)) elements.push(element);
    }
    return elements;
  }
</script>
<!--
  Accordion Plugin

  Allows sections of content under h2 headings to be collapsible.
-->

<script type="module">
  // whether to always start expanded ('false'), always start collapsed
  // ('true'), or start collapsed when screen small ('auto')
  const startCollapsed = "auto";

  // start script
  function start() {
    // run through each <h2> heading
    const headings = document.querySelectorAll("h2");
    for (const heading of headings) {
      addArrow(heading);

      // start expanded/collapsed based on option
      if (
        startCollapsed === "true" ||
        (startCollapsed === "auto" && isSmallScreen()) ||
        heading.dataset.collapsed === "true"
      )
        collapseHeading(heading);
      else expandElement(heading);
    }

    // attach hash change listener to window
    window.addEventListener("hashchange", onHashChange);
  }

  // when hash (eg manuscript.html#introduction) changes
  function onHashChange() {
    const target = getHashTarget();
    if (target) goToElement(target);
  }

  // add arrow to heading
  function addArrow(heading) {
    // add arrow button
    const arrow = document.createElement("button");
    arrow.innerHTML = document.querySelector(".icon_angle_down").innerHTML;
    arrow.classList.add("icon_button", "accordion_arrow");
    heading.insertBefore(arrow, heading.firstChild);

    // attach click listener to heading and button
    heading.addEventListener("click", onHeadingClick);
    arrow.addEventListener("click", onArrowClick);
  }

  // determine if on mobile-like device with small screen
  function isSmallScreen() {
    return Math.min(window.innerWidth, window.innerHeight) < 480;
  }

  // when <h2> heading is clicked
  function onHeadingClick(event) {
    // only collapse if <h2> itself is target of click (eg, user did
    // not click on anchor within <h2>)
    if (event.target === this) toggleCollapse(this);
  }

  // when arrow button is clicked
  function onArrowClick() {
    toggleCollapse(this.parentNode);
  }

  // collapse section if expanded, expand if collapsed
  function toggleCollapse(heading) {
    if (heading.dataset.collapsed === "false") collapseHeading(heading);
    else expandElement(heading);
  }

  // elements to exclude from collapse, such as table of contents panel,
  // hypothesis panel, etc
  const exclude = "#toc_panel, div.annotator-frame, #lightbox_overlay";

  // collapse section
  function collapseHeading(heading) {
    heading.setAttribute("data-collapsed", "true");
    const children = getChildren(heading);
    for (const child of children) child.setAttribute("data-collapsed", "true");
  }

  // expand section
  function expandElement(heading) {
    heading.setAttribute("data-collapsed", "false");
    const children = getChildren(heading);
    for (const child of children) child.setAttribute("data-collapsed", "false");
  }

  // get list of elements between this <h2> and next <h2> or <h1>
  // ("children" of the <h2> section)
  function getChildren(heading) {
    return nextUntil(heading, "h2, h1", exclude);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- angle down icon -->

<template class="icon_angle_down">
  <!-- modified from: https://fontawesome.com/icons/angle-down -->
  <svg width="16" height="16" viewBox="0 0 448 512">
    <path
      fill="currentColor"
      d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* accordion arrow button */
    .accordion_arrow {
      margin-right: 10px;
    }

    /* arrow icon when <h2> data-collapsed attribute true */
    h2[data-collapsed="true"] > .accordion_arrow > svg {
      transform: rotate(-90deg);
    }

    /* all elements (except <h2>'s) when data-collapsed attribute true */
    *:not(h2)[data-collapsed="true"] {
      display: none;
    }

    /* accordion arrow button when hovered and <h2>'s when hovered */
    .accordion_arrow:hover,
    h2[data-collapsed="true"]:hover,
    h2[data-collapsed="false"]:hover {
      cursor: pointer;
    }
  }

  /* always hide accordion arrow button on print */
  @media only print {
    .accordion_arrow {
      display: none;
    }
  }
</style>
<!--
  Anchors Plugin

  Adds an anchor next to each of a certain type of element that provides a
  human-readable url to that specific item/position in the document (e.g.
  "manuscript.html#abstract"). It also makes it such that scrolling out of view
  of a target removes its identifier from the url.
-->

<script type="module">
  // which types of elements to add anchors next to, in "document.querySelector"
  // format
  const typesQuery =
    'h1, h2, h3, div[id^="fig:"], div[id^="tbl:"], span[id^="eq:"]';

  // start script
  function start() {
    // add anchor to each element of specified types
    const elements = document.querySelectorAll(typesQuery);
    for (const element of elements) addAnchor(element);

    // attach scroll listener to window
    window.addEventListener("scroll", onScroll);
  }

  // when window is scrolled
  function onScroll() {
    // if url has hash and user has scrolled out of view of hash
    // target, remove hash from url
    const tolerance = 100;
    const target = getHashTarget();
    if (target) {
      if (
        target.getBoundingClientRect().top > window.innerHeight + tolerance ||
        target.getBoundingClientRect().bottom < 0 - tolerance
      )
        history.pushState(null, null, " ");
    }
  }

  // add anchor to element
  function addAnchor(element) {
    let addTo; // element to add anchor button to

    // if figure or table, modify withId and addTo to get expected
    // elements
    if (element.id.indexOf("fig:") === 0) {
      addTo = element.querySelector("figcaption");
    } else if (element.id.indexOf("tbl:") === 0) {
      addTo = element.querySelector("caption");
    } else if (element.id.indexOf("eq:") === 0) {
      addTo = element.querySelector(".eqnos-number");
    }

    addTo = addTo || element;
    const id = element.id || null;

    // do not add anchor if element doesn't have assigned id.
    // id is generated by pandoc and is assumed to be unique and
    // human-readable
    if (!id) return;

    // create anchor button
    const anchor = document.createElement("a");
    anchor.innerHTML = document.querySelector(".icon_link").innerHTML;
    anchor.title = "Link to this part of the document";
    anchor.classList.add("icon_button", "anchor");
    anchor.dataset.ignore = "true";
    anchor.href = "#" + id;
    addTo.appendChild(anchor);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- link icon -->

<template class="icon_link">
  <!-- modified from: https://fontawesome.com/icons/link -->
  <svg width="16" height="16" viewBox="0 0 512 512">
    <path
      fill="currentColor"
      d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* anchor button */
    .anchor {
      opacity: 0;
      margin-left: 5px;
    }

    /* anchor buttons within <h2>'s */
    h2 .anchor {
      margin-left: 10px;
    }

    /* anchor buttons when hovered/focused and anything containing an anchor button when hovered */
    *:hover > .anchor,
    .anchor:hover,
    .anchor:focus {
      opacity: 1;
    }

    /* anchor button when hovered */
    .anchor:hover {
      cursor: pointer;
    }
  }

  /* always show anchor button on devices with no mouse/hover ability */
  @media (hover: none) {
    .anchor {
      opacity: 1;
    }
  }

  /* always hide anchor button on print */
  @media only print {
    .anchor {
      display: none;
    }
  }
</style>
<!-- 
    Attributes Plugin

    Allows arbitrary HTML attributes to be attached to (almost) any element.
    Place an HTML comment inside or next to the desired element with the content:
    $attribute="value"
-->

<script type="module">
  // start script
  function start() {
    // get list of comments in document
    const comments = findComments();

    for (const comment of comments)
      if (comment.parentElement)
        addAttributes(comment.parentElement, comment.nodeValue.trim());
  }

  // add html attributes to specified element based on string of
  // html attributes and values
  function addAttributes(element, text) {
    // regex's for finding attribute/value pairs in the format of
    // attribute="value" or attribute='value
    const regex2 = /\$([a-zA-Z\-]+)?=\"(.+?)\"/;
    const regex1 = /\$([a-zA-Z\-]+)?=\'(.+?)\'/;

    // loop through attribute/value pairs
    let match;
    while ((match = text.match(regex2) || text.match(regex1))) {
      // get attribute and value from regex capture groups
      let attribute = match[1];
      let value = match[2];

      // remove from string
      text = text.substring(match.index + match[0].length);

      if (!attribute || !value) break;

      // set attribute of parent element
      try {
        element.setAttribute(attribute, value);
      } catch (error) {
        console.log(error);
      }

      // special case for colspan
      if (attribute === "colspan") removeTableCells(element, value);
    }
  }

  // get list of comment elements in document
  function findComments() {
    const comments = [];

    // iterate over comment nodes in document
    function acceptNode(node) {
      return NodeFilter.FILTER_ACCEPT;
    }
    const iterator = document.createNodeIterator(
      document.body,
      NodeFilter.SHOW_COMMENT,
      acceptNode
    );
    let node;
    while ((node = iterator.nextNode())) comments.push(node);

    return comments;
  }

  // remove certain number of cells after specified cell
  function removeTableCells(cell, number) {
    number = parseInt(number);
    if (!number) return;

    // remove elements
    for (; number > 1; number--) {
      if (cell.nextElementSibling) cell.nextElementSibling.remove();
    }
  }

  // start script on DOMContentLoaded instead of load to ensure this plugins
  // runs before other plugins
  window.addEventListener("DOMContentLoaded", start);
</script>
<!--
  Jump to First Plugin

  Adds a button next to each reference entry, figure, and table that jumps the
  page to the first occurrence of a link to that item in the manuscript.
-->

<script type="module">
  // whether to add buttons next to reference entries
  const references = "true";
  // whether to add buttons next to figures
  const figures = "true";
  // whether to add buttons next to tables
  const tables = "true";

  // start script
  function start() {
    if (references !== "false")
      makeButtons(`div[id^="ref-"]`, ".csl-left-margin", "reference");
    if (figures !== "false")
      makeButtons(`div[id^="fig:"]`, "figcaption", "figure");
    if (tables !== "false") makeButtons(`div[id^="tbl:"]`, "caption", "table");
  }

  // when jump button clicked
  function onButtonClick() {
    const first = getFirstOccurrence(this.dataset.id);
    if (!first) return;

    // update url hash so navigating "back" in history will return user to button
    window.location.hash = this.dataset.id;
    // scroll to link
    const timeout = function () {
      goToElement(first, window.innerHeight * 0.5);
    };
    window.setTimeout(timeout, 0);
  }

  // get first occurrence of link to item in document
  function getFirstOccurrence(id) {
    let query = "a";
    query += '[href="#' + id + '"]';
    // exclude buttons, anchor links, toc links, etc
    query += ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    return document.querySelector(query);
  }

  // add button next to each reference entry, figure, or table
  function makeButtons(query, containerQuery, subject) {
    const elements = document.querySelectorAll(query);
    for (const element of elements) {
      const id = element.id;
      const buttonContainer = element.querySelector(containerQuery);
      const first = getFirstOccurrence(id);

      // if can't find link to reference or place to put button, ignore
      if (!first || !buttonContainer) continue;

      // make jump button
      let button = document.createElement("button");
      button.classList.add("icon_button", "jump_arrow");
      button.title = `Jump to the first occurrence of this ${subject} in the document`;
      const icon = document.querySelector(".icon_angle_double_up");
      button.innerHTML = icon.innerHTML;
      button.dataset.id = id;
      button.dataset.ignore = "true";
      button.addEventListener("click", onButtonClick);
      buttonContainer.prepend(button);
    }
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- angle double up icon -->

<template class="icon_angle_double_up">
  <!-- modified from: https://fontawesome.com/icons/angle-double-up -->
  <svg width="16" height="16" viewBox="0 0 320 512">
    <path
      fill="currentColor"
      d="M177 255.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 351.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 425.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1zm-34-192L7 199.7c-9.4 9.4-9.4 24.6 0 33.9l22.6 22.6c9.4 9.4 24.6 9.4 33.9 0l96.4-96.4 96.4 96.4c9.4 9.4 24.6 9.4 33.9 0l22.6-22.6c9.4-9.4 9.4-24.6 0-33.9l-136-136c-9.2-9.4-24.4-9.4-33.8 0z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* jump button */
    .jump_arrow {
      position: relative;
      top: 0.125em;
      margin-right: 5px;
    }
  }

  /* always hide jump button on print */
  @media only print {
    .jump_arrow {
      display: none;
    }
  }
</style>
<!-- 
    Lightbox Plugin

    Makes it such that when a user clicks on an image, the image fills the
    screen and the user can pan/drag/zoom the image and navigate between other
    images in the document.
-->

<script type="module">
  // list of possible zoom/scale factors
  const zooms =
    "0.1, 0.25, 0.333333, 0.5, 0.666666, 0.75, 1, 1.25, 1.5, 1.75, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8";
  // whether to fit image to view ('fit'), display at 100% and shrink if
  // necessary ('shrink'), or always display at 100% ('100')
  const defaultZoom = "fit";
  // whether to zoom in/out toward center of view ('true') or mouse ('false')
  const centerZoom = "false";

  // start script
  function start() {
    // run through each <img> element
    const imgs = document.querySelectorAll("figure > img");
    let count = 1;
    for (const img of imgs) {
      img.classList.add("lightbox_document_img");
      img.dataset.number = count;
      img.dataset.total = imgs.length;
      img.addEventListener("click", openLightbox);
      count++;
    }

    // attach mouse and key listeners to window
    window.addEventListener("mousemove", onWindowMouseMove);
    window.addEventListener("keyup", onKeyUp);
  }

  // when mouse is moved anywhere in window
  function onWindowMouseMove(event) {
    window.mouseX = event.clientX;
    window.mouseY = event.clientY;
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    switch (event.key) {
      // trigger click of prev button
      case "ArrowLeft":
        const prevButton = document.getElementById("lightbox_prev_button");
        if (prevButton) prevButton.click();
        break;
      // trigger click of next button
      case "ArrowRight":
        const nextButton = document.getElementById("lightbox_next_button");
        if (nextButton) nextButton.click();
        break;
      // close on esc
      case "Escape":
        closeLightbox();
        break;
    }
  }

  // open lightbox
  function openLightbox() {
    const lightbox = makeLightbox(this);
    if (!lightbox) return;

    blurBody(lightbox);
    document.body.appendChild(lightbox);
  }

  // make lightbox
  function makeLightbox(img) {
    // delete lightbox if it exists, start fresh
    closeLightbox();

    // create screen overlay containing lightbox
    const overlay = document.createElement("div");
    overlay.id = "lightbox_overlay";

    // create image info boxes
    const numberInfo = document.createElement("div");
    const zoomInfo = document.createElement("div");
    numberInfo.id = "lightbox_number_info";
    zoomInfo.id = "lightbox_zoom_info";

    // create container for image
    const imageContainer = document.createElement("div");
    imageContainer.id = "lightbox_image_container";
    const lightboxImg = makeLightboxImg(
      img,
      imageContainer,
      numberInfo,
      zoomInfo
    );
    imageContainer.appendChild(lightboxImg);

    // create bottom container for caption and navigation buttons
    const bottomContainer = document.createElement("div");
    bottomContainer.id = "lightbox_bottom_container";
    const caption = makeCaption(img);
    const prevButton = makePrevButton(img);
    const nextButton = makeNextButton(img);
    bottomContainer.appendChild(prevButton);
    bottomContainer.appendChild(caption);
    bottomContainer.appendChild(nextButton);

    // attach top middle and bottom to overlay
    overlay.appendChild(numberInfo);
    overlay.appendChild(zoomInfo);
    overlay.appendChild(imageContainer);
    overlay.appendChild(bottomContainer);

    return overlay;
  }

  // make <img> object that is intuitively draggable and zoomable
  function makeLightboxImg(sourceImg, container, numberInfoBox, zoomInfoBox) {
    // create copy of source <img>
    const img = sourceImg.cloneNode(true);
    img.classList.remove("lightbox_document_img");
    img.removeAttribute("id");
    img.removeAttribute("width");
    img.removeAttribute("height");
    img.style.position = "unset";
    img.style.margin = "0";
    img.style.padding = "0";
    img.style.width = "";
    img.style.height = "";
    img.style.minWidth = "";
    img.style.minHeight = "";
    img.style.maxWidth = "";
    img.style.maxHeight = "";
    img.id = "lightbox_img";

    // build sorted list of zoomSteps
    const zoomSteps = zooms.split(/[^0-9.]/).map((step) => parseFloat(step));
    zoomSteps.sort((a, b) => a - b);

    // <img> object property variables
    let zoom = 1;
    let translateX = 0;
    let translateY = 0;
    let clickMouseX = undefined;
    let clickMouseY = undefined;
    let clickTranslateX = undefined;
    let clickTranslateY = undefined;

    updateNumberInfo();

    // update image numbers displayed in info box
    function updateNumberInfo() {
      numberInfoBox.innerHTML =
        sourceImg.dataset.number + " of " + sourceImg.dataset.total;
    }

    // update zoom displayed in info box
    function updateZoomInfo() {
      let zoomInfo = zoom * 100;
      if (!Number.isInteger(zoomInfo)) zoomInfo = zoomInfo.toFixed(2);
      zoomInfoBox.innerHTML = zoomInfo + "%";
    }

    // move to closest zoom step above current zoom
    const zoomIn = function () {
      for (const zoomStep of zoomSteps) {
        if (zoomStep > zoom) {
          zoom = zoomStep;
          break;
        }
      }
      updateTransform();
    };

    // move to closest zoom step above current zoom
    const zoomOut = function () {
      zoomSteps.reverse();
      for (const zoomStep of zoomSteps) {
        if (zoomStep < zoom) {
          zoom = zoomStep;
          break;
        }
      }
      zoomSteps.reverse();

      updateTransform();
    };

    // update display of <img> based on scale/translate properties
    const updateTransform = function () {
      // set transform
      img.style.transform =
        "translate(" +
        (translateX || 0) +
        "px," +
        (translateY || 0) +
        "px) scale(" +
        (zoom || 1) +
        ")";

      // get new width/height after scale
      const rect = img.getBoundingClientRect();
      // limit translate
      translateX = Math.max(translateX, -rect.width / 2);
      translateX = Math.min(translateX, rect.width / 2);
      translateY = Math.max(translateY, -rect.height / 2);
      translateY = Math.min(translateY, rect.height / 2);

      // set transform
      img.style.transform =
        "translate(" +
        (translateX || 0) +
        "px," +
        (translateY || 0) +
        "px) scale(" +
        (zoom || 1) +
        ")";

      updateZoomInfo();
    };

    // fit <img> to container
    const fit = function () {
      // no x/y offset, 100% zoom by default
      translateX = 0;
      translateY = 0;
      zoom = 1;

      // widths of <img> and container
      const imgWidth = img.naturalWidth;
      const imgHeight = img.naturalHeight;
      const containerWidth = parseFloat(
        window.getComputedStyle(container).width
      );
      const containerHeight = parseFloat(
        window.getComputedStyle(container).height
      );

      // how much zooming is needed to fit <img> to container
      const xRatio = imgWidth / containerWidth;
      const yRatio = imgHeight / containerHeight;
      const maxRatio = Math.max(xRatio, yRatio);
      const newZoom = 1 / maxRatio;

      // fit <img> to container according to option
      if (defaultZoom === "shrink") {
        if (maxRatio > 1) zoom = newZoom;
      } else if (defaultZoom === "fit") zoom = newZoom;

      updateTransform();
    };

    // when mouse wheel is rolled anywhere in container
    const onContainerWheel = function (event) {
      if (!event) return;

      // let ctrl + mouse wheel to zoom behave as normal
      if (event.ctrlKey) return;

      // prevent normal scroll behavior
      event.preventDefault();
      event.stopPropagation();

      // point around which to scale img
      const viewRect = container.getBoundingClientRect();
      const viewX = (viewRect.left + viewRect.right) / 2;
      const viewY = (viewRect.top + viewRect.bottom) / 2;
      const originX = centerZoom === "true" ? viewX : mouseX;
      const originY = centerZoom === "true" ? viewY : mouseY;

      // get point on image under origin
      const oldRect = img.getBoundingClientRect();
      const oldPercentX = (originX - oldRect.left) / oldRect.width;
      const oldPercentY = (originY - oldRect.top) / oldRect.height;

      // increment/decrement zoom
      if (event.deltaY < 0) zoomIn();
      if (event.deltaY > 0) zoomOut();

      // get offset between previous image point and origin
      const newRect = img.getBoundingClientRect();
      const offsetX = originX - (newRect.left + newRect.width * oldPercentX);
      const offsetY = originY - (newRect.top + newRect.height * oldPercentY);

      // translate image to keep image point under origin
      translateX += offsetX;
      translateY += offsetY;

      // perform translate
      updateTransform();
    };

    // when container is clicked
    function onContainerClick(event) {
      // if container itself is target of click, and not other
      // element above it
      if (event.target === this) closeLightbox();
    }

    // when mouse button is pressed on image
    const onImageMouseDown = function (event) {
      // store original mouse position relative to image
      clickMouseX = window.mouseX;
      clickMouseY = window.mouseY;
      clickTranslateX = translateX;
      clickTranslateY = translateY;
      event.stopPropagation();
      event.preventDefault();
    };

    // when mouse button is released anywhere in window
    const onWindowMouseUp = function (event) {
      // reset original mouse position
      clickMouseX = undefined;
      clickMouseY = undefined;
      clickTranslateX = undefined;
      clickTranslateY = undefined;

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("mouseup", onWindowMouseUp);
    };

    // when mouse is moved anywhere in window
    const onWindowMouseMove = function (event) {
      if (
        clickMouseX === undefined ||
        clickMouseY === undefined ||
        clickTranslateX === undefined ||
        clickTranslateY === undefined
      )
        return;

      // offset image based on original and current mouse position
      translateX = clickTranslateX + window.mouseX - clickMouseX;
      translateY = clickTranslateY + window.mouseY - clickMouseY;
      updateTransform();
      event.preventDefault();

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("mousemove", onWindowMouseMove);
    };

    // when window is resized
    const onWindowResize = function (event) {
      fit();

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("resize", onWindowResize);
    };

    // attach the necessary event listeners
    img.addEventListener("dblclick", fit);
    img.addEventListener("mousedown", onImageMouseDown);
    container.addEventListener("wheel", onContainerWheel);
    container.addEventListener("mousedown", onContainerClick);
    container.addEventListener("touchstart", onContainerClick);
    window.addEventListener("mouseup", onWindowMouseUp);
    window.addEventListener("mousemove", onWindowMouseMove);
    window.addEventListener("resize", onWindowResize);

    // run fit() after lightbox atttached to document and <img> Loaded
    // so needed container and img dimensions available
    img.addEventListener("load", fit);

    return img;
  }

  // make caption
  function makeCaption(img) {
    const caption = document.createElement("div");
    caption.id = "lightbox_caption";
    const captionSource = img.nextElementSibling;
    if (captionSource.tagName.toLowerCase() === "figcaption") {
      const captionCopy = makeCopy(captionSource);
      caption.innerHTML = captionCopy.innerHTML;
    }

    caption.addEventListener("touchstart", function (event) {
      event.stopPropagation();
    });

    return caption;
  }

  // make carbon copy of html dom element
  function makeCopy(source) {
    const sourceCopy = source.cloneNode(true);

    // delete elements marked with ignore (eg anchor and jump buttons)
    const deleteFromCopy = sourceCopy.querySelectorAll('[data-ignore="true"]');
    for (const element of deleteFromCopy) element.remove();

    // delete certain element attributes
    const attributes = [
      "id",
      "data-collapsed",
      "data-selected",
      "data-highlighted",
      "data-glow",
    ];
    for (const attribute of attributes) {
      sourceCopy.removeAttribute(attribute);
      const elements = sourceCopy.querySelectorAll("[" + attribute + "]");
      for (const element of elements) element.removeAttribute(attribute);
    }

    return sourceCopy;
  }

  // make button to jump to previous image in document
  function makePrevButton(img) {
    const prevButton = document.createElement("button");
    prevButton.id = "lightbox_prev_button";
    prevButton.title = "Jump to the previous image in the document [←]";
    prevButton.classList.add("icon_button", "lightbox_button");
    prevButton.innerHTML = document.querySelector(".icon_caret_left").innerHTML;

    // attach click listeners to button
    prevButton.addEventListener("click", function () {
      getPrevImg(img).click();
    });

    return prevButton;
  }

  // make button to jump to next image in document
  function makeNextButton(img) {
    const nextButton = document.createElement("button");
    nextButton.id = "lightbox_next_button";
    nextButton.title = "Jump to the next image in the document [→]";
    nextButton.classList.add("icon_button", "lightbox_button");
    nextButton.innerHTML = document.querySelector(
      ".icon_caret_right"
    ).innerHTML;

    // attach click listeners to button
    nextButton.addEventListener("click", function () {
      getNextImg(img).click();
    });

    return nextButton;
  }

  // get previous image in document
  function getPrevImg(img) {
    const imgs = document.querySelectorAll(".lightbox_document_img");

    // find index of provided img
    let index;
    for (index = 0; index < imgs.length; index++) {
      if (imgs[index] === img) break;
    }

    // wrap index to other side if < 1
    if (index - 1 >= 0) index--;
    else index = imgs.length - 1;
    return imgs[index];
  }

  // get next image in document
  function getNextImg(img) {
    const imgs = document.querySelectorAll(".lightbox_document_img");

    // find index of provided img
    let index;
    for (index = 0; index < imgs.length; index++) {
      if (imgs[index] === img) break;
    }

    // wrap index to other side if > total
    if (index + 1 <= imgs.length - 1) index++;
    else index = 0;
    return imgs[index];
  }

  // close lightbox
  function closeLightbox() {
    focusBody();

    const lightbox = document.getElementById("lightbox_overlay");
    if (lightbox) lightbox.remove();
  }

  // make all elements behind lightbox non-focusable
  function blurBody(overlay) {
    const all = document.querySelectorAll("*");
    for (const element of all) element.tabIndex = -1;
    document.body.classList.add("body_no_scroll");
  }

  // make all elements focusable again
  function focusBody() {
    const all = document.querySelectorAll("*");
    for (const element of all) element.removeAttribute("tabIndex");
    document.body.classList.remove("body_no_scroll");
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
  <!-- modified from: https://fontawesome.com/icons/caret-left -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
    ></path>
  </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
  <!-- modified from: https://fontawesome.com/icons/caret-right -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* regular <img> in document when hovered */
    img.lightbox_document_img:hover {
      cursor: pointer;
    }

    .body_no_scroll {
      overflow: hidden !important;
    }

    /* screen overlay */
    #lightbox_overlay {
      display: flex;
      flex-direction: column;
      position: fixed;
      left: 0;
      top: 0;
      right: 0;
      bottom: 0;
      background: rgba(0, 0, 0, 0.75);
      z-index: 3;
    }

    /* middle area containing lightbox image */
    #lightbox_image_container {
      flex-grow: 1;
      display: flex;
      justify-content: center;
      align-items: center;
      overflow: hidden;
      position: relative;
      padding: 20px;
    }

    /* bottom area containing caption */
    #lightbox_bottom_container {
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100px;
      min-height: 100px;
      max-height: 100px;
      background: rgba(0, 0, 0, 0.5);
    }

    /* image number info text box */
    #lightbox_number_info {
      position: absolute;
      color: #ffffff;
      font-weight: 600;
      left: 2px;
      top: 0;
      z-index: 4;
    }

    /* zoom info text box */
    #lightbox_zoom_info {
      position: absolute;
      color: #ffffff;
      font-weight: 600;
      right: 2px;
      top: 0;
      z-index: 4;
    }

    /* copy of image caption */
    #lightbox_caption {
      box-sizing: border-box;
      display: inline-block;
      width: 100%;
      max-height: 100%;
      padding: 10px 0;
      text-align: center;
      overflow-y: auto;
      color: #ffffff;
    }

    /* navigation previous/next button */
    .lightbox_button {
      width: 100px;
      height: 100%;
      min-width: 100px;
      min-height: 100%;
      color: #ffffff;
    }

    /* navigation previous/next button when hovered */
    .lightbox_button:hover {
      background: none !important;
    }

    /* navigation button icon */
    .lightbox_button > svg {
      height: 25px;
    }

    /* figure auto-number */
    #lightbox_caption > span:first-of-type {
      font-weight: bold;
      margin-right: 5px;
    }

    /* lightbox image when hovered */
    #lightbox_img:hover {
      cursor: grab;
    }

    /* lightbox image when grabbed */
    #lightbox_img:active {
      cursor: grabbing;
    }
  }

  /* when on screen < 480px wide */
  @media only screen and (max-width: 480px) {
    /* make navigation buttons skinnier on small screens to make more room for caption text */
    .lightbox_button {
      width: 50px;
      min-width: 50px;
    }
  }

  /* always hide lightbox on print */
  @media only print {
    #lightbox_overlay {
      display: none;
    }
  }
</style>
<!-- 
  Link Highlight Plugin

  Makes it such that when a user hovers or focuses a link, other links that have
  the same target will be highlighted. It also makes it such that when clicking
  a link, the target of the link (eg reference, figure, table) is briefly
  highlighted.
-->

<script type="module">
  // whether to also highlight links that go to external urls
  const externalLinks = "false";
  // whether user must click off to unhighlight instead of just
  // un-hovering
  const clickUnhighlight = "false";
  // whether to also highlight links that are unique
  const highlightUnique = "true";

  // start script
  function start() {
    const links = getLinks();
    for (const link of links) {
      // attach mouse and focus listeners to link
      link.addEventListener("mouseenter", onLinkFocus);
      link.addEventListener("focus", onLinkFocus);
      link.addEventListener("mouseleave", onLinkUnhover);
    }

    // attach click and hash change listeners to window
    window.addEventListener("click", onClick);
    window.addEventListener("touchstart", onClick);
    window.addEventListener("hashchange", onHashChange);

    // run hash change on window load in case user has navigated
    // directly to hash
    onHashChange();
  }

  // when link is focused (tabbed to) or hovered
  function onLinkFocus() {
    highlight(this);
  }

  // when link is unhovered
  function onLinkUnhover() {
    if (clickUnhighlight !== "true") unhighlightAll();
  }

  // when the mouse is clicked anywhere in window
  function onClick(event) {
    unhighlightAll();
  }

  // when hash (eg manuscript.html#introduction) changes
  function onHashChange() {
    const target = getHashTarget();
    if (target) glowElement(target);
  }

  // start glow sequence on an element
  function glowElement(element) {
    const startGlow = function () {
      onGlowEnd();
      element.dataset.glow = "true";
      element.addEventListener("animationend", onGlowEnd);
    };
    const onGlowEnd = function () {
      element.removeAttribute("data-glow");
      element.removeEventListener("animationend", onGlowEnd);
    };
    startGlow();
  }

  // highlight link and all others with same target
  function highlight(link) {
    // force unhighlight all to start fresh
    unhighlightAll();

    // get links with same target
    if (!link) return;
    const sameLinks = getSameLinks(link);

    // if link unique and option is off, exit and don't highlight
    if (sameLinks.length <= 1 && highlightUnique !== "true") return;

    // highlight all same links, and "select" (special highlight) this
    // one
    for (const sameLink of sameLinks) {
      if (sameLink === link) sameLink.setAttribute("data-selected", "true");
      else sameLink.setAttribute("data-highlighted", "true");
    }
  }

  // unhighlight all links
  function unhighlightAll() {
    const links = getLinks();
    for (const link of links) {
      link.setAttribute("data-selected", "false");
      link.setAttribute("data-highlighted", "false");
    }
  }

  // get links with same target
  function getSameLinks(link) {
    const results = [];
    const links = getLinks();
    for (const otherLink of links) {
      if (otherLink.getAttribute("href") === link.getAttribute("href"))
        results.push(otherLink);
    }
    return results;
  }

  // get all links of types we wish to handle
  function getLinks() {
    let query = "a";
    if (externalLinks !== "true") query += '[href^="#"]';
    // exclude buttons, anchor links, toc links, etc
    query += ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    return document.querySelectorAll(query);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<style>
  @media only screen {
    /* anything with data-highlighted attribute true */
    [data-highlighted="true"] {
      background: #ffeb3b;
    }

    /* anything with data-selected attribute true */
    [data-selected="true"] {
      background: #ff8a65 !important;
    }

    /* animation definition for glow */
    @keyframes highlight_glow {
      0% {
        background: none;
      }
      10% {
        background: #bbdefb;
      }
      100% {
        background: none;
      }
    }

    /* anything with data-glow attribute true */
    [data-glow="true"] {
      animation: highlight_glow 2s;
    }
  }
</style>
<!--
  Table of Contents Plugin

  Provides a "table of contents" (toc) panel on the side of the document that
  allows the user to conveniently navigate between sections of the document.
-->

<script type="module">
  // which types of elements to add links for, in "document.querySelector" format
  const typesQuery = "h1, h2, h3";
  // whether toc starts open. use 'true' or 'false', or 'auto' to
  // use 'true' behavior when screen wide enough and 'false' when not
  const startOpen = "false";
  // whether toc closes when clicking on toc link. use 'true' or
  // 'false', or 'auto' to use 'false' behavior when screen wide
  // enough and 'true' when not
  const clickClose = "auto";
  // if list item is more than this many characters, text will be
  // truncated
  const charLimit = "50";
  // whether or not to show bullets next to each toc item
  const bullets = "false";

  // start script
  function start() {
    // make toc panel and populate with entries (links to document
    // sections)
    const panel = makePanel();
    if (!panel) return;
    makeEntries(panel);
    // attach panel to document after making entries, so 'toc' heading
    // in panel isn't included in toc
    document.body.insertBefore(panel, document.body.firstChild);

    // initial panel state
    if (startOpen === "true" || (startOpen === "auto" && !isSmallScreen()))
      openPanel();
    else closePanel();

    // attach click, scroll, and hash change listeners to window
    window.addEventListener("click", onClick);
    window.addEventListener("scroll", onScroll);
    window.addEventListener("hashchange", onScroll);
    window.addEventListener("keyup", onKeyUp);
    onScroll();

    // add class to push document body down out of way of toc button
    document.body.classList.add("toc_body_nudge");
  }

  // determine if screen wide enough to fit toc panel
  function isSmallScreen() {
    // in default theme:
    // 816px = 8.5in = width of "page" (<body>) element
    // 260px = min width of toc panel (*2 for both sides of <body>)
    return window.innerWidth < 816 + 260 * 2;
  }

  // when mouse is clicked anywhere in window
  function onClick() {
    if (isSmallScreen()) closePanel();
  }

  // when window is scrolled or hash changed
  function onScroll() {
    highlightViewed();
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    // close on esc
    if (event.key === "Escape") closePanel();
  }

  // find entry of currently viewed document section in toc and highlight
  function highlightViewed() {
    const firstId = getFirstInView(typesQuery);

    // get toc entries (links), unhighlight all, then highlight viewed
    const list = document.getElementById("toc_list");
    if (!firstId || !list) return;
    const links = list.querySelectorAll("a");
    for (const link of links) link.dataset.viewing = "false";
    const link = list.querySelector('a[href="#' + firstId + '"]');
    if (!link) return;
    link.dataset.viewing = "true";
  }

  // get first or previous toc listed element in top half of view
  function getFirstInView(query) {
    // get all elements matching query and with id
    const elements = document.querySelectorAll(query);
    const elementsWithIds = [];
    for (const element of elements) {
      if (element.id) elementsWithIds.push(element);
    }

    // get first or previous element in top half of view
    for (let i = 0; i < elementsWithIds.length; i++) {
      const element = elementsWithIds[i];
      const prevElement = elementsWithIds[Math.max(0, i - 1)];
      if (element.getBoundingClientRect().top >= 0) {
        if (element.getBoundingClientRect().top < window.innerHeight / 2)
          return element.id;
        else return prevElement.id;
      }
    }
  }

  // make panel
  function makePanel() {
    // create panel
    const panel = document.createElement("div");
    panel.id = "toc_panel";
    if (bullets === "true") panel.dataset.bullets = "true";

    // create header
    const header = document.createElement("div");
    header.id = "toc_header";

    // create toc button
    const button = document.createElement("button");
    button.id = "toc_button";
    button.innerHTML = document.querySelector(".icon_th_list").innerHTML;
    button.title = "Table of Contents";
    button.classList.add("icon_button");

    // create header text
    const text = document.createElement("h4");
    text.innerHTML = "Table of Contents";

    // create container for toc list
    const list = document.createElement("div");
    list.id = "toc_list";

    // attach click listeners
    panel.addEventListener("click", onPanelClick);
    header.addEventListener("click", onHeaderClick);
    button.addEventListener("click", onButtonClick);

    // attach elements
    header.appendChild(button);
    header.appendChild(text);
    panel.appendChild(header);
    panel.appendChild(list);

    return panel;
  }

  // create toc entries (links) to each element of the specified types
  function makeEntries(panel) {
    const elements = document.querySelectorAll(typesQuery);
    for (const element of elements) {
      // do not add link if element doesn't have assigned id
      if (!element.id) continue;

      // create link/list item
      const link = document.createElement("a");
      link.classList.add("toc_link");
      switch (element.tagName.toLowerCase()) {
        case "h1":
          link.dataset.level = "1";
          break;
        case "h2":
          link.dataset.level = "2";
          break;
        case "h3":
          link.dataset.level = "3";
          break;
        case "h4":
          link.dataset.level = "4";
          break;
      }
      link.title = element.innerText;
      let text = element.innerText;
      if (text.length > charLimit) text = text.slice(0, charLimit) + "...";
      link.innerHTML = text;
      link.href = "#" + element.id;
      link.addEventListener("click", onLinkClick);

      // attach link
      panel.querySelector("#toc_list").appendChild(link);
    }
  }

  // when panel is clicked
  function onPanelClick(event) {
    // stop click from propagating to window/document and closing panel
    event.stopPropagation();
  }

  // when header itself is clicked
  function onHeaderClick(event) {
    togglePanel();
  }

  // when button is clicked
  function onButtonClick(event) {
    togglePanel();
    // stop header underneath button from also being clicked
    event.stopPropagation();
  }

  // when link is clicked
  function onLinkClick(event) {
    if (clickClose === "true" || (clickClose === "auto" && isSmallScreen()))
      closePanel();
    else openPanel();
  }

  // open panel if closed, close if opened
  function togglePanel() {
    const panel = document.getElementById("toc_panel");
    if (!panel) return;

    if (panel.dataset.open === "true") closePanel();
    else openPanel();
  }

  // open panel
  function openPanel() {
    const panel = document.getElementById("toc_panel");
    if (panel) panel.dataset.open = "true";
  }

  // close panel
  function closePanel() {
    const panel = document.getElementById("toc_panel");
    if (panel) panel.dataset.open = "false";
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- th list icon -->

<template class="icon_th_list">
  <!-- modified from: https://fontawesome.com/icons/th-list -->
  <svg width="16" height="16" viewBox="0 0 512 512" tabindex="-1">
    <path
      fill="currentColor"
      d="M96 96c0 26.51-21.49 48-48 48S0 122.51 0 96s21.49-48 48-48 48 21.49 48 48zM48 208c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm0 160c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm96-236h352c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"
      tabindex="-1"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* toc panel */
    #toc_panel {
      box-sizing: border-box;
      position: fixed;
      top: 0;
      left: 0;
      background: #ffffff;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      z-index: 2;
    }

    /* toc panel when closed */
    #toc_panel[data-open="false"] {
      min-width: 60px;
      width: 60px;
      height: 60px;
      border-right: solid 1px #bdbdbd;
      border-bottom: solid 1px #bdbdbd;
    }

    /* toc panel when open */
    #toc_panel[data-open="true"] {
      min-width: 260px;
      max-width: 480px;
      /* keep panel edge consistent distance away from "page" edge */
      width: calc(((100vw - 8.5in) / 2) - 30px - 40px);
      bottom: 0;
      border-right: solid 1px #bdbdbd;
    }

    /* toc panel header */
    #toc_header {
      box-sizing: border-box;
      display: flex;
      flex-direction: row;
      align-items: center;
      height: 60px;
      margin: 0;
      padding: 20px;
    }

    /* toc panel header when hovered */
    #toc_header:hover {
      cursor: pointer;
    }

    /* toc panel header when panel open */
    #toc_panel[data-open="true"] > #toc_header {
      border-bottom: solid 1px #bdbdbd;
    }

    /* toc open/close header button */
    #toc_button {
      margin-right: 20px;
    }

    /* hide toc list and header text when closed */
    #toc_panel[data-open="false"] > #toc_header > *:not(#toc_button),
    #toc_panel[data-open="false"] > #toc_list {
      display: none;
    }

    /* toc list of entries */
    #toc_list {
      box-sizing: border-box;
      width: 100%;
      padding: 20px;
      position: absolute;
      top: calc(60px + 1px);
      bottom: 0;
      overflow: auto;
    }

    /* toc entry, link to section in document */
    .toc_link {
      display: block;
      padding: 5px;
      position: relative;
      font-weight: 600;
      text-decoration: none;
    }

    /* toc entry when hovered or when "viewed" */
    .toc_link:hover,
    .toc_link[data-viewing="true"] {
      background: #f5f5f5;
    }

    /* toc entry, level 1 indentation */
    .toc_link[data-level="1"] {
      margin-left: 0;
    }

    /* toc entry, level 2 indentation */
    .toc_link[data-level="2"] {
      margin-left: 20px;
    }

    /* toc entry, level 3 indentation */
    .toc_link[data-level="3"] {
      margin-left: 40px;
    }

    /* toc entry, level 4 indentation */
    .toc_link[data-level="4"] {
      margin-left: 60px;
    }

    /* toc entry bullets */
    #toc_panel[data-bullets="true"] .toc_link[data-level]:before {
      position: absolute;
      left: -15px;
      top: -1px;
      font-size: 1.5em;
    }

    /* toc entry, level 2 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="2"]:before {
      content: "\2022";
    }

    /* toc entry, level 3 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="3"]:before {
      content: "\25AB";
    }

    /* toc entry, level 4 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="4"]:before {
      content: "-";
    }
  }

  /* when on screen < 8.5in wide */
  @media only screen and (max-width: 8.5in) {
    /* push <body> ("page") element down to make room for toc icon */
    .toc_body_nudge {
      padding-top: 60px;
    }

    /* toc icon when panel closed and not hovered */
    #toc_panel[data-open="false"]:not(:hover) {
      background: rgba(255, 255, 255, 0.75);
    }
  }

  /* always hide toc panel on print */
  @media only print {
    #toc_panel {
      display: none;
    }
  }
</style>
<!-- 
  Tooltips Plugin

  Makes it such that when the user hovers or focuses a link to a citation or
  figure, a tooltip appears with a preview of the reference content, along with
  arrows to navigate between instances of the same reference in the document.
-->

<script type="module">
  // whether user must click off to close tooltip instead of just un-hovering
  const clickClose = "false";
  // delay (in ms) between opening and closing tooltip
  const delay = "100";

  // start script
  function start() {
    const links = getLinks();
    for (const link of links) {
      // attach hover and focus listeners to link
      link.addEventListener("mouseover", onLinkHover);
      link.addEventListener("mouseleave", onLinkUnhover);
      link.addEventListener("focus", onLinkFocus);
      link.addEventListener("touchend", onLinkTouch);
    }

    // attach mouse, key, and resize listeners to window
    window.addEventListener("mousedown", onClick);
    window.addEventListener("touchstart", onClick);
    window.addEventListener("keyup", onKeyUp);
    window.addEventListener("resize", onResize);
  }

  // when link is hovered
  function onLinkHover() {
    // function to open tooltip
    const delayOpenTooltip = function () {
      openTooltip(this);
    }.bind(this);

    // run open function after delay
    this.openTooltipTimer = window.setTimeout(delayOpenTooltip, delay);
  }

  // when mouse leaves link
  function onLinkUnhover() {
    // cancel opening tooltip
    window.clearTimeout(this.openTooltipTimer);

    // don't close on unhover if option specifies
    if (clickClose === "true") return;

    // function to close tooltip
    const delayCloseTooltip = function () {
      // if tooltip open and if mouse isn't over tooltip, close
      const tooltip = document.getElementById("tooltip");
      if (tooltip && !tooltip.matches(":hover")) closeTooltip();
    };

    // run close function after delay
    this.closeTooltipTimer = window.setTimeout(delayCloseTooltip, delay);
  }

  // when link is focused (tabbed to)
  function onLinkFocus(event) {
    openTooltip(this);
  }

  // when link is touched on touch screen
  function onLinkTouch(event) {
    // attempt to force hover state on first tap always, and trigger
    // regular link click (and navigation) on second tap
    if (event.target === document.activeElement) event.target.click();
    else {
      document.activeElement.blur();
      event.target.focus();
    }
    if (event.cancelable) event.preventDefault();
    event.stopPropagation();
    return false;
  }

  // when mouse is clicked anywhere in window
  function onClick(event) {
    closeTooltip();
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    switch (event.key) {
      // trigger click of prev button
      case "ArrowLeft":
        const prevButton = document.getElementById("tooltip_prev_button");
        if (prevButton) prevButton.click();
        break;
      // trigger click of next button
      case "ArrowRight":
        const nextButton = document.getElementById("tooltip_next_button");
        if (nextButton) nextButton.click();
        break;
      // close on esc
      case "Escape":
        closeTooltip();
        break;
    }
  }

  // when window is resized or zoomed
  function onResize() {
    closeTooltip();
  }

  // get all links of types we wish to handle
  function getLinks() {
    const queries = [];
    // exclude buttons, anchor links, toc links, etc
    const exclude =
      ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    queries.push('a[href^="#ref-"]' + exclude); // citation links
    queries.push('a[href^="#fig:"]' + exclude); // figure links
    const query = queries.join(", ");
    return document.querySelectorAll(query);
  }

  // get links with same target, get index of link in set, get total
  // same links
  function getSameLinks(link) {
    const sameLinks = [];
    const links = getLinks();
    for (const otherLink of links) {
      if (otherLink.getAttribute("href") === link.getAttribute("href"))
        sameLinks.push(otherLink);
    }

    return {
      elements: sameLinks,
      index: sameLinks.indexOf(link),
      total: sameLinks.length,
    };
  }

  // open tooltip
  function openTooltip(link) {
    // delete tooltip if it exists, start fresh
    closeTooltip();

    // make tooltip element
    const tooltip = makeTooltip(link);

    // if source couldn't be found and tooltip not made, exit
    if (!tooltip) return;

    // make navbar elements
    const navBar = makeNavBar(link);
    if (navBar) tooltip.firstElementChild.appendChild(navBar);

    // attach tooltip to page
    document.body.appendChild(tooltip);

    // position tooltip
    const position = function () {
      positionTooltip(link);
    };
    position();

    // if tooltip contains images, position again after they've loaded
    const imgs = tooltip.querySelectorAll("img");
    for (const img of imgs) img.addEventListener("load", position);
  }

  // close (delete) tooltip
  function closeTooltip() {
    const tooltip = document.getElementById("tooltip");
    if (tooltip) tooltip.remove();
  }

  // make tooltip
  function makeTooltip(link) {
    // get target element that link points to
    const source = getSource(link);

    // if source can't be found, exit
    if (!source) return;

    // create new tooltip
    const tooltip = document.createElement("div");
    tooltip.id = "tooltip";
    const tooltipContent = document.createElement("div");
    tooltipContent.id = "tooltip_content";
    tooltip.appendChild(tooltipContent);

    // make copy of source node and put in tooltip
    const sourceCopy = makeCopy(source);
    tooltipContent.appendChild(sourceCopy);

    // attach mouse event listeners
    tooltip.addEventListener("click", onTooltipClick);
    tooltip.addEventListener("mousedown", onTooltipClick);
    tooltip.addEventListener("touchstart", onTooltipClick);
    tooltip.addEventListener("mouseleave", onTooltipUnhover);

    // (for interaction with lightbox plugin)
    // transfer click on tooltip copied img to original img
    const sourceImg = source.querySelector("img");
    const sourceCopyImg = sourceCopy.querySelector("img");
    if (sourceImg && sourceCopyImg) {
      const clickImg = function () {
        sourceImg.click();
        closeTooltip();
      };
      sourceCopyImg.addEventListener("click", clickImg);
    }

    return tooltip;
  }

  // make carbon copy of html dom element
  function makeCopy(source) {
    const sourceCopy = source.cloneNode(true);

    // delete elements marked with ignore (eg anchor and jump buttons)
    const deleteFromCopy = sourceCopy.querySelectorAll('[data-ignore="true"]');
    for (const element of deleteFromCopy) element.remove();

    // delete certain element attributes
    const attributes = [
      "id",
      "data-collapsed",
      "data-selected",
      "data-highlighted",
      "data-glow",
      "class",
    ];
    for (const attribute of attributes) {
      sourceCopy.removeAttribute(attribute);
      const elements = sourceCopy.querySelectorAll("[" + attribute + "]");
      for (const element of elements) element.removeAttribute(attribute);
    }

    return sourceCopy;
  }

  // when tooltip is clicked
  function onTooltipClick(event) {
    // when user clicks on tooltip, stop click from transferring
    // outside of tooltip (eg, click off to close tooltip, or eg click
    // off to unhighlight same refs)
    event.stopPropagation();
  }

  // when tooltip is unhovered
  function onTooltipUnhover(event) {
    if (clickClose === "true") return;

    // make sure new mouse/touch/focus no longer over tooltip or any
    // element within it
    const tooltip = document.getElementById("tooltip");
    if (!tooltip) return;
    if (this.contains(event.relatedTarget)) return;

    closeTooltip();
  }

  // make nav bar to go betwen prev/next instances of same reference
  function makeNavBar(link) {
    // find other links to the same source
    const sameLinks = getSameLinks(link);

    // don't show nav bar when singular reference
    if (sameLinks.total <= 1) return;

    // find prev/next links with same target
    const prevLink = getPrevLink(link, sameLinks);
    const nextLink = getNextLink(link, sameLinks);

    // create nav bar
    const navBar = document.createElement("div");
    navBar.id = "tooltip_nav_bar";
    const text = sameLinks.index + 1 + " of " + sameLinks.total;

    // create nav bar prev/next buttons
    const prevButton = document.createElement("button");
    const nextButton = document.createElement("button");
    prevButton.id = "tooltip_prev_button";
    nextButton.id = "tooltip_next_button";
    prevButton.title =
      "Jump to the previous occurence of this item in the document [←]";
    nextButton.title =
      "Jump to the next occurence of this item in the document [→]";
    prevButton.classList.add("icon_button");
    nextButton.classList.add("icon_button");
    prevButton.innerHTML = document.querySelector(".icon_caret_left").innerHTML;
    nextButton.innerHTML =
      document.querySelector(".icon_caret_right").innerHTML;
    navBar.appendChild(prevButton);
    navBar.appendChild(document.createTextNode(text));
    navBar.appendChild(nextButton);

    // attach click listeners to buttons
    prevButton.addEventListener("click", function () {
      onPrevNextClick(link, prevLink);
    });
    nextButton.addEventListener("click", function () {
      onPrevNextClick(link, nextLink);
    });

    return navBar;
  }

  // get previous link with same target
  function getPrevLink(link, sameLinks) {
    if (!sameLinks) sameLinks = getSameLinks(link);
    // wrap index to other side if < 1
    let index;
    if (sameLinks.index - 1 >= 0) index = sameLinks.index - 1;
    else index = sameLinks.total - 1;
    return sameLinks.elements[index];
  }

  // get next link with same target
  function getNextLink(link, sameLinks) {
    if (!sameLinks) sameLinks = getSameLinks(link);
    // wrap index to other side if > total
    let index;
    if (sameLinks.index + 1 <= sameLinks.total - 1) index = sameLinks.index + 1;
    else index = 0;
    return sameLinks.elements[index];
  }

  // get element that is target of link or url hash
  function getSource(link) {
    const hash = link ? link.hash : window.location.hash;
    const id = hash.slice(1);
    let target = document.querySelector('[id="' + id + '"]');
    if (!target) return;

    // if ref or figure, modify target to get expected element
    if (id.indexOf("ref-") === 0) target = target.querySelector(":nth-child(2)");
    else if (id.indexOf("fig:") === 0) target = target.querySelector("figure");

    return target;
  }

  // when prev/next arrow button is clicked
  function onPrevNextClick(link, prevNextLink) {
    if (link && prevNextLink)
      goToElement(prevNextLink, window.innerHeight * 0.5);
  }

  // scroll to and focus element
  function goToElement(element, offset) {
    // expand accordion section if collapsed
    expandElement(element);
    const y =
      getRectInView(element).top -
      getRectInView(document.documentElement).top -
      (offset || 0);
    // trigger any function listening for "onscroll" event
    window.dispatchEvent(new Event("scroll"));
    window.scrollTo(0, y);
    document.activeElement.blur();
    element.focus();
  }

  // determine position to place tooltip based on link position in
  // viewport and tooltip size
  function positionTooltip(link, left, top) {
    const tooltipElement = document.getElementById("tooltip");
    if (!tooltipElement) return;

    // get convenient vars for position/dimensions of
    // link/tooltip/page/view
    link = getRectInPage(link);
    const tooltip = getRectInPage(tooltipElement);
    const view = getRectInPage();

    // horizontal positioning
    if (left)
      // use explicit value
      left = left;
    else if (link.left + tooltip.width < view.right)
      // fit tooltip to right of link
      left = link.left;
    else if (link.right - tooltip.width > view.left)
      // fit tooltip to left of link
      left = link.right - tooltip.width;
    // center tooltip in view
    else left = (view.right - view.left) / 2 - tooltip.width / 2;

    // vertical positioning
    if (top)
      // use explicit value
      top = top;
    else if (link.top - tooltip.height > view.top)
      // fit tooltip above link
      top = link.top - tooltip.height;
    else if (link.bottom + tooltip.height < view.bottom)
      // fit tooltip below link
      top = link.bottom;
    else {
      // center tooltip in view
      top = view.top + view.height / 2 - tooltip.height / 2;
      // nudge off of link to left/right if possible
      if (link.right + tooltip.width < view.right) left = link.right;
      else if (link.left - tooltip.width > view.left)
        left = link.left - tooltip.width;
    }

    tooltipElement.style.left = left + "px";
    tooltipElement.style.top = top + "px";
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
  <!-- modified from: https://fontawesome.com/icons/caret-left -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
    ></path>
  </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
  <!-- modified from: https://fontawesome.com/icons/caret-right -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* tooltip container */
    #tooltip {
      position: absolute;
      width: 50%;
      min-width: 240px;
      max-width: 75%;
      z-index: 1;
    }

    /* tooltip content */
    #tooltip_content {
      margin-bottom: 5px;
      padding: 20px;
      border-radius: 5px;
      border: solid 1px #bdbdbd;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      background: #ffffff;
      overflow-wrap: break-word;
    }

    /* tooltip copy of paragraphs and figures */
    #tooltip_content > p,
    #tooltip_content > figure {
      margin: 0;
      max-height: 320px;
      overflow-y: auto;
    }

    /* tooltip copy of <img> */
    #tooltip_content > figure > img,
    #tooltip_content > figure > svg {
      max-height: 260px;
    }

    /* navigation bar */
    #tooltip_nav_bar {
      margin-top: 10px;
      text-align: center;
    }

    /* navigation bar previous/next buton */
    #tooltip_nav_bar > .icon_button {
      position: relative;
      top: 3px;
    }

    /* navigation bar previous button */
    #tooltip_nav_bar > .icon_button:first-of-type {
      margin-right: 5px;
    }

    /* navigation bar next button */
    #tooltip_nav_bar > .icon_button:last-of-type {
      margin-left: 5px;
    }
  }

  /* always hide tooltip on print */
  @media only print {
    #tooltip {
      display: none;
    }
  }
</style>
<!--
  Analytics Plugin (third-party) 
  
  Copy and paste code from Google Analytics or similar service here.
-->
<!-- 
  Annotations Plugin

  Allows public annotation of the  manuscript. See https://web.hypothes.is/.
-->

<script type="module">
  // configuration
  window.hypothesisConfig = function () {
    return {
      branding: {
        accentColor: "#2196f3",
        appBackgroundColor: "#f8f8f8",
        ctaBackgroundColor: "#f8f8f8",
        ctaTextColor: "#000000",
        selectionFontFamily: "Open Sans, Helvetica, sans serif",
        annotationFontFamily: "Open Sans, Helvetica, sans serif",
      },
    };
  };

  // hypothesis client script
  const embed = "https://hypothes.is/embed.js";
  // hypothesis annotation count query url
  const query = "https://api.hypothes.is/api/search?limit=0&url=";

  // start script
  function start() {
    const button = makeButton();
    document.body.insertBefore(button, document.body.firstChild);
    insertCount(button);
  }

  // make button
  function makeButton() {
    // create button
    const button = document.createElement("button");
    button.id = "hypothesis_button";
    button.innerHTML = document.querySelector(".icon_hypothesis").innerHTML;
    button.title = "Hypothesis annotations";
    button.classList.add("icon_button");

    function onClick(event) {
      onButtonClick(event, button);
    }

    // attach click listeners
    button.addEventListener("click", onClick);

    return button;
  }

  // insert annotations count
  async function insertCount(button) {
    // get annotation count from Hypothesis based on url
    let count = "-";
    try {
      const canonical = document.querySelector('link[rel="canonical"]');
      const location = window.location;
      const url = encodeURIComponent((canonical || location).href);
      const response = await fetch(query + url);
      const json = await response.json();
      count = json.total || "-";
    } catch (error) {
      console.log(error);
    }

    // put count into button
    const counter = document.createElement("span");
    counter.id = "hypothesis_count";
    counter.innerHTML = count;
    button.title = "View " + count + " Hypothesis annotations";
    button.append(counter);
  }

  // when button is clicked
  function onButtonClick(event, button) {
    const script = document.createElement("script");
    script.src = embed;
    document.body.append(script);
    button.remove();
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- hypothesis icon -->

<template class="icon_hypothesis">
  <!-- modified from: https://simpleicons.org/icons/hypothesis.svg / https://git.io/Jf1VB -->
  <svg width="16" height="16" viewBox="0 0 24 24" tabindex="-1">
    <path
      fill="currentColor"
      d="M3.43 0C2.5 0 1.72 .768 1.72 1.72V18.86C1.72 19.8 2.5 20.57 3.43 20.57H9.38L12 24L14.62 20.57H20.57C21.5 20.57 22.29 19.8 22.29 18.86V1.72C22.29 .77 21.5 0 20.57 0H3.43M5.14 3.43H7.72V9.43S8.58 7.72 10.28 7.72C12 7.72 13.74 8.57 13.74 11.24V17.14H11.16V12C11.16 10.61 10.28 10.07 9.43 10.29C8.57 10.5 7.72 11.41 7.72 13.29V17.14H5.14V3.43M18 13.72C18.95 13.72 19.72 14.5 19.72 15.42A1.71 1.71 0 0 1 18 17.13A1.71 1.71 0 0 1 16.29 15.42C16.29 14.5 17.05 13.71 18 13.71Z"
      tabindex="-1"
    ></path>
  </svg>
</template>

<style>
  /* hypothesis activation button */
  #hypothesis_button {
    box-sizing: border-box;
    position: fixed;
    top: 0;
    right: 0;
    width: 60px;
    height: 60px;
    background: #ffffff;
    border-radius: 0;
    border-left: solid 1px #bdbdbd;
    border-bottom: solid 1px #bdbdbd;
    box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
    z-index: 2;
  }

  /* hypothesis button svg */
  #hypothesis_button > svg {
    position: relative;
    top: -4px;
  }

  /* hypothesis annotation count */
  #hypothesis_count {
    position: absolute;
    left: 0;
    right: 0;
    bottom: 5px;
  }

  /* side panel */
  .annotator-frame {
    width: 280px !important;
  }

  /* match highlight color to rest of theme */
  .annotator-highlights-always-on .annotator-hl {
    background-color: #ffeb3b !important;
  }

  /* match focused color to rest of theme */
  .annotator-hl.annotator-hl-focused {
    background-color: #ff8a65 !important;
  }

  /* match bucket bar color to rest of theme */
  .annotator-bucket-bar {
    background: #f5f5f5 !important;
  }

  /* always hide button, toolbar, and tooltip on print */
  @media only print {
    #hypothesis_button {
      display: none;
    }

    .annotator-frame {
      display: none !important;
    }

    hypothesis-adder {
      display: none !important;
    }
  }
</style>
<!-- 
  Mathjax Plugin (third-party) 

  Allows the proper rendering of math/equations written in LaTeX.
  See https://www.mathjax.org/.
-->

<script type="text/x-mathjax-config">
  // configuration
  MathJax.Hub.Config({
    "CommonHTML": { linebreaks: { automatic: true } },
    "HTML-CSS": { linebreaks: { automatic: true } },
    "SVG": { linebreaks: { automatic: true } },
    "fast-preview": { disabled: true }
  });
</script>

<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A=="
  crossorigin="anonymous"
></script>

<style>
  /* mathjax containers */
  .math.display > span:not(.MathJax_Preview) {
    /* turn inline element (no dimensions) into block (allows fixed width and thus scrolling) */
    display: flex !important;
    overflow-x: auto !important;
    overflow-y: hidden !important;
    justify-content: center;
    align-items: center;
    margin: 0 !important;
  }

  /* right click menu */
  .MathJax_Menu {
    border-radius: 5px !important;
    border: solid 1px #bdbdbd !important;
    box-shadow: none !important;
  }

  /* equation auto-number */
  span[id^="eq:"] > span.math.display + span {
    font-weight: 600;
  }

  /* equation */
  span[id^="eq:"] > span.math.display > span {
    /* nudge to make room for equation auto-number and anchor */
    margin-right: 60px !important;
  }
</style>
</body>
</html>
